{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b2aa88a",
   "metadata": {},
   "source": [
    "# RTP Forecasting: CNN-LSTM search\n",
    "In this notebook, we do a full search for the best hyperparameters for the LSTM model. To achieve this task, we used keras-tuner with some manual tuning. Six searchs runs was conducted and the best model was chosen and implement in `LSTM_model.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c5e7ab-46c8-467b-8a4d-64c441864db4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in /srv/conda/envs/notebook/lib/python3.10/site-packages (1.4.6)\n",
      "Requirement already satisfied: keras in /srv/conda/envs/notebook/lib/python3.10/site-packages (from keras-tuner) (2.12.0)\n",
      "Requirement already satisfied: packaging in /srv/conda/envs/notebook/lib/python3.10/site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.10/site-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in /srv/conda/envs/notebook/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests->keras-tuner) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests->keras-tuner) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests->keras-tuner) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b599e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 14:34:29.723308: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-19 14:34:29.762271: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7317c723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e68172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "791e50da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dir(path):\n",
    "    if os.path.exists(path) is False:\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3107984b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#timing callback\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eeacbf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#zones = ['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'LONGIL',\n",
    "#         'MHK VL', 'MILLWD', 'N.Y.C.', 'NORTH', 'WEST']\n",
    "zone = 'N.Y.C.'\n",
    "year = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6a2ff2",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f734c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read each timeseries (RTP = Real-Time Price, DAP = Day-Ahead Price, LF = Load Forecast)\n",
    "raw_DAP = pd.read_csv(\"nyiso/da_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "raw_RTP = pd.read_csv(\"nyiso/rt_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "raw_LF = pd.read_csv(\"nyiso/load_frcstd_df_2015_2021.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5febf202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the dataset as a dataframe\n",
    "raw_data = pd.concat([raw_DAP.loc[:,zone], raw_LF.loc[:,zone], raw_RTP.loc[:,zone]],\n",
    "                       axis=1).loc['2017-01-01 05:00:00+00:00':]\n",
    "raw_data.columns = ['DAP', 'LF', 'RTP']\n",
    "raw_data.index.names = ['date']\n",
    "raw_data.to_csv('nyiso/NYISO_'+zone+'_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2704d43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We perform log tranformation before feeding the dataset into the model to make enhance the performance\n",
    "# We only log tranform the price data (RTP and DAP)\n",
    "log = 1\n",
    "# log transformation for the forecasting task log10(Y + 1 - min(Y))\n",
    "if log:\n",
    "    log_data = raw_data.copy(deep=True)\n",
    "    log_data.loc[:,\"DAP\"] = np.log(raw_data.loc[:,\"DAP\"] + 1 - min(raw_data.loc[:,\"DAP\"]))\n",
    "    log_data.loc[:,\"RTP\"] = np.log(raw_data.loc[:,\"RTP\"] + 1 - min(raw_data.loc[:,\"RTP\"]))\n",
    "    log_data.to_csv('nyiso/NYISO_'+zone+'_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36355172",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e13d18ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split dataset: 2017-2020 years for training and 2021 year for testing\n",
    "x_train_df = log_data.iloc[:8760*4+24,:]\n",
    "x_test_df = log_data.iloc[8760*4+24:,:]\n",
    "\n",
    "y_train_df = log_data.iloc[:8760*4+24,2:]\n",
    "y_test_df = log_data.iloc[8760*4+24:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "494c0470",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35064, 3) (35064, 1) (8760, 3) (8760, 1)\n"
     ]
    }
   ],
   "source": [
    "# # Standardization\n",
    "x_mean, x_std = x_train_df.mean(), x_train_df.std()\n",
    "y_mean, y_std = y_train_df.mean(), y_train_df.std()\n",
    "\n",
    "x_train = ((x_train_df - x_mean)/x_std).to_numpy()\n",
    "x_test = ((x_test_df - x_mean)/x_std).to_numpy()\n",
    "\n",
    "y_train = ((y_train_df - y_mean)/y_std).to_numpy()\n",
    "y_test = ((y_test_df - y_mean)/y_std).to_numpy()\n",
    "\n",
    "print(x_train.shape,y_train.shape,x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776a123",
   "metadata": {},
   "source": [
    "### Reshape to (samples, steps, features)\n",
    "more details about the reshape can be found in `LSTM_model.ipynb` or the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4327ffd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34969, 72, 3) (34969, 24, 1) (8665, 72, 3) (8665, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "n_steps_in = 72\n",
    "n_steps_out = 24\n",
    "\n",
    "x_train_lstm = np.array([x_train[i:i+n_steps_in] for i in range(0, x_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "y_train_lstm = np.array([y_train[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "x_test_lstm = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "y_test_lstm = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "print(x_train_lstm.shape,y_train_lstm.shape,x_test_lstm.shape,y_test_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e79341c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These hyperparameter are set manually as it is not part of the model structure,\n",
    "# so we don't include it to keras-tuner search pool\n",
    "# minibatch considered are [32, 64]\n",
    "\n",
    "minibatch_size = 64\n",
    "num_epochs     = 50\n",
    "n_trials       = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f27844b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function for keras-tuner model builder, the model structure was set during experimntation phase of the project\n",
    "def build_model(hp):\n",
    "\n",
    "    hp_neurons = hp.Choice('neurons', values=[16,32,64])\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh', 'sigmoid'])\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "    hp_loss = hp.Choice('loss', values=['mse','mae'])\n",
    "    \n",
    "    lstm_model = keras.models.Sequential()\n",
    "\n",
    "    lstm_model.add(LSTM(hp_neurons,input_shape=(x_train_lstm.shape[1],x_train_lstm.shape[2]),\n",
    "               return_sequences=True,activation=hp_activation))\n",
    "    lstm_model.add(LSTM(hp_neurons,return_sequences=False,\n",
    "               activation=hp_activation))\n",
    "    lstm_model.add(Dense(hp_neurons,activation=hp_activation))\n",
    "    lstm_model.add(Dense(y_train_lstm.shape[-2],activation='linear')) \n",
    "\n",
    "    lstm_model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate))\n",
    "    \n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b867e1c-130f-4dde-9520-609bcc4e15f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the Tuner and save the trials in a directory with customized project name\n",
    "random_tuner = keras_tuner.RandomSearch(build_model, \n",
    "                                        max_trials=n_trials,\n",
    "                                        seed=5,\n",
    "                                        objective='val_loss', \n",
    "                                        max_retries_per_trial=0,\n",
    "                                        max_consecutive_failed_trials=3,\n",
    "                                        directory='random_search', \n",
    "                                        project_name='lstm_search7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aeaec84-9b0b-426f-b9e9-e9beca8abdd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "neurons (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001, 1e-05], 'ordered': True}\n",
      "loss (Choice)\n",
      "{'default': 'mse', 'conditions': [], 'values': ['mse', 'mae'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "random_tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "450ec251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 36m 25s]\n",
      "val_loss: 0.2370855212211609\n",
      "\n",
      "Best val_loss So Far: 0.19176627695560455\n",
      "Total elapsed time: 05h 59m 54s\n"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "random_tuner.search(x_train_lstm, y_train_lstm, \n",
    "                    batch_size = minibatch_size,\n",
    "                    epochs = num_epochs,\n",
    "                    validation_split=0.2, verbose=1,\n",
    "                    callbacks=[early_stop],\n",
    "                    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb4e33d9-5607-4756-83e7-1b788132aa29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 72, 32)            4608      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1056      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 21:10:18.616448: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-19 21:10:18.617743: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-19 21:10:18.618635: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-19 21:10:18.757647: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-19 21:10:18.758584: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-19 21:10:18.759376: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,776\n",
      "Trainable params: 14,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# display the model structure with the best tuning\n",
    "best_model = random_tuner.get_best_models()[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34ef404d-28e1-48d2-a112-68eda2a0f9e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking # 1 of best tuning, total trials =  10\n",
      "{'neurons': 32, 'activation': 'tanh', 'learning_rate': 0.001, 'loss': 'mse'}\n",
      "=============================================================================================\n",
      "Ranking # 2 of best tuning, total trials =  10\n",
      "{'neurons': 32, 'activation': 'tanh', 'learning_rate': 0.0001, 'loss': 'mse'}\n",
      "=============================================================================================\n",
      "Ranking # 3 of best tuning, total trials =  10\n",
      "{'neurons': 32, 'activation': 'sigmoid', 'learning_rate': 0.001, 'loss': 'mse'}\n",
      "=============================================================================================\n",
      "Ranking # 4 of best tuning, total trials =  10\n",
      "{'neurons': 32, 'activation': 'tanh', 'learning_rate': 0.01, 'loss': 'mse'}\n",
      "=============================================================================================\n",
      "Ranking # 5 of best tuning, total trials =  10\n",
      "{'neurons': 16, 'activation': 'sigmoid', 'learning_rate': 0.001, 'loss': 'mae'}\n",
      "=============================================================================================\n",
      "Ranking # 6 of best tuning, total trials =  10\n",
      "{'neurons': 32, 'activation': 'sigmoid', 'learning_rate': 0.0001, 'loss': 'mse'}\n",
      "=============================================================================================\n",
      "Ranking # 7 of best tuning, total trials =  10\n",
      "{'neurons': 64, 'activation': 'tanh', 'learning_rate': 0.01, 'loss': 'mse'}\n",
      "=============================================================================================\n",
      "Ranking # 8 of best tuning, total trials =  10\n",
      "{'neurons': 32, 'activation': 'relu', 'learning_rate': 0.0001, 'loss': 'mae'}\n",
      "=============================================================================================\n",
      "Ranking # 9 of best tuning, total trials =  10\n",
      "{'neurons': 16, 'activation': 'relu', 'learning_rate': 1e-05, 'loss': 'mse'}\n",
      "=============================================================================================\n",
      "Ranking # 10 of best tuning, total trials =  10\n",
      "{'neurons': 16, 'activation': 'sigmoid', 'learning_rate': 1e-05, 'loss': 'mae'}\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# check hyperparameters of the all tuning trials\n",
    "all_hps = random_tuner.get_best_hyperparameters(num_trials=n_trials)\n",
    "\n",
    "# print the hyperparameters of the top 3 tuning trials\n",
    "for it in range(n_trials):\n",
    "    print(\"Ranking #\", str(it+1).zfill(1), \"of best tuning, total trials = \", str(n_trials))\n",
    "    print(all_hps[it].values)\n",
    "    print(\"=============================================================================================\")\n",
    "\n",
    "\n",
    "# get the hyperparameters of the best tuning trial\n",
    "best_hps = random_tuner.get_best_hyperparameters(num_trials=n_trials)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b202127b-6562-48b1-af04-6dff40407cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initiate an empty dataframe to store your results\n",
    "tune_res = pd.DataFrame()\n",
    "\n",
    "# Run a for loop to extract all the information we want\n",
    "for trial in random_tuner.oracle.trials:\n",
    "    # Get the state for this trial\n",
    "    trial_state = random_tuner.oracle.trials[trial].get_state()\n",
    "    \n",
    "    # Create a Series contaning the hyperparameter values for this trial\n",
    "    trial_hyperparameters = pd.Series(\n",
    "        trial_state[\"hyperparameters\"][\"values\"],\n",
    "        index = trial_state[\"hyperparameters\"][\"values\"].keys())\n",
    "    \n",
    "    # Create a Series contaning the validation loss for this trial\n",
    "    trial_loss = pd.Series(trial_state[\"score\"], index = [\"val_loss\"])\n",
    "    \n",
    "    # Combine both Series into one Series\n",
    "    trial_tune_res = pd.concat([trial_hyperparameters, trial_loss])\n",
    "    \n",
    "    # Name the Series (such that we can trace the trial numbers in the final DataFrame)\n",
    "    trial_tune_res.name = trial\n",
    "    \n",
    "    # Add this trial information to the DataFrame\n",
    "    tune_res = pd.concat([tune_res, trial_tune_res], axis = 1)\n",
    "    \n",
    "# Transpose the DataFrame such that each row represents a trial\n",
    "tune_res = tune_res.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7178a9f-8d06-471b-aa6d-5e26d41cfe68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neurons</th>\n",
       "      <th>activation</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.191766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.193819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>32</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.19983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.200516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.237086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>32</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.256971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06</th>\n",
       "      <td>64</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.328912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07</th>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.485965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08</th>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.505513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09</th>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.570843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neurons activation learning_rate loss  val_loss\n",
       "00      32       tanh         0.001  mse  0.191766\n",
       "01      32       tanh        0.0001  mse  0.193819\n",
       "02      32    sigmoid         0.001  mse   0.19983\n",
       "03      32       tanh          0.01  mse  0.200516\n",
       "04      16    sigmoid         0.001  mae  0.237086\n",
       "05      32    sigmoid        0.0001  mse  0.256971\n",
       "06      64       tanh          0.01  mse  0.328912\n",
       "07      32       relu        0.0001  mae  0.485965\n",
       "08      16       relu       0.00001  mse  0.505513\n",
       "09      16    sigmoid       0.00001  mae  0.570843"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for s in range(n_trials):\n",
    "    min_idx = s\n",
    "    for i in range(s + 1, n_trials):\n",
    "             \n",
    "            # For sorting in descending order\n",
    "            # for minimum element in each loop\n",
    "        if (tune_res[\"val_loss\"][i] < tune_res[\"val_loss\"][min_idx]):\n",
    "                min_idx = i\n",
    " \n",
    "        # Arranging min at the correct position\n",
    "    b, c = tune_res.iloc[s].copy(), tune_res.iloc[min_idx].copy()\n",
    "    temp = tune_res.iloc[s].copy()\n",
    "    tune_res.iloc[s] = c\n",
    "    tune_res.iloc[min_idx] = temp\n",
    "\n",
    "\n",
    "tune_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9338ab-fab2-48db-aec5-18268496bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_res.to_csv('tuning_results/lstm_tune_res_mini'+str(minibatch_size)+'_'+str(n_steps_in)+'h.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running all the different random searches, we will only test the best one for the three different look-back windows, and see which is the best in the testing set. This process is done in another notebook `LSTM_model.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
