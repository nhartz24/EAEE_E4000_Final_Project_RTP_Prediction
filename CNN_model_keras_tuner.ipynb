{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b2aa88a",
   "metadata": {},
   "source": [
    "# RTP Forecasting: CNN search\n",
    "In this notebook, we do a full search for the best hyperparameters for the CNN model. To achieve this task, we used keras-tuner with some manual tuning. Six search runs was conducted and the best model was chosen and implement in `CNN_model.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731d33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b599e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "import keras_tuner\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7317c723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e68172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791e50da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dir(path):\n",
    "    if os.path.exists(path) is False:\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3107984b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#timing callback\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eeacbf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#zones = ['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'LONGIL',\n",
    "#         'MHK VL', 'MILLWD', 'N.Y.C.', 'NORTH', 'WEST']\n",
    "zone = 'N.Y.C.'\n",
    "year = 2021"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca6a2ff2",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45f734c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read each timeseries (RTP = Real-Time Price, DAP = Day-Ahead Price, LF = Load Forecast)\n",
    "raw_DAP = pd.read_csv(\"nyiso/da_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "raw_RTP = pd.read_csv(\"nyiso/rt_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "raw_LF = pd.read_csv(\"nyiso/load_frcstd_df_2015_2021.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5febf202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the dataset as a dataframe\n",
    "raw_data = pd.concat([raw_DAP.loc[:,zone], raw_LF.loc[:,zone], raw_RTP.loc[:,zone]],\n",
    "                       axis=1).loc['2017-01-01 05:00:00+00:00':]\n",
    "raw_data.columns = ['DAP', 'LF', 'RTP']\n",
    "raw_data.index.names = ['date']\n",
    "raw_data.to_csv('nyiso/NYISO_'+zone+'_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2704d43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We perform log tranformation before feeding the dataset into the model to make enhance the performance\n",
    "# We only log tranform the price data (RTP and DAP)\n",
    "log = 1\n",
    "# log transformation for the forecasting task log10(Y + 1 - min(Y))\n",
    "if log:\n",
    "    log_data = raw_data.copy(deep=True)\n",
    "    log_data.loc[:,\"DAP\"] = np.log(raw_data.loc[:,\"DAP\"] + 1 - min(raw_data.loc[:,\"DAP\"]))\n",
    "    log_data.loc[:,\"RTP\"] = np.log(raw_data.loc[:,\"RTP\"] + 1 - min(raw_data.loc[:,\"RTP\"]))\n",
    "    log_data.to_csv('nyiso/NYISO_'+zone+'_log.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36355172",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e13d18ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split dataset: 2017-2020 years for training and 2021 year for testing\n",
    "x_train_df = log_data.iloc[:8760*4+24,:]\n",
    "x_test_df = log_data.iloc[8760*4+24:,:]\n",
    "\n",
    "y_train_df = log_data.iloc[:8760*4+24,2:]\n",
    "y_test_df = log_data.iloc[8760*4+24:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "494c0470",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35064, 3) (35064, 1) (8760, 3) (8760, 1)\n"
     ]
    }
   ],
   "source": [
    "# # Standardization\n",
    "x_mean, x_std = x_train_df.mean(), x_train_df.std()\n",
    "y_mean, y_std = y_train_df.mean(), y_train_df.std()\n",
    "\n",
    "x_train = ((x_train_df - x_mean)/x_std).to_numpy()\n",
    "x_test = ((x_test_df - x_mean)/x_std).to_numpy()\n",
    "\n",
    "y_train = ((y_train_df - y_mean)/y_std).to_numpy()\n",
    "y_test = ((y_test_df - y_mean)/y_std).to_numpy()\n",
    "\n",
    "print(x_train.shape,y_train.shape,x_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9776a123",
   "metadata": {},
   "source": [
    "### Reshape to (samples, steps, features)\n",
    "more details about the reshape can be found in `CNN_model.ipynb` or the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b31366b0-34cd-4134-b5d8-296bea0ef5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35017, 24, 3) (35017, 24, 1) (8713, 24, 3) (8713, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "n_steps_in = 24\n",
    "n_steps_out = 24\n",
    "\n",
    "x_train_cnn = np.array([x_train[i:i+n_steps_in] for i in range(0, x_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "y_train_cnn = np.array([y_train[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "x_test_cnn = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "y_test_cnn = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "print(x_train_cnn.shape,y_train_cnn.shape,x_test_cnn.shape,y_test_cnn.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b004c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These hyperparameter are set manually as it is not part of the model structure,\n",
    "# so we don't include it to keras-tuner search pool\n",
    "# minibatch considered are [32, 64]\n",
    "\n",
    "minibatch_size = 32\n",
    "num_epochs     = 50\n",
    "n_trials       = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c677010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for keras-tuner model builder, the model structure was set during experimntation phase of the project\n",
    "def build_model(hp):\n",
    "\n",
    "    hp_neurons = hp.Choice('neurons', values=[16,32,64])\n",
    "    hp_filters = hp.Choice('filters', values=[16,32,64])\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh', 'sigmoid'])\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "    hp_kernel_size = hp.Choice('kernel_size', values=[2, 3, 4])\n",
    "    hp_pool_size = hp.Choice('pool_size', values=[1, 2])\n",
    "    hp_loss = hp.Choice('loss', values=['mse','mae'])\n",
    "    \n",
    "    cnn_model = keras.models.Sequential()\n",
    "    cnn_model.add(Conv1D(filters=hp_filters,kernel_size=hp_kernel_size, strides=2, padding='same',\n",
    "                        input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=hp_activation))\n",
    "    cnn_model.add(Conv1D(filters=hp_filters,kernel_size=hp_kernel_size, strides=2, padding='same',\n",
    "                        input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=hp_activation))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=hp_pool_size))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(hp_neurons, activation=hp_activation))\n",
    "    cnn_model.add(Dense(n_steps_out, activation='linear'))\n",
    "    cnn_model.summary()\n",
    "    cnn_model.compile(loss=hp_loss,optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate))\n",
    "\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44cb9900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 36, 16)            112       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 18, 16)            528       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 18, 16)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                4624      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                408       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,672\n",
      "Trainable params: 5,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Tuner and save the trials in a directory with customized project name\n",
    "random_tuner = keras_tuner.RandomSearch(build_model, \n",
    "                                        max_trials=n_trials,\n",
    "                                        seed=5,\n",
    "                                        objective='val_loss', \n",
    "                                        max_retries_per_trial=0,\n",
    "                                        max_consecutive_failed_trials=3,\n",
    "                                        directory='random_search', \n",
    "                                        project_name='cnn_search6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "787914e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 7\n",
      "neurons (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "filters (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001, 1e-05], 'ordered': True}\n",
      "kernel_size (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 4], 'ordered': True}\n",
      "pool_size (Choice)\n",
      "{'default': 1, 'conditions': [], 'values': [1, 2], 'ordered': True}\n",
      "loss (Choice)\n",
      "{'default': 'mse', 'conditions': [], 'values': ['mse', 'mae'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "random_tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a29d64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 48s]\n",
      "val_loss: 0.27021634578704834\n",
      "\n",
      "Best val_loss So Far: 0.19307756423950195\n",
      "Total elapsed time: 00h 16m 46s\n"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "random_tuner.search(x_train_cnn, y_train_cnn, \n",
    "                    batch_size = minibatch_size,\n",
    "                    epochs = num_epochs,\n",
    "                    validation_split=0.2, verbose=1,\n",
    "                    callbacks=[early_stop],\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaac14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate an empty dataframe to store your results\n",
    "tune_res = pd.DataFrame()\n",
    "\n",
    "# Run a for loop to extract all the information we want\n",
    "for trial in random_tuner.oracle.trials:\n",
    "    # Get the state for this trial\n",
    "    trial_state = random_tuner.oracle.trials[trial].get_state()\n",
    "    \n",
    "    # Create a Series contaning the hyperparameter values for this trial\n",
    "    trial_hyperparameters = pd.Series(\n",
    "        trial_state[\"hyperparameters\"][\"values\"],\n",
    "        index = trial_state[\"hyperparameters\"][\"values\"].keys())\n",
    "    \n",
    "    # Create a Series contaning the validation loss for this trial\n",
    "    trial_loss = pd.Series(trial_state[\"score\"], index = [\"val_loss\"])\n",
    "    \n",
    "    # Combine both Series into one Series\n",
    "    trial_tune_res = pd.concat([trial_hyperparameters, trial_loss])\n",
    "    \n",
    "    # Name the Series (such that we can trace the trial numbers in the final DataFrame)\n",
    "    trial_tune_res.name = trial\n",
    "    \n",
    "    # Add this trial information to the DataFrame\n",
    "    tune_res = pd.concat([tune_res, trial_tune_res], axis = 1)\n",
    "    \n",
    "# Transpose the DataFrame such that each row represents a trial\n",
    "tune_res = tune_res.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20d4c42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neurons</th>\n",
       "      <th>filters</th>\n",
       "      <th>activation</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>pool_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.193078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.194066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.20257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.209496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.229598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.263423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.270216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.310589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.370995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09</th>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.376353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neurons filters activation learning_rate kernel_size pool_size loss  \\\n",
       "00      32      32       tanh         0.001           4         2  mse   \n",
       "01      64      32       relu        0.0001           3         1  mse   \n",
       "02      64      64       relu       0.00001           4         2  mse   \n",
       "03      32      64       tanh         0.001           3         1  mse   \n",
       "04      32      16       relu       0.00001           3         2  mse   \n",
       "05      32      32       relu         0.001           2         2  mae   \n",
       "06      64      64    sigmoid         0.001           2         1  mae   \n",
       "07      32      32       tanh          0.01           3         1  mae   \n",
       "08      32      64       relu          0.01           3         2  mse   \n",
       "09      64      16    sigmoid          0.01           3         1  mse   \n",
       "\n",
       "    val_loss  \n",
       "00  0.193078  \n",
       "01  0.194066  \n",
       "02   0.20257  \n",
       "03  0.209496  \n",
       "04  0.229598  \n",
       "05  0.263423  \n",
       "06  0.270216  \n",
       "07  0.310589  \n",
       "08  0.370995  \n",
       "09  0.376353  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for s in range(n_trials):\n",
    "    min_idx = s\n",
    "    for i in range(s + 1, n_trials):\n",
    "             \n",
    "            # For sorting in descending order\n",
    "            # for minimum element in each loop\n",
    "        if (tune_res[\"val_loss\"][i] < tune_res[\"val_loss\"][min_idx]):\n",
    "                min_idx = i\n",
    " \n",
    "        # Arranging min at the correct position\n",
    "    b, c = tune_res.iloc[s].copy(), tune_res.iloc[min_idx].copy()\n",
    "    temp = tune_res.iloc[s].copy()\n",
    "    tune_res.iloc[s] = c\n",
    "    tune_res.iloc[min_idx] = temp\n",
    "\n",
    "\n",
    "tune_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d750d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_res.to_csv('cnn_tune_res_mini'+str(minibatch_size)+'_'+str(n_steps_in)+'h.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0efdc68",
   "metadata": {},
   "source": [
    "After running all the different random searches, we will only test the best one for the three different look-back windows, and see which is the best in the testing set. This process is done in another notebook `CNN_model.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
