{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b2aa88a",
   "metadata": {},
   "source": [
    "# RTP Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b599e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7317c723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e68172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791e50da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dir(path):\n",
    "    if os.path.exists(path) is False:\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3107984b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#timing callback\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6599df1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot history and future\n",
    "def plot_predictions(pred , actual, title):\n",
    "    plt.figure(figsize=(20, 4), dpi=150)\n",
    "    plt.plot(np.arange(len(pred)), np.array(pred),label='cnn',alpha=0.7)\n",
    "    plt.plot(np.arange(len(pred)), np.array(actual),label='PF', alpha=0.7)\n",
    "    plt.axhline(y=0, color='black', linestyle='--', lw=1, alpha=0.5)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Time step' ,  fontsize=18)\n",
    "    plt.ylabel('Price' , fontsize=18)\n",
    "    plt.title(title, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f090a8e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot history and future\n",
    "def plot_predictions_slide(pred_1,pred_2,pred_3, actual, title):\n",
    "    plt.figure(figsize=(20, 4), dpi=150)\n",
    "    plt.plot(np.arange(len(pred_1)), np.array(actual),label='PF', alpha=0.7)\n",
    "    plt.plot(np.arange(len(pred_1)), np.array(pred_1),label='cnn-24',alpha=0.7)\n",
    "    plt.plot(np.arange(len(pred_1)), np.array(pred_2),label='cnn-48',alpha=0.7)\n",
    "    plt.plot(np.arange(len(pred_1)), np.array(pred_3),label='cnn-27',alpha=0.7)\n",
    "    plt.axhline(y=0, color='black', linestyle='--', lw=1, alpha=0.5)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Time step' ,  fontsize=18)\n",
    "    plt.ylabel('Price' , fontsize=18)\n",
    "    plt.title(title, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eeacbf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zones = ['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'LONGIL',\n",
    "        'MHK VL', 'MILLWD', 'N.Y.C.', 'NORTH', 'WEST']\n",
    "# zone = 'N.Y.C.'\n",
    "year = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6a2ff2",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f734c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 12, 32)            320       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 6, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 6, 32)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                12352     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,336\n",
      "Trainable params: 17,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.9335 - val_loss: 0.2834\n",
      "Epoch 2/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6994 - val_loss: 0.2303\n",
      "Epoch 3/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6366 - val_loss: 0.2206\n",
      "Epoch 4/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6244 - val_loss: 0.2154\n",
      "Epoch 5/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6135 - val_loss: 0.2132\n",
      "Epoch 6/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6079 - val_loss: 0.2110\n",
      "Epoch 7/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6033 - val_loss: 0.2099\n",
      "Epoch 8/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5987 - val_loss: 0.2086\n",
      "Epoch 9/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5956 - val_loss: 0.2080\n",
      "Epoch 10/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5926 - val_loss: 0.2070\n",
      "Epoch 11/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5900 - val_loss: 0.2068\n",
      "Epoch 12/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5875 - val_loss: 0.2061\n",
      "Epoch 13/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5854 - val_loss: 0.2060\n",
      "Epoch 14/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5834 - val_loss: 0.2054\n",
      "Epoch 15/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5815 - val_loss: 0.2053\n",
      "Epoch 16/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5797 - val_loss: 0.2050\n",
      "Epoch 17/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5780 - val_loss: 0.2047\n",
      "Epoch 18/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5765 - val_loss: 0.2046\n",
      "Epoch 19/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5751 - val_loss: 0.2045\n",
      "Epoch 20/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5739 - val_loss: 0.2043\n",
      "Epoch 21/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5727 - val_loss: 0.2041\n",
      "Epoch 22/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5715 - val_loss: 0.2042\n",
      "Epoch 23/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5705 - val_loss: 0.2039\n",
      "Epoch 24/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5696 - val_loss: 0.2040\n",
      "Epoch 25/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5686 - val_loss: 0.2038\n",
      "Epoch 26/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5678 - val_loss: 0.2037\n",
      "Epoch 27/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.5670 - val_loss: 0.2036\n",
      "Epoch 28/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.5661 - val_loss: 0.2035\n",
      "Epoch 29/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.5655 - val_loss: 0.2034\n",
      "Epoch 30/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.5647 - val_loss: 0.2034\n",
      "Epoch 31/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5640 - val_loss: 0.2033\n",
      "Epoch 32/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5630 - val_loss: 0.2033\n",
      "Epoch 33/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5625 - val_loss: 0.2032\n",
      "Epoch 34/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5617 - val_loss: 0.2032\n",
      "Epoch 35/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5611 - val_loss: 0.2031\n",
      "Epoch 36/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5603 - val_loss: 0.2031\n",
      "Epoch 37/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5598 - val_loss: 0.2030\n",
      "Epoch 38/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5591 - val_loss: 0.2031\n",
      "Epoch 39/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5585 - val_loss: 0.2030\n",
      "Epoch 40/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5578 - val_loss: 0.2030\n",
      "Epoch 41/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5572 - val_loss: 0.2030\n",
      "Epoch 42/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5565 - val_loss: 0.2029\n",
      "Epoch 43/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5560 - val_loss: 0.2029\n",
      "Epoch 44/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5554 - val_loss: 0.2029\n",
      "Epoch 45/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5549 - val_loss: 0.2028\n",
      "Epoch 46/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5543 - val_loss: 0.2029\n",
      "Epoch 47/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5537 - val_loss: 0.2028\n",
      "Epoch 48/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5531 - val_loss: 0.2029\n",
      "Epoch 49/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5526 - val_loss: 0.2028\n",
      "Epoch 50/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5520 - val_loss: 0.2029\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 12, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 12, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.9322 - val_loss: 0.2627\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6991 - val_loss: 0.2344\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6380 - val_loss: 0.2258\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6271 - val_loss: 0.2205\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6147 - val_loss: 0.2186\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6066 - val_loss: 0.2155\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6021 - val_loss: 0.2135\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5978 - val_loss: 0.2123\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5932 - val_loss: 0.2110\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5902 - val_loss: 0.2100\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5868 - val_loss: 0.2093\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5844 - val_loss: 0.2088\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5814 - val_loss: 0.2083\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5797 - val_loss: 0.2079\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5773 - val_loss: 0.2077\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5760 - val_loss: 0.2073\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5738 - val_loss: 0.2072\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5726 - val_loss: 0.2069\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5705 - val_loss: 0.2069\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5695 - val_loss: 0.2066\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5675 - val_loss: 0.2067\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5667 - val_loss: 0.2064\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5646 - val_loss: 0.2065\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5639 - val_loss: 0.2063\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5622 - val_loss: 0.2064\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5615 - val_loss: 0.2062\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5598 - val_loss: 0.2061\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5591 - val_loss: 0.2062\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5576 - val_loss: 0.2062\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5569 - val_loss: 0.2063\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5555 - val_loss: 0.2061\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5547 - val_loss: 0.2064\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5533 - val_loss: 0.2062\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5526 - val_loss: 0.2066\n",
      "Epoch 35/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5514 - val_loss: 0.2062\n",
      "Epoch 36/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5506 - val_loss: 0.2069\n",
      "Epoch 37/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5495 - val_loss: 0.2064\n",
      "Epoch 38/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5486 - val_loss: 0.2073\n",
      "Epoch 39/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5476 - val_loss: 0.2065\n",
      "Epoch 40/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5469 - val_loss: 0.2076\n",
      "Epoch 41/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5456 - val_loss: 0.2068\n",
      "Epoch 42/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5450 - val_loss: 0.2077\n",
      "Epoch 43/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5440 - val_loss: 0.2072\n",
      "Epoch 44/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5431 - val_loss: 0.2079\n",
      "Epoch 45/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5422 - val_loss: 0.2074\n",
      "Epoch 46/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5415 - val_loss: 0.2082\n",
      "Epoch 47/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5405 - val_loss: 0.2075\n",
      "Epoch 48/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5399 - val_loss: 0.2085\n",
      "Epoch 49/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5390 - val_loss: 0.2075\n",
      "Epoch 50/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5385 - val_loss: 0.2083\n",
      "(34969, 72, 3) (34969, 24, 1) (8665, 72, 3) (8665, 24, 1)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 9, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 288)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 9, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 288)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.8846 - val_loss: 0.2513\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8194 - val_loss: 0.2475\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7756 - val_loss: 0.2225\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7386 - val_loss: 0.2364\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7301 - val_loss: 0.2345\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7154 - val_loss: 0.2420\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7018 - val_loss: 0.2491\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6886 - val_loss: 0.2350\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7268 - val_loss: 0.2369\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6471 - val_loss: 0.2259\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6696 - val_loss: 0.2483\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6577 - val_loss: 0.2468\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6451 - val_loss: 0.2550\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6886 - val_loss: 0.2324\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6471 - val_loss: 0.2761\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6627 - val_loss: 0.2312\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6953 - val_loss: 0.2380\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6465 - val_loss: 0.2318\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6454 - val_loss: 0.2645\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6647 - val_loss: 0.2450\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6331 - val_loss: 0.2762\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6364 - val_loss: 0.2647\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6509 - val_loss: 0.2646\n",
      "273/273 [==============================] - 0s 1ms/step\n",
      "272/272 [==============================] - 0s 2ms/step\n",
      "271/271 [==============================] - 1s 2ms/step\n",
      "CAPITL\n",
      "24h MAE: 0.4735\n",
      "48h MAE: 0.4724\n",
      "72h MAE: 0.5590\n",
      "\n",
      "CAPITL\n",
      "24h MAE: 11.9279\n",
      "48h MAE: 11.9008\n",
      "72h MAE: 13.9056\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 12, 32)            320       \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 6, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 6, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                12352     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,336\n",
      "Trainable params: 17,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 1.0195 - val_loss: 0.2960\n",
      "Epoch 2/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8491 - val_loss: 0.2655\n",
      "Epoch 3/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7766 - val_loss: 0.2580\n",
      "Epoch 4/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7498 - val_loss: 0.2541\n",
      "Epoch 5/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7369 - val_loss: 0.2511\n",
      "Epoch 6/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7282 - val_loss: 0.2487\n",
      "Epoch 7/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7221 - val_loss: 0.2469\n",
      "Epoch 8/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7171 - val_loss: 0.2455\n",
      "Epoch 9/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7129 - val_loss: 0.2444\n",
      "Epoch 10/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7095 - val_loss: 0.2435\n",
      "Epoch 11/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7065 - val_loss: 0.2428\n",
      "Epoch 12/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7039 - val_loss: 0.2422\n",
      "Epoch 13/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7016 - val_loss: 0.2417\n",
      "Epoch 14/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6994 - val_loss: 0.2413\n",
      "Epoch 15/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6974 - val_loss: 0.2410\n",
      "Epoch 16/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6956 - val_loss: 0.2407\n",
      "Epoch 17/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.6938 - val_loss: 0.2405\n",
      "Epoch 18/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6923 - val_loss: 0.2402\n",
      "Epoch 19/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6908 - val_loss: 0.2401\n",
      "Epoch 20/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6893 - val_loss: 0.2398\n",
      "Epoch 21/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6879 - val_loss: 0.2396\n",
      "Epoch 22/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6866 - val_loss: 0.2393\n",
      "Epoch 23/50\n",
      "876/876 [==============================] - 5s 6ms/step - loss: 0.6855 - val_loss: 0.2391\n",
      "Epoch 24/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6843 - val_loss: 0.2389\n",
      "Epoch 25/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.6832 - val_loss: 0.2387\n",
      "Epoch 26/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6821 - val_loss: 0.2385\n",
      "Epoch 27/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6811 - val_loss: 0.2383\n",
      "Epoch 28/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6802 - val_loss: 0.2381\n",
      "Epoch 29/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6792 - val_loss: 0.2380\n",
      "Epoch 30/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6784 - val_loss: 0.2378\n",
      "Epoch 31/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6775 - val_loss: 0.2376\n",
      "Epoch 32/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6766 - val_loss: 0.2375\n",
      "Epoch 33/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6758 - val_loss: 0.2374\n",
      "Epoch 34/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6750 - val_loss: 0.2373\n",
      "Epoch 35/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6741 - val_loss: 0.2371\n",
      "Epoch 36/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6734 - val_loss: 0.2369\n",
      "Epoch 37/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6725 - val_loss: 0.2367\n",
      "Epoch 38/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6719 - val_loss: 0.2365\n",
      "Epoch 39/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6711 - val_loss: 0.2363\n",
      "Epoch 40/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6704 - val_loss: 0.2362\n",
      "Epoch 41/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6697 - val_loss: 0.2361\n",
      "Epoch 42/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6690 - val_loss: 0.2359\n",
      "Epoch 43/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6683 - val_loss: 0.2358\n",
      "Epoch 44/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6677 - val_loss: 0.2356\n",
      "Epoch 45/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6670 - val_loss: 0.2355\n",
      "Epoch 46/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6664 - val_loss: 0.2353\n",
      "Epoch 47/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6657 - val_loss: 0.2352\n",
      "Epoch 48/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6651 - val_loss: 0.2350\n",
      "Epoch 49/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6645 - val_loss: 0.2349\n",
      "Epoch 50/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6639 - val_loss: 0.2348\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 12, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 12, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.9779 - val_loss: 0.2775\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8350 - val_loss: 0.2600\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7776 - val_loss: 0.2541\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.7550 - val_loss: 0.2510\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7427 - val_loss: 0.2492\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7341 - val_loss: 0.2478\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7276 - val_loss: 0.2470\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7222 - val_loss: 0.2461\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7178 - val_loss: 0.2453\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7138 - val_loss: 0.2446\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7102 - val_loss: 0.2438\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7068 - val_loss: 0.2431\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7038 - val_loss: 0.2424\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7009 - val_loss: 0.2418\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6983 - val_loss: 0.2412\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6959 - val_loss: 0.2407\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6939 - val_loss: 0.2403\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6917 - val_loss: 0.2399\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6898 - val_loss: 0.2396\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6876 - val_loss: 0.2392\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6861 - val_loss: 0.2389\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6842 - val_loss: 0.2386\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6828 - val_loss: 0.2383\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6809 - val_loss: 0.2380\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6800 - val_loss: 0.2379\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6781 - val_loss: 0.2376\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6771 - val_loss: 0.2375\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6756 - val_loss: 0.2373\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6743 - val_loss: 0.2372\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6730 - val_loss: 0.2371\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6719 - val_loss: 0.2369\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6707 - val_loss: 0.2367\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6695 - val_loss: 0.2366\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6684 - val_loss: 0.2364\n",
      "Epoch 35/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6675 - val_loss: 0.2363\n",
      "Epoch 36/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6661 - val_loss: 0.2362\n",
      "Epoch 37/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6653 - val_loss: 0.2361\n",
      "Epoch 38/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6640 - val_loss: 0.2359\n",
      "Epoch 39/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6632 - val_loss: 0.2358\n",
      "Epoch 40/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6620 - val_loss: 0.2357\n",
      "Epoch 41/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6611 - val_loss: 0.2356\n",
      "Epoch 42/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6600 - val_loss: 0.2355\n",
      "Epoch 43/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6593 - val_loss: 0.2355\n",
      "Epoch 44/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6581 - val_loss: 0.2354\n",
      "Epoch 45/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6573 - val_loss: 0.2354\n",
      "Epoch 46/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6561 - val_loss: 0.2352\n",
      "Epoch 47/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6555 - val_loss: 0.2352\n",
      "Epoch 48/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6541 - val_loss: 0.2351\n",
      "Epoch 49/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6535 - val_loss: 0.2351\n",
      "Epoch 50/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6523 - val_loss: 0.2350\n",
      "(34969, 72, 3) (34969, 24, 1) (8665, 72, 3) (8665, 24, 1)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_10 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 9, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 288)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_10 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 9, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 288)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.9189 - val_loss: 0.2504\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8604 - val_loss: 0.2443\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8447 - val_loss: 0.2439\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8346 - val_loss: 0.2459\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8155 - val_loss: 0.2514\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8742 - val_loss: 0.2519\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.8418 - val_loss: 0.2489\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8135 - val_loss: 0.2475\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.8118 - val_loss: 0.2514\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7686 - val_loss: 0.2498\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.7685 - val_loss: 0.2499\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7680 - val_loss: 0.2544\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7548 - val_loss: 0.2516\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7684 - val_loss: 0.2537\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7632 - val_loss: 0.2540\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7585 - val_loss: 0.2517\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7518 - val_loss: 0.2564\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7694 - val_loss: 0.2489\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7520 - val_loss: 0.2481\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7331 - val_loss: 0.2491\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7508 - val_loss: 0.2492\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7454 - val_loss: 0.2468\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7504 - val_loss: 0.2495\n",
      "273/273 [==============================] - 0s 1ms/step\n",
      "272/272 [==============================] - 0s 1ms/step\n",
      "271/271 [==============================] - 1s 2ms/step\n",
      "CENTRL\n",
      "24h MAE: 0.4908\n",
      "48h MAE: 0.4944\n",
      "72h MAE: 0.5600\n",
      "\n",
      "CENTRL\n",
      "24h MAE: 9.6811\n",
      "48h MAE: 9.7542\n",
      "72h MAE: 11.0742\n",
      "\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_12 (Conv1D)          (None, 12, 32)            320       \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 6, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 6, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                12352     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,336\n",
      "Trainable params: 17,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.9945 - val_loss: 0.2861\n",
      "Epoch 2/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7465 - val_loss: 0.2138\n",
      "Epoch 3/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6712 - val_loss: 0.2052\n",
      "Epoch 4/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6565 - val_loss: 0.2014\n",
      "Epoch 5/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6453 - val_loss: 0.1984\n",
      "Epoch 6/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6380 - val_loss: 0.1964\n",
      "Epoch 7/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6309 - val_loss: 0.1945\n",
      "Epoch 8/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6257 - val_loss: 0.1932\n",
      "Epoch 9/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6206 - val_loss: 0.1922\n",
      "Epoch 10/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6166 - val_loss: 0.1915\n",
      "Epoch 11/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6125 - val_loss: 0.1908\n",
      "Epoch 12/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6094 - val_loss: 0.1903\n",
      "Epoch 13/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6062 - val_loss: 0.1901\n",
      "Epoch 14/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.6037 - val_loss: 0.1897\n",
      "Epoch 15/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6014 - val_loss: 0.1897\n",
      "Epoch 16/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.5995 - val_loss: 0.1894\n",
      "Epoch 17/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.5978 - val_loss: 0.1894\n",
      "Epoch 18/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5962 - val_loss: 0.1893\n",
      "Epoch 19/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5947 - val_loss: 0.1892\n",
      "Epoch 20/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5932 - val_loss: 0.1892\n",
      "Epoch 21/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5919 - val_loss: 0.1892\n",
      "Epoch 22/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5907 - val_loss: 0.1891\n",
      "Epoch 23/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5894 - val_loss: 0.1891\n",
      "Epoch 24/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5882 - val_loss: 0.1891\n",
      "Epoch 25/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5870 - val_loss: 0.1891\n",
      "Epoch 26/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5859 - val_loss: 0.1891\n",
      "Epoch 27/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5848 - val_loss: 0.1891\n",
      "Epoch 28/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5838 - val_loss: 0.1891\n",
      "Epoch 29/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5828 - val_loss: 0.1891\n",
      "Epoch 30/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.5818 - val_loss: 0.1892\n",
      "Epoch 31/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5809 - val_loss: 0.1892\n",
      "Epoch 32/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5800 - val_loss: 0.1893\n",
      "Epoch 33/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5792 - val_loss: 0.1893\n",
      "Epoch 34/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5783 - val_loss: 0.1892\n",
      "Epoch 35/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5776 - val_loss: 0.1893\n",
      "Epoch 36/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5767 - val_loss: 0.1893\n",
      "Epoch 37/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5760 - val_loss: 0.1893\n",
      "Epoch 38/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5753 - val_loss: 0.1894\n",
      "Epoch 39/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5745 - val_loss: 0.1893\n",
      "Epoch 40/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5738 - val_loss: 0.1893\n",
      "Epoch 41/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5731 - val_loss: 0.1893\n",
      "Epoch 42/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5724 - val_loss: 0.1893\n",
      "Epoch 43/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5718 - val_loss: 0.1892\n",
      "Epoch 44/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5711 - val_loss: 0.1893\n",
      "Epoch 45/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5705 - val_loss: 0.1892\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_14 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 12, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_14 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 12, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.9586 - val_loss: 0.2711\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7252 - val_loss: 0.2189\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6682 - val_loss: 0.2084\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6535 - val_loss: 0.2023\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6436 - val_loss: 0.1989\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6354 - val_loss: 0.1968\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6292 - val_loss: 0.1953\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6256 - val_loss: 0.1941\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6211 - val_loss: 0.1932\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6176 - val_loss: 0.1924\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6139 - val_loss: 0.1918\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6108 - val_loss: 0.1913\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6080 - val_loss: 0.1909\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6057 - val_loss: 0.1907\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6038 - val_loss: 0.1903\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6018 - val_loss: 0.1901\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5998 - val_loss: 0.1898\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5976 - val_loss: 0.1898\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5961 - val_loss: 0.1895\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5942 - val_loss: 0.1895\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5928 - val_loss: 0.1893\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5911 - val_loss: 0.1893\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5900 - val_loss: 0.1890\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5886 - val_loss: 0.1889\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5870 - val_loss: 0.1887\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5854 - val_loss: 0.1887\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5843 - val_loss: 0.1885\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5828 - val_loss: 0.1886\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5817 - val_loss: 0.1884\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5803 - val_loss: 0.1885\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.5791 - val_loss: 0.1884\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5777 - val_loss: 0.1884\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5768 - val_loss: 0.1883\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5754 - val_loss: 0.1884\n",
      "Epoch 35/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5743 - val_loss: 0.1884\n",
      "Epoch 36/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5732 - val_loss: 0.1884\n",
      "Epoch 37/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5721 - val_loss: 0.1885\n",
      "Epoch 38/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5710 - val_loss: 0.1885\n",
      "Epoch 39/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5698 - val_loss: 0.1885\n",
      "Epoch 40/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5690 - val_loss: 0.1885\n",
      "Epoch 41/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5680 - val_loss: 0.1885\n",
      "Epoch 42/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5670 - val_loss: 0.1886\n",
      "Epoch 43/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5660 - val_loss: 0.1886\n",
      "Epoch 44/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5649 - val_loss: 0.1887\n",
      "Epoch 45/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5640 - val_loss: 0.1887\n",
      "Epoch 46/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5632 - val_loss: 0.1888\n",
      "Epoch 47/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5622 - val_loss: 0.1888\n",
      "Epoch 48/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5613 - val_loss: 0.1889\n",
      "Epoch 49/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5604 - val_loss: 0.1890\n",
      "Epoch 50/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5596 - val_loss: 0.1891\n",
      "(34969, 72, 3) (34969, 24, 1) (8665, 72, 3) (8665, 24, 1)\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_16 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 9, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 288)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_16 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 9, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 288)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.8559 - val_loss: 0.2047\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7911 - val_loss: 0.1981\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7423 - val_loss: 0.1917\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7072 - val_loss: 0.1874\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7106 - val_loss: 0.2143\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7317 - val_loss: 0.2145\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7796 - val_loss: 0.1996\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6958 - val_loss: 0.1953\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.7503 - val_loss: 0.2018\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.6789 - val_loss: 0.1913\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6675 - val_loss: 0.1877\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6484 - val_loss: 0.1911\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6376 - val_loss: 0.1851\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6430 - val_loss: 0.1898\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6426 - val_loss: 0.1884\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6552 - val_loss: 0.1964\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6434 - val_loss: 0.1931\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7218 - val_loss: 0.2051\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6693 - val_loss: 0.1940\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6471 - val_loss: 0.1947\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6414 - val_loss: 0.1938\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6572 - val_loss: 0.1962\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6490 - val_loss: 0.1982\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6380 - val_loss: 0.2062\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6591 - val_loss: 0.2124\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6266 - val_loss: 0.2024\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6230 - val_loss: 0.2017\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6488 - val_loss: 0.2046\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6335 - val_loss: 0.2053\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6451 - val_loss: 0.1986\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6506 - val_loss: 0.2116\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6387 - val_loss: 0.2155\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6342 - val_loss: 0.2196\n",
      "273/273 [==============================] - 1s 2ms/step\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "271/271 [==============================] - 1s 2ms/step\n",
      "DUNWOD\n",
      "24h MAE: 0.4055\n",
      "48h MAE: 0.4170\n",
      "72h MAE: 0.4673\n",
      "\n",
      "DUNWOD\n",
      "24h MAE: 9.8439\n",
      "48h MAE: 10.1006\n",
      "72h MAE: 11.2262\n",
      "\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_18 (Conv1D)          (None, 12, 32)            320       \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 6, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 6, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                12352     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,336\n",
      "Trainable params: 17,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 1.0105 - val_loss: 0.3711\n",
      "Epoch 2/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.8529 - val_loss: 0.3403\n",
      "Epoch 3/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7824 - val_loss: 0.3316\n",
      "Epoch 4/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.7544 - val_loss: 0.3267\n",
      "Epoch 5/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7412 - val_loss: 0.3234\n",
      "Epoch 6/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7326 - val_loss: 0.3209\n",
      "Epoch 7/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7260 - val_loss: 0.3189\n",
      "Epoch 8/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7207 - val_loss: 0.3172\n",
      "Epoch 9/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7158 - val_loss: 0.3160\n",
      "Epoch 10/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7115 - val_loss: 0.3149\n",
      "Epoch 11/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7080 - val_loss: 0.3139\n",
      "Epoch 12/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7048 - val_loss: 0.3131\n",
      "Epoch 13/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7020 - val_loss: 0.3124\n",
      "Epoch 14/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6999 - val_loss: 0.3117\n",
      "Epoch 15/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6977 - val_loss: 0.3111\n",
      "Epoch 16/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6958 - val_loss: 0.3105\n",
      "Epoch 17/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6941 - val_loss: 0.3100\n",
      "Epoch 18/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6923 - val_loss: 0.3096\n",
      "Epoch 19/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6908 - val_loss: 0.3092\n",
      "Epoch 20/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6895 - val_loss: 0.3087\n",
      "Epoch 21/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6880 - val_loss: 0.3083\n",
      "Epoch 22/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6870 - val_loss: 0.3079\n",
      "Epoch 23/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6853 - val_loss: 0.3077\n",
      "Epoch 24/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6844 - val_loss: 0.3072\n",
      "Epoch 25/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6830 - val_loss: 0.3070\n",
      "Epoch 26/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6822 - val_loss: 0.3066\n",
      "Epoch 27/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6807 - val_loss: 0.3065\n",
      "Epoch 28/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6801 - val_loss: 0.3061\n",
      "Epoch 29/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6788 - val_loss: 0.3060\n",
      "Epoch 30/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6781 - val_loss: 0.3057\n",
      "Epoch 31/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6767 - val_loss: 0.3056\n",
      "Epoch 32/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6762 - val_loss: 0.3053\n",
      "Epoch 33/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.6748 - val_loss: 0.3053\n",
      "Epoch 34/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6744 - val_loss: 0.3050\n",
      "Epoch 35/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.6728 - val_loss: 0.3050\n",
      "Epoch 36/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6725 - val_loss: 0.3048\n",
      "Epoch 37/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6710 - val_loss: 0.3048\n",
      "Epoch 38/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6709 - val_loss: 0.3045\n",
      "Epoch 39/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6692 - val_loss: 0.3045\n",
      "Epoch 40/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6692 - val_loss: 0.3043\n",
      "Epoch 41/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6675 - val_loss: 0.3043\n",
      "Epoch 42/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6674 - val_loss: 0.3041\n",
      "Epoch 43/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6659 - val_loss: 0.3042\n",
      "Epoch 44/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6657 - val_loss: 0.3039\n",
      "Epoch 45/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6644 - val_loss: 0.3040\n",
      "Epoch 46/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6640 - val_loss: 0.3038\n",
      "Epoch 47/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6627 - val_loss: 0.3040\n",
      "Epoch 48/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6625 - val_loss: 0.3038\n",
      "Epoch 49/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6611 - val_loss: 0.3039\n",
      "Epoch 50/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6610 - val_loss: 0.3037\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_20 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_20 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.9688 - val_loss: 0.3634\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8209 - val_loss: 0.3400\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7710 - val_loss: 0.3301\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7496 - val_loss: 0.3242\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7369 - val_loss: 0.3208\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7283 - val_loss: 0.3183\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7216 - val_loss: 0.3166\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7166 - val_loss: 0.3153\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7121 - val_loss: 0.3143\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7083 - val_loss: 0.3135\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7050 - val_loss: 0.3127\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7018 - val_loss: 0.3122\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6991 - val_loss: 0.3116\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6964 - val_loss: 0.3111\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6943 - val_loss: 0.3106\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6920 - val_loss: 0.3103\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6901 - val_loss: 0.3099\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6882 - val_loss: 0.3096\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6865 - val_loss: 0.3092\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6847 - val_loss: 0.3090\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6832 - val_loss: 0.3087\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6816 - val_loss: 0.3084\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6801 - val_loss: 0.3082\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6787 - val_loss: 0.3080\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6772 - val_loss: 0.3078\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6758 - val_loss: 0.3076\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6745 - val_loss: 0.3074\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6732 - val_loss: 0.3073\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6719 - val_loss: 0.3072\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6708 - val_loss: 0.3070\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6694 - val_loss: 0.3069\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6683 - val_loss: 0.3067\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6670 - val_loss: 0.3067\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6660 - val_loss: 0.3065\n",
      "Epoch 35/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6647 - val_loss: 0.3065\n",
      "Epoch 36/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6638 - val_loss: 0.3064\n",
      "Epoch 37/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6624 - val_loss: 0.3064\n",
      "Epoch 38/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6615 - val_loss: 0.3062\n",
      "Epoch 39/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6604 - val_loss: 0.3062\n",
      "Epoch 40/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6593 - val_loss: 0.3062\n",
      "Epoch 41/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6582 - val_loss: 0.3061\n",
      "Epoch 42/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6571 - val_loss: 0.3061\n",
      "Epoch 43/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6561 - val_loss: 0.3061\n",
      "Epoch 44/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6550 - val_loss: 0.3060\n",
      "Epoch 45/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6539 - val_loss: 0.3061\n",
      "Epoch 46/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6532 - val_loss: 0.3059\n",
      "Epoch 47/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6516 - val_loss: 0.3062\n",
      "Epoch 48/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6521 - val_loss: 0.3057\n",
      "Epoch 49/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6492 - val_loss: 0.3061\n",
      "Epoch 50/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6505 - val_loss: 0.3056\n",
      "(34969, 72, 3) (34969, 24, 1) (8665, 72, 3) (8665, 24, 1)\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_22 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_22 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.8986 - val_loss: 0.3286\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8666 - val_loss: 0.3240\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8330 - val_loss: 0.3167\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8170 - val_loss: 0.3178\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8193 - val_loss: 0.3236\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8350 - val_loss: 0.3178\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7899 - val_loss: 0.3160\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7672 - val_loss: 0.3168\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7631 - val_loss: 0.3156\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7540 - val_loss: 0.3124\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7383 - val_loss: 0.3129\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7462 - val_loss: 0.3135\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7358 - val_loss: 0.3118\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7379 - val_loss: 0.3150\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7337 - val_loss: 0.3150\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7525 - val_loss: 0.3146\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7371 - val_loss: 0.3223\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7275 - val_loss: 0.3158\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.7287 - val_loss: 0.3188\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7088 - val_loss: 0.3137\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.7124 - val_loss: 0.3180\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7313 - val_loss: 0.3146\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7304 - val_loss: 0.3162\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7439 - val_loss: 0.3208\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7323 - val_loss: 0.3183\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7292 - val_loss: 0.3217\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7150 - val_loss: 0.3158\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7352 - val_loss: 0.3212\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7223 - val_loss: 0.3184\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7421 - val_loss: 0.3196\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7432 - val_loss: 0.3172\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7847 - val_loss: 0.3272\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7884 - val_loss: 0.3216\n",
      "273/273 [==============================] - 0s 1ms/step\n",
      "272/272 [==============================] - 0s 1ms/step\n",
      "271/271 [==============================] - 1s 2ms/step\n",
      "GENESE\n",
      "24h MAE: 0.4902\n",
      "48h MAE: 0.4991\n",
      "72h MAE: 0.5600\n",
      "\n",
      "GENESE\n",
      "24h MAE: 9.4703\n",
      "48h MAE: 9.6315\n",
      "72h MAE: 10.8587\n",
      "\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_24 (Conv1D)          (None, 12, 32)            320       \n",
      "                                                                 \n",
      " conv1d_25 (Conv1D)          (None, 6, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 64)                12352     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,336\n",
      "Trainable params: 17,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 1.0061 - val_loss: 0.2068\n",
      "Epoch 2/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7911 - val_loss: 0.1773\n",
      "Epoch 3/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7167 - val_loss: 0.1715\n",
      "Epoch 4/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7010 - val_loss: 0.1695\n",
      "Epoch 5/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6926 - val_loss: 0.1678\n",
      "Epoch 6/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6865 - val_loss: 0.1669\n",
      "Epoch 7/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6822 - val_loss: 0.1655\n",
      "Epoch 8/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6781 - val_loss: 0.1648\n",
      "Epoch 9/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6745 - val_loss: 0.1639\n",
      "Epoch 10/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6715 - val_loss: 0.1634\n",
      "Epoch 11/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6691 - val_loss: 0.1627\n",
      "Epoch 12/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6666 - val_loss: 0.1622\n",
      "Epoch 13/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6646 - val_loss: 0.1618\n",
      "Epoch 14/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6624 - val_loss: 0.1614\n",
      "Epoch 15/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.6608 - val_loss: 0.1613\n",
      "Epoch 16/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6590 - val_loss: 0.1610\n",
      "Epoch 17/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.6576 - val_loss: 0.1608\n",
      "Epoch 18/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6561 - val_loss: 0.1605\n",
      "Epoch 19/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6549 - val_loss: 0.1605\n",
      "Epoch 20/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6537 - val_loss: 0.1601\n",
      "Epoch 21/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6524 - val_loss: 0.1602\n",
      "Epoch 22/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6513 - val_loss: 0.1597\n",
      "Epoch 23/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6501 - val_loss: 0.1599\n",
      "Epoch 24/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6492 - val_loss: 0.1595\n",
      "Epoch 25/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6482 - val_loss: 0.1596\n",
      "Epoch 26/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6473 - val_loss: 0.1593\n",
      "Epoch 27/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6463 - val_loss: 0.1594\n",
      "Epoch 28/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6454 - val_loss: 0.1591\n",
      "Epoch 29/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6446 - val_loss: 0.1592\n",
      "Epoch 30/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6439 - val_loss: 0.1589\n",
      "Epoch 31/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6430 - val_loss: 0.1590\n",
      "Epoch 32/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6423 - val_loss: 0.1588\n",
      "Epoch 33/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6415 - val_loss: 0.1589\n",
      "Epoch 34/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6408 - val_loss: 0.1587\n",
      "Epoch 35/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6401 - val_loss: 0.1588\n",
      "Epoch 36/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6395 - val_loss: 0.1586\n",
      "Epoch 37/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6388 - val_loss: 0.1587\n",
      "Epoch 38/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6382 - val_loss: 0.1585\n",
      "Epoch 39/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6376 - val_loss: 0.1587\n",
      "Epoch 40/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6369 - val_loss: 0.1584\n",
      "Epoch 41/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6363 - val_loss: 0.1586\n",
      "Epoch 42/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6358 - val_loss: 0.1584\n",
      "Epoch 43/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6351 - val_loss: 0.1585\n",
      "Epoch 44/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6346 - val_loss: 0.1584\n",
      "Epoch 45/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6340 - val_loss: 0.1586\n",
      "Epoch 46/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6335 - val_loss: 0.1585\n",
      "Epoch 47/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6329 - val_loss: 0.1586\n",
      "Epoch 48/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6324 - val_loss: 0.1586\n",
      "Epoch 49/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6319 - val_loss: 0.1586\n",
      "Epoch 50/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6315 - val_loss: 0.1586\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_26 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_27 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_26 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_27 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 1.0235 - val_loss: 0.2112\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.8224 - val_loss: 0.1834\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7381 - val_loss: 0.1746\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7140 - val_loss: 0.1709\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7023 - val_loss: 0.1685\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6938 - val_loss: 0.1674\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6879 - val_loss: 0.1661\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6831 - val_loss: 0.1655\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6787 - val_loss: 0.1647\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6755 - val_loss: 0.1642\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6721 - val_loss: 0.1637\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6696 - val_loss: 0.1636\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6668 - val_loss: 0.1629\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6650 - val_loss: 0.1628\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6627 - val_loss: 0.1624\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6608 - val_loss: 0.1622\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6590 - val_loss: 0.1619\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6573 - val_loss: 0.1619\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6555 - val_loss: 0.1616\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6540 - val_loss: 0.1616\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6524 - val_loss: 0.1614\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6510 - val_loss: 0.1614\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6497 - val_loss: 0.1613\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6483 - val_loss: 0.1613\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6469 - val_loss: 0.1612\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6458 - val_loss: 0.1612\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6445 - val_loss: 0.1610\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6435 - val_loss: 0.1611\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6424 - val_loss: 0.1610\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6413 - val_loss: 0.1611\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6403 - val_loss: 0.1610\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6393 - val_loss: 0.1611\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6383 - val_loss: 0.1611\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6372 - val_loss: 0.1611\n",
      "Epoch 35/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6363 - val_loss: 0.1611\n",
      "Epoch 36/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6354 - val_loss: 0.1611\n",
      "Epoch 37/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6345 - val_loss: 0.1612\n",
      "Epoch 38/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6335 - val_loss: 0.1612\n",
      "Epoch 39/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6327 - val_loss: 0.1612\n",
      "Epoch 40/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6318 - val_loss: 0.1613\n",
      "Epoch 41/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6308 - val_loss: 0.1614\n",
      "Epoch 42/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6300 - val_loss: 0.1614\n",
      "Epoch 43/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6290 - val_loss: 0.1615\n",
      "Epoch 44/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6283 - val_loss: 0.1616\n",
      "Epoch 45/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6274 - val_loss: 0.1616\n",
      "Epoch 46/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6266 - val_loss: 0.1617\n",
      "Epoch 47/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6257 - val_loss: 0.1618\n",
      "Epoch 48/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6249 - val_loss: 0.1618\n",
      "Epoch 49/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6241 - val_loss: 0.1619\n",
      "(34969, 72, 3) (34969, 24, 1) (8665, 72, 3) (8665, 24, 1)\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_28 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_28 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.9116 - val_loss: 0.1952\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8627 - val_loss: 0.1746\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8326 - val_loss: 0.1713\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8085 - val_loss: 0.1955\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8357 - val_loss: 0.1927\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8760 - val_loss: 0.1674\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7973 - val_loss: 0.1735\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8076 - val_loss: 0.1769\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.7770 - val_loss: 0.1750\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7958 - val_loss: 0.1743\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.7664 - val_loss: 0.1744\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.8140 - val_loss: 0.1738\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8234 - val_loss: 0.1717\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7472 - val_loss: 0.1838\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7868 - val_loss: 0.1900\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8952 - val_loss: 0.1829\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8494 - val_loss: 0.1783\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7899 - val_loss: 0.1754\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7780 - val_loss: 0.1889\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7450 - val_loss: 0.1749\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7218 - val_loss: 0.1718\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7511 - val_loss: 0.1697\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7148 - val_loss: 0.1749\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7509 - val_loss: 0.1813\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7663 - val_loss: 0.1808\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7014 - val_loss: 0.1754\n",
      "273/273 [==============================] - 0s 1ms/step\n",
      "272/272 [==============================] - 0s 1ms/step\n",
      "271/271 [==============================] - 1s 2ms/step\n",
      "HUD VL\n",
      "24h MAE: 0.3725\n",
      "48h MAE: 0.3712\n",
      "72h MAE: 0.4272\n",
      "\n",
      "HUD VL\n",
      "24h MAE: 9.3869\n",
      "48h MAE: 9.3512\n",
      "72h MAE: 10.6918\n",
      "\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_30 (Conv1D)          (None, 12, 32)            320       \n",
      "                                                                 \n",
      " conv1d_31 (Conv1D)          (None, 6, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 64)                12352     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,336\n",
      "Trainable params: 17,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.9551 - val_loss: 0.5332\n",
      "Epoch 2/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.8000 - val_loss: 0.4888\n",
      "Epoch 3/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7507 - val_loss: 0.4791\n",
      "Epoch 4/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7365 - val_loss: 0.4741\n",
      "Epoch 5/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7279 - val_loss: 0.4707\n",
      "Epoch 6/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7219 - val_loss: 0.4681\n",
      "Epoch 7/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7172 - val_loss: 0.4660\n",
      "Epoch 8/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7135 - val_loss: 0.4643\n",
      "Epoch 9/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7103 - val_loss: 0.4629\n",
      "Epoch 10/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.7075 - val_loss: 0.4617\n",
      "Epoch 11/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.7052 - val_loss: 0.4606\n",
      "Epoch 12/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.7030 - val_loss: 0.4596\n",
      "Epoch 13/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.7011 - val_loss: 0.4587\n",
      "Epoch 14/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6992 - val_loss: 0.4579\n",
      "Epoch 15/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6975 - val_loss: 0.4572\n",
      "Epoch 16/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6959 - val_loss: 0.4565\n",
      "Epoch 17/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6944 - val_loss: 0.4559\n",
      "Epoch 18/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6930 - val_loss: 0.4554\n",
      "Epoch 19/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6916 - val_loss: 0.4549\n",
      "Epoch 20/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6903 - val_loss: 0.4544\n",
      "Epoch 21/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6891 - val_loss: 0.4540\n",
      "Epoch 22/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6880 - val_loss: 0.4536\n",
      "Epoch 23/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6868 - val_loss: 0.4531\n",
      "Epoch 24/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6857 - val_loss: 0.4527\n",
      "Epoch 25/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6847 - val_loss: 0.4523\n",
      "Epoch 26/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6837 - val_loss: 0.4520\n",
      "Epoch 27/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6828 - val_loss: 0.4515\n",
      "Epoch 28/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6819 - val_loss: 0.4512\n",
      "Epoch 29/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6810 - val_loss: 0.4508\n",
      "Epoch 30/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6801 - val_loss: 0.4506\n",
      "Epoch 31/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6793 - val_loss: 0.4503\n",
      "Epoch 32/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6785 - val_loss: 0.4501\n",
      "Epoch 33/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6777 - val_loss: 0.4497\n",
      "Epoch 34/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6769 - val_loss: 0.4495\n",
      "Epoch 35/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6762 - val_loss: 0.4492\n",
      "Epoch 36/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6754 - val_loss: 0.4490\n",
      "Epoch 37/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6747 - val_loss: 0.4489\n",
      "Epoch 38/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6741 - val_loss: 0.4486\n",
      "Epoch 39/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6734 - val_loss: 0.4485\n",
      "Epoch 40/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6727 - val_loss: 0.4483\n",
      "Epoch 41/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6721 - val_loss: 0.4481\n",
      "Epoch 42/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6715 - val_loss: 0.4480\n",
      "Epoch 43/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6709 - val_loss: 0.4479\n",
      "Epoch 44/50\n",
      "876/876 [==============================] - 5s 6ms/step - loss: 0.6702 - val_loss: 0.4478\n",
      "Epoch 45/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6697 - val_loss: 0.4476\n",
      "Epoch 46/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.6691 - val_loss: 0.4475\n",
      "Epoch 47/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6686 - val_loss: 0.4474\n",
      "Epoch 48/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6681 - val_loss: 0.4474\n",
      "Epoch 49/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6676 - val_loss: 0.4473\n",
      "Epoch 50/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6670 - val_loss: 0.4472\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_32 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_33 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_32 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_33 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 1.0180 - val_loss: 0.5301\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8271 - val_loss: 0.4917\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7666 - val_loss: 0.4809\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7456 - val_loss: 0.4752\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7335 - val_loss: 0.4711\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7252 - val_loss: 0.4681\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7184 - val_loss: 0.4655\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7128 - val_loss: 0.4635\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7079 - val_loss: 0.4616\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7036 - val_loss: 0.4601\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7001 - val_loss: 0.4587\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6969 - val_loss: 0.4577\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6942 - val_loss: 0.4569\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6917 - val_loss: 0.4561\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6894 - val_loss: 0.4555\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6872 - val_loss: 0.4549\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6852 - val_loss: 0.4544\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6834 - val_loss: 0.4539\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6816 - val_loss: 0.4536\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6799 - val_loss: 0.4533\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6784 - val_loss: 0.4530\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6769 - val_loss: 0.4528\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6754 - val_loss: 0.4526\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6738 - val_loss: 0.4523\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6724 - val_loss: 0.4522\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6710 - val_loss: 0.4520\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6695 - val_loss: 0.4520\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6683 - val_loss: 0.4518\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6670 - val_loss: 0.4517\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6658 - val_loss: 0.4517\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6647 - val_loss: 0.4517\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6637 - val_loss: 0.4516\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6625 - val_loss: 0.4516\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6615 - val_loss: 0.4515\n",
      "Epoch 35/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6604 - val_loss: 0.4516\n",
      "Epoch 36/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6595 - val_loss: 0.4515\n",
      "Epoch 37/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6585 - val_loss: 0.4516\n",
      "Epoch 38/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6575 - val_loss: 0.4515\n",
      "Epoch 39/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6566 - val_loss: 0.4515\n",
      "Epoch 40/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6556 - val_loss: 0.4516\n",
      "Epoch 41/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6547 - val_loss: 0.4515\n",
      "Epoch 42/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6537 - val_loss: 0.4517\n",
      "Epoch 43/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6529 - val_loss: 0.4516\n",
      "Epoch 44/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6520 - val_loss: 0.4516\n",
      "Epoch 45/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6511 - val_loss: 0.4517\n",
      "Epoch 46/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6501 - val_loss: 0.4516\n",
      "Epoch 47/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6493 - val_loss: 0.4517\n",
      "Epoch 48/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6485 - val_loss: 0.4517\n",
      "Epoch 49/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6475 - val_loss: 0.4519\n",
      "Epoch 50/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6468 - val_loss: 0.4517\n",
      "(34969, 72, 3) (34969, 24, 1) (8665, 72, 3) (8665, 24, 1)\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_34 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_34 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.8764 - val_loss: 0.4924\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8186 - val_loss: 0.4849\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.8046 - val_loss: 0.4726\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7865 - val_loss: 0.4678\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.7813 - val_loss: 0.4678\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7735 - val_loss: 0.4657\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7754 - val_loss: 0.4745\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7489 - val_loss: 0.4913\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7422 - val_loss: 0.5048\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7448 - val_loss: 0.5017\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7429 - val_loss: 0.4991\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7511 - val_loss: 0.4768\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7226 - val_loss: 0.4918\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7452 - val_loss: 0.4923\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7351 - val_loss: 0.5179\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7831 - val_loss: 0.4820\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7367 - val_loss: 0.4689\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7384 - val_loss: 0.4841\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7170 - val_loss: 0.4635\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7196 - val_loss: 0.4816\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7109 - val_loss: 0.4695\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7002 - val_loss: 0.4776\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7238 - val_loss: 0.4821\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7105 - val_loss: 0.4710\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7159 - val_loss: 0.4814\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7155 - val_loss: 0.4846\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7117 - val_loss: 0.4999\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7063 - val_loss: 0.4703\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7267 - val_loss: 0.4743\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7175 - val_loss: 0.4681\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6971 - val_loss: 0.4802\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7072 - val_loss: 0.4702\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.6938 - val_loss: 0.4742\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7010 - val_loss: 0.4757\n",
      "Epoch 35/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6939 - val_loss: 0.4757\n",
      "Epoch 36/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6981 - val_loss: 0.4766\n",
      "Epoch 37/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6963 - val_loss: 0.4725\n",
      "Epoch 38/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7062 - val_loss: 0.4941\n",
      "Epoch 39/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6965 - val_loss: 0.4777\n",
      "273/273 [==============================] - 0s 1ms/step\n",
      "272/272 [==============================] - 0s 1ms/step\n",
      "271/271 [==============================] - 1s 2ms/step\n",
      "LONGIL\n",
      "24h MAE: 0.6586\n",
      "48h MAE: 0.6775\n",
      "72h MAE: 0.6746\n",
      "\n",
      "LONGIL\n",
      "24h MAE: 22.0411\n",
      "48h MAE: 22.6794\n",
      "72h MAE: 22.6936\n",
      "\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_36 (Conv1D)          (None, 12, 32)            320       \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 6, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 64)                12352     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,336\n",
      "Trainable params: 17,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 1.0158 - val_loss: 0.2482\n",
      "Epoch 2/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8666 - val_loss: 0.2280\n",
      "Epoch 3/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8055 - val_loss: 0.2236\n",
      "Epoch 4/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7850 - val_loss: 0.2214\n",
      "Epoch 5/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7754 - val_loss: 0.2198\n",
      "Epoch 6/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7689 - val_loss: 0.2185\n",
      "Epoch 7/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7636 - val_loss: 0.2174\n",
      "Epoch 8/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7596 - val_loss: 0.2166\n",
      "Epoch 9/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7561 - val_loss: 0.2159\n",
      "Epoch 10/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.7532 - val_loss: 0.2154\n",
      "Epoch 11/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7509 - val_loss: 0.2150\n",
      "Epoch 12/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7483 - val_loss: 0.2146\n",
      "Epoch 13/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7469 - val_loss: 0.2143\n",
      "Epoch 14/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7445 - val_loss: 0.2140\n",
      "Epoch 15/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7433 - val_loss: 0.2137\n",
      "Epoch 16/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7413 - val_loss: 0.2135\n",
      "Epoch 17/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7403 - val_loss: 0.2133\n",
      "Epoch 18/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7386 - val_loss: 0.2131\n",
      "Epoch 19/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7377 - val_loss: 0.2129\n",
      "Epoch 20/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7362 - val_loss: 0.2127\n",
      "Epoch 21/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.7353 - val_loss: 0.2125\n",
      "Epoch 22/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.7339 - val_loss: 0.2124\n",
      "Epoch 23/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.7328 - val_loss: 0.2121\n",
      "Epoch 24/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.7317 - val_loss: 0.2120\n",
      "Epoch 25/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.7307 - val_loss: 0.2118\n",
      "Epoch 26/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7296 - val_loss: 0.2117\n",
      "Epoch 27/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.7288 - val_loss: 0.2115\n",
      "Epoch 28/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7276 - val_loss: 0.2114\n",
      "Epoch 29/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7268 - val_loss: 0.2112\n",
      "Epoch 30/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7259 - val_loss: 0.2111\n",
      "Epoch 31/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7250 - val_loss: 0.2110\n",
      "Epoch 32/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7241 - val_loss: 0.2108\n",
      "Epoch 33/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7233 - val_loss: 0.2107\n",
      "Epoch 34/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7224 - val_loss: 0.2106\n",
      "Epoch 35/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7216 - val_loss: 0.2105\n",
      "Epoch 36/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7209 - val_loss: 0.2104\n",
      "Epoch 37/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7199 - val_loss: 0.2104\n",
      "Epoch 38/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7193 - val_loss: 0.2102\n",
      "Epoch 39/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7183 - val_loss: 0.2102\n",
      "Epoch 40/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7180 - val_loss: 0.2100\n",
      "Epoch 41/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7168 - val_loss: 0.2100\n",
      "Epoch 42/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7164 - val_loss: 0.2098\n",
      "Epoch 43/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7154 - val_loss: 0.2099\n",
      "Epoch 44/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7151 - val_loss: 0.2097\n",
      "Epoch 45/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7141 - val_loss: 0.2097\n",
      "Epoch 46/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7136 - val_loss: 0.2095\n",
      "Epoch 47/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7129 - val_loss: 0.2095\n",
      "Epoch 48/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7122 - val_loss: 0.2094\n",
      "Epoch 49/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7114 - val_loss: 0.2094\n",
      "Epoch 50/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7108 - val_loss: 0.2093\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_38 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_39 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_38 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_39 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 1.0346 - val_loss: 0.2715\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.8937 - val_loss: 0.2340\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.8200 - val_loss: 0.2234\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7924 - val_loss: 0.2194\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7799 - val_loss: 0.2175\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7722 - val_loss: 0.2163\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7662 - val_loss: 0.2154\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7613 - val_loss: 0.2146\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7574 - val_loss: 0.2140\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7539 - val_loss: 0.2134\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7510 - val_loss: 0.2130\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7482 - val_loss: 0.2125\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7454 - val_loss: 0.2122\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7429 - val_loss: 0.2119\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7403 - val_loss: 0.2117\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7385 - val_loss: 0.2114\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7365 - val_loss: 0.2112\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7349 - val_loss: 0.2110\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7332 - val_loss: 0.2108\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7317 - val_loss: 0.2106\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7302 - val_loss: 0.2103\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7288 - val_loss: 0.2101\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7276 - val_loss: 0.2099\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7260 - val_loss: 0.2098\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7249 - val_loss: 0.2096\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7234 - val_loss: 0.2095\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7223 - val_loss: 0.2093\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7210 - val_loss: 0.2092\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7201 - val_loss: 0.2090\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7186 - val_loss: 0.2089\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7177 - val_loss: 0.2087\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7164 - val_loss: 0.2086\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7156 - val_loss: 0.2084\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7142 - val_loss: 0.2085\n",
      "Epoch 35/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7135 - val_loss: 0.2082\n",
      "Epoch 36/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7119 - val_loss: 0.2083\n",
      "Epoch 37/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7116 - val_loss: 0.2080\n",
      "Epoch 38/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7099 - val_loss: 0.2081\n",
      "Epoch 39/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7095 - val_loss: 0.2078\n",
      "Epoch 40/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7079 - val_loss: 0.2080\n",
      "Epoch 41/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7076 - val_loss: 0.2076\n",
      "Epoch 42/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7057 - val_loss: 0.2079\n",
      "Epoch 43/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7056 - val_loss: 0.2075\n",
      "Epoch 44/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7038 - val_loss: 0.2078\n",
      "Epoch 45/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7040 - val_loss: 0.2073\n",
      "Epoch 46/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7017 - val_loss: 0.2077\n",
      "Epoch 47/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7020 - val_loss: 0.2072\n",
      "Epoch 48/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6999 - val_loss: 0.2076\n",
      "Epoch 49/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7002 - val_loss: 0.2071\n",
      "Epoch 50/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6979 - val_loss: 0.2076\n",
      "(34969, 72, 3) (34969, 24, 1) (8665, 72, 3) (8665, 24, 1)\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_40 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_41 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_40 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_41 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.9591 - val_loss: 0.2342\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.9052 - val_loss: 0.2227\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8862 - val_loss: 0.2239\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8676 - val_loss: 0.2314\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8955 - val_loss: 0.2604\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8810 - val_loss: 0.2430\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8595 - val_loss: 0.2350\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8312 - val_loss: 0.2201\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8581 - val_loss: 0.2268\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8173 - val_loss: 0.2201\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8088 - val_loss: 0.2222\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8071 - val_loss: 0.2205\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7850 - val_loss: 0.2234\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.8025 - val_loss: 0.2281\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7935 - val_loss: 0.2156\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7816 - val_loss: 0.2160\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7787 - val_loss: 0.2201\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7770 - val_loss: 0.2187\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7811 - val_loss: 0.2196\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7789 - val_loss: 0.2202\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7640 - val_loss: 0.2251\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7689 - val_loss: 0.2188\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7551 - val_loss: 0.2266\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7898 - val_loss: 0.2228\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7524 - val_loss: 0.2217\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7832 - val_loss: 0.2258\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7587 - val_loss: 0.2196\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7800 - val_loss: 0.2262\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7553 - val_loss: 0.2192\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7513 - val_loss: 0.2210\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7800 - val_loss: 0.2243\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7490 - val_loss: 0.2196\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7430 - val_loss: 0.2230\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7584 - val_loss: 0.2263\n",
      "Epoch 35/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7484 - val_loss: 0.2205\n",
      "273/273 [==============================] - 0s 1ms/step\n",
      "272/272 [==============================] - 0s 2ms/step\n",
      "271/271 [==============================] - 1s 2ms/step\n",
      "MHK VL\n",
      "24h MAE: 0.4680\n",
      "48h MAE: 0.4677\n",
      "72h MAE: 0.5367\n",
      "\n",
      "MHK VL\n",
      "24h MAE: 9.9577\n",
      "48h MAE: 9.9444\n",
      "72h MAE: 11.4394\n",
      "\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_42 (Conv1D)          (None, 12, 32)            320       \n",
      "                                                                 \n",
      " conv1d_43 (Conv1D)          (None, 6, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 64)                12352     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,336\n",
      "Trainable params: 17,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.9877 - val_loss: 0.2679\n",
      "Epoch 2/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.7195 - val_loss: 0.2325\n",
      "Epoch 3/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6568 - val_loss: 0.2259\n",
      "Epoch 4/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6435 - val_loss: 0.2225\n",
      "Epoch 5/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6335 - val_loss: 0.2202\n",
      "Epoch 6/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6267 - val_loss: 0.2184\n",
      "Epoch 7/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6206 - val_loss: 0.2173\n",
      "Epoch 8/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6155 - val_loss: 0.2162\n",
      "Epoch 9/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.6118 - val_loss: 0.2155\n",
      "Epoch 10/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.6084 - val_loss: 0.2149\n",
      "Epoch 11/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6055 - val_loss: 0.2144\n",
      "Epoch 12/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6028 - val_loss: 0.2141\n",
      "Epoch 13/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6005 - val_loss: 0.2138\n",
      "Epoch 14/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5986 - val_loss: 0.2135\n",
      "Epoch 15/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5968 - val_loss: 0.2133\n",
      "Epoch 16/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5950 - val_loss: 0.2129\n",
      "Epoch 17/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5934 - val_loss: 0.2128\n",
      "Epoch 18/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5919 - val_loss: 0.2125\n",
      "Epoch 19/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5905 - val_loss: 0.2124\n",
      "Epoch 20/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5892 - val_loss: 0.2122\n",
      "Epoch 21/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5879 - val_loss: 0.2121\n",
      "Epoch 22/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5866 - val_loss: 0.2119\n",
      "Epoch 23/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5855 - val_loss: 0.2119\n",
      "Epoch 24/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5844 - val_loss: 0.2118\n",
      "Epoch 25/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5833 - val_loss: 0.2117\n",
      "Epoch 26/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5822 - val_loss: 0.2118\n",
      "Epoch 27/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5812 - val_loss: 0.2117\n",
      "Epoch 28/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5803 - val_loss: 0.2117\n",
      "Epoch 29/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5794 - val_loss: 0.2117\n",
      "Epoch 30/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5785 - val_loss: 0.2117\n",
      "Epoch 31/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5776 - val_loss: 0.2117\n",
      "Epoch 32/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5768 - val_loss: 0.2117\n",
      "Epoch 33/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5759 - val_loss: 0.2118\n",
      "Epoch 34/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5751 - val_loss: 0.2117\n",
      "Epoch 35/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5744 - val_loss: 0.2118\n",
      "Epoch 36/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5736 - val_loss: 0.2118\n",
      "Epoch 37/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5728 - val_loss: 0.2119\n",
      "Epoch 38/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5721 - val_loss: 0.2119\n",
      "Epoch 39/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5714 - val_loss: 0.2120\n",
      "Epoch 40/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5706 - val_loss: 0.2120\n",
      "Epoch 41/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5700 - val_loss: 0.2120\n",
      "Epoch 42/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.5693 - val_loss: 0.2120\n",
      "Epoch 43/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.5688 - val_loss: 0.2121\n",
      "Epoch 44/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.5681 - val_loss: 0.2120\n",
      "Epoch 45/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.5676 - val_loss: 0.2121\n",
      "Epoch 46/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5669 - val_loss: 0.2121\n",
      "Epoch 47/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5663 - val_loss: 0.2122\n",
      "Epoch 48/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5658 - val_loss: 0.2122\n",
      "Epoch 49/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5652 - val_loss: 0.2122\n",
      "Epoch 50/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5646 - val_loss: 0.2123\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_44 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_45 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_44 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_45 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.9758 - val_loss: 0.2715\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7558 - val_loss: 0.2418\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6738 - val_loss: 0.2295\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6480 - val_loss: 0.2239\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6329 - val_loss: 0.2205\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6236 - val_loss: 0.2183\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6167 - val_loss: 0.2166\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6111 - val_loss: 0.2156\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6068 - val_loss: 0.2146\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6032 - val_loss: 0.2139\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6002 - val_loss: 0.2133\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5975 - val_loss: 0.2129\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5953 - val_loss: 0.2126\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5930 - val_loss: 0.2124\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5914 - val_loss: 0.2123\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5895 - val_loss: 0.2121\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5879 - val_loss: 0.2120\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5863 - val_loss: 0.2119\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5849 - val_loss: 0.2118\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5835 - val_loss: 0.2117\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5820 - val_loss: 0.2117\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5806 - val_loss: 0.2116\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5793 - val_loss: 0.2117\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5781 - val_loss: 0.2117\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5768 - val_loss: 0.2117\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5758 - val_loss: 0.2118\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5747 - val_loss: 0.2118\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5737 - val_loss: 0.2118\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5726 - val_loss: 0.2119\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5716 - val_loss: 0.2119\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5706 - val_loss: 0.2120\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5697 - val_loss: 0.2121\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5687 - val_loss: 0.2121\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5679 - val_loss: 0.2122\n",
      "Epoch 35/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5668 - val_loss: 0.2123\n",
      "Epoch 36/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5660 - val_loss: 0.2123\n",
      "Epoch 37/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5650 - val_loss: 0.2124\n",
      "Epoch 38/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5643 - val_loss: 0.2125\n",
      "Epoch 39/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5634 - val_loss: 0.2126\n",
      "Epoch 40/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5627 - val_loss: 0.2127\n",
      "Epoch 41/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5618 - val_loss: 0.2128\n",
      "Epoch 42/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5611 - val_loss: 0.2129\n",
      "(34969, 72, 3) (34969, 24, 1) (8665, 72, 3) (8665, 24, 1)\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_46 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_47 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_46 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_47 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.8495 - val_loss: 0.2358\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8099 - val_loss: 0.2301\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7736 - val_loss: 0.2211\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7538 - val_loss: 0.2552\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7812 - val_loss: 0.2621\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7784 - val_loss: 0.2256\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7295 - val_loss: 0.2467\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7215 - val_loss: 0.2424\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7578 - val_loss: 0.2462\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6868 - val_loss: 0.2360\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7421 - val_loss: 0.2436\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6856 - val_loss: 0.2411\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6900 - val_loss: 0.2428\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7628 - val_loss: 0.2378\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7316 - val_loss: 0.2243\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6969 - val_loss: 0.2408\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7159 - val_loss: 0.2264\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6720 - val_loss: 0.2276\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6445 - val_loss: 0.2322\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6324 - val_loss: 0.2394\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6356 - val_loss: 0.2496\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6634 - val_loss: 0.2339\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6562 - val_loss: 0.2254\n",
      "273/273 [==============================] - 0s 1ms/step\n",
      "272/272 [==============================] - 0s 1ms/step\n",
      "271/271 [==============================] - 1s 2ms/step\n",
      "MILLWD\n",
      "24h MAE: 0.4123\n",
      "48h MAE: 0.4135\n",
      "72h MAE: 0.4633\n",
      "\n",
      "MILLWD\n",
      "24h MAE: 10.1554\n",
      "48h MAE: 10.1681\n",
      "72h MAE: 11.2790\n",
      "\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_48 (Conv1D)          (None, 12, 32)            320       \n",
      "                                                                 \n",
      " conv1d_49 (Conv1D)          (None, 6, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d_24 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 64)                12352     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,336\n",
      "Trainable params: 17,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 1.0092 - val_loss: 0.2501\n",
      "Epoch 2/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.7649 - val_loss: 0.2152\n",
      "Epoch 3/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6687 - val_loss: 0.2086\n",
      "Epoch 4/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6428 - val_loss: 0.2059\n",
      "Epoch 5/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6305 - val_loss: 0.2036\n",
      "Epoch 6/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6220 - val_loss: 0.2021\n",
      "Epoch 7/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6154 - val_loss: 0.2006\n",
      "Epoch 8/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.6103 - val_loss: 0.1997\n",
      "Epoch 9/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6057 - val_loss: 0.1988\n",
      "Epoch 10/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.6018 - val_loss: 0.1982\n",
      "Epoch 11/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5986 - val_loss: 0.1977\n",
      "Epoch 12/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5958 - val_loss: 0.1973\n",
      "Epoch 13/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5932 - val_loss: 0.1968\n",
      "Epoch 14/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5910 - val_loss: 0.1965\n",
      "Epoch 15/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5890 - val_loss: 0.1962\n",
      "Epoch 16/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5872 - val_loss: 0.1960\n",
      "Epoch 17/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5856 - val_loss: 0.1958\n",
      "Epoch 18/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.5840 - val_loss: 0.1956\n",
      "Epoch 19/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.5826 - val_loss: 0.1954\n",
      "Epoch 20/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.5813 - val_loss: 0.1953\n",
      "Epoch 21/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.5800 - val_loss: 0.1951\n",
      "Epoch 22/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5789 - val_loss: 0.1950\n",
      "Epoch 23/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5779 - val_loss: 0.1949\n",
      "Epoch 24/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5769 - val_loss: 0.1948\n",
      "Epoch 25/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5759 - val_loss: 0.1947\n",
      "Epoch 26/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5749 - val_loss: 0.1946\n",
      "Epoch 27/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5740 - val_loss: 0.1945\n",
      "Epoch 28/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5731 - val_loss: 0.1944\n",
      "Epoch 29/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5723 - val_loss: 0.1943\n",
      "Epoch 30/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5715 - val_loss: 0.1943\n",
      "Epoch 31/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5708 - val_loss: 0.1942\n",
      "Epoch 32/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5701 - val_loss: 0.1941\n",
      "Epoch 33/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5693 - val_loss: 0.1941\n",
      "Epoch 34/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5687 - val_loss: 0.1940\n",
      "Epoch 35/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5681 - val_loss: 0.1940\n",
      "Epoch 36/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5674 - val_loss: 0.1940\n",
      "Epoch 37/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5668 - val_loss: 0.1939\n",
      "Epoch 38/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5662 - val_loss: 0.1939\n",
      "Epoch 39/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5656 - val_loss: 0.1939\n",
      "Epoch 40/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5650 - val_loss: 0.1938\n",
      "Epoch 41/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5644 - val_loss: 0.1938\n",
      "Epoch 42/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5638 - val_loss: 0.1938\n",
      "Epoch 43/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5632 - val_loss: 0.1937\n",
      "Epoch 44/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5627 - val_loss: 0.1937\n",
      "Epoch 45/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5621 - val_loss: 0.1937\n",
      "Epoch 46/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5616 - val_loss: 0.1937\n",
      "Epoch 47/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5610 - val_loss: 0.1937\n",
      "Epoch 48/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5605 - val_loss: 0.1938\n",
      "Epoch 49/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.5599 - val_loss: 0.1936\n",
      "Epoch 50/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.5595 - val_loss: 0.1937\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_50 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_51 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_50 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_51 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.9860 - val_loss: 0.2546\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7379 - val_loss: 0.2227\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6635 - val_loss: 0.2141\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6458 - val_loss: 0.2092\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6345 - val_loss: 0.2064\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6261 - val_loss: 0.2047\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6204 - val_loss: 0.2033\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6156 - val_loss: 0.2024\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6118 - val_loss: 0.2014\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6084 - val_loss: 0.2007\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6053 - val_loss: 0.2001\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6026 - val_loss: 0.1995\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.6002 - val_loss: 0.1991\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5981 - val_loss: 0.1986\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5962 - val_loss: 0.1982\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5944 - val_loss: 0.1978\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5927 - val_loss: 0.1975\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5911 - val_loss: 0.1971\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5895 - val_loss: 0.1969\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5880 - val_loss: 0.1966\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5865 - val_loss: 0.1964\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5851 - val_loss: 0.1961\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5836 - val_loss: 0.1959\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5822 - val_loss: 0.1958\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5808 - val_loss: 0.1956\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5796 - val_loss: 0.1953\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5783 - val_loss: 0.1951\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5769 - val_loss: 0.1949\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5756 - val_loss: 0.1948\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5742 - val_loss: 0.1947\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5730 - val_loss: 0.1946\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5718 - val_loss: 0.1944\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5706 - val_loss: 0.1943\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5693 - val_loss: 0.1943\n",
      "Epoch 35/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5681 - val_loss: 0.1942\n",
      "Epoch 36/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5671 - val_loss: 0.1941\n",
      "Epoch 37/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5659 - val_loss: 0.1941\n",
      "Epoch 38/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5649 - val_loss: 0.1941\n",
      "Epoch 39/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5639 - val_loss: 0.1941\n",
      "Epoch 40/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5628 - val_loss: 0.1941\n",
      "Epoch 41/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5618 - val_loss: 0.1941\n",
      "Epoch 42/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5608 - val_loss: 0.1942\n",
      "Epoch 43/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5599 - val_loss: 0.1942\n",
      "Epoch 44/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5590 - val_loss: 0.1942\n",
      "Epoch 45/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5580 - val_loss: 0.1943\n",
      "Epoch 46/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5570 - val_loss: 0.1943\n",
      "Epoch 47/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.5563 - val_loss: 0.1944\n",
      "Epoch 48/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5554 - val_loss: 0.1945\n",
      "Epoch 49/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5545 - val_loss: 0.1945\n",
      "Epoch 50/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.5538 - val_loss: 0.1946\n",
      "(34969, 72, 3) (34969, 24, 1) (8665, 72, 3) (8665, 24, 1)\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_52 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_53 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_26 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_52 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_53 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_26 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.8505 - val_loss: 0.2147\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7752 - val_loss: 0.2072\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7344 - val_loss: 0.1968\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6897 - val_loss: 0.1986\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6715 - val_loss: 0.1995\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6750 - val_loss: 0.1942\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6360 - val_loss: 0.1938\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6744 - val_loss: 0.2135\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6511 - val_loss: 0.2009\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6285 - val_loss: 0.1971\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6353 - val_loss: 0.1962\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6089 - val_loss: 0.1968\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6172 - val_loss: 0.1999\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6247 - val_loss: 0.1970\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6070 - val_loss: 0.1997\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6145 - val_loss: 0.2010\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6048 - val_loss: 0.1977\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6103 - val_loss: 0.1989\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6121 - val_loss: 0.2002\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6096 - val_loss: 0.2020\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6115 - val_loss: 0.2013\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6097 - val_loss: 0.2023\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6169 - val_loss: 0.2028\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6126 - val_loss: 0.2017\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6136 - val_loss: 0.2015\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6065 - val_loss: 0.2081\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.6136 - val_loss: 0.2036\n",
      "273/273 [==============================] - 0s 1ms/step\n",
      "272/272 [==============================] - 0s 1ms/step\n",
      "271/271 [==============================] - 0s 2ms/step\n",
      "N.Y.C.\n",
      "24h MAE: 0.4011\n",
      "48h MAE: 0.3955\n",
      "72h MAE: 0.4310\n",
      "\n",
      "N.Y.C.\n",
      "24h MAE: 10.2322\n",
      "48h MAE: 10.0751\n",
      "72h MAE: 10.9721\n",
      "\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_54 (Conv1D)          (None, 12, 32)            320       \n",
      "                                                                 \n",
      " conv1d_55 (Conv1D)          (None, 6, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d_27 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 64)                12352     \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,336\n",
      "Trainable params: 17,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 1.2605 - val_loss: 0.0222\n",
      "Epoch 2/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2474 - val_loss: 0.0212\n",
      "Epoch 3/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2412 - val_loss: 0.0204\n",
      "Epoch 4/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 1.2377 - val_loss: 0.0200\n",
      "Epoch 5/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 1.2357 - val_loss: 0.0197\n",
      "Epoch 6/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2343 - val_loss: 0.0196\n",
      "Epoch 7/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2333 - val_loss: 0.0194\n",
      "Epoch 8/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2326 - val_loss: 0.0194\n",
      "Epoch 9/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2320 - val_loss: 0.0193\n",
      "Epoch 10/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2314 - val_loss: 0.0193\n",
      "Epoch 11/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 1.2311 - val_loss: 0.0192\n",
      "Epoch 12/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2305 - val_loss: 0.0192\n",
      "Epoch 13/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2302 - val_loss: 0.0192\n",
      "Epoch 14/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 1.2298 - val_loss: 0.0192\n",
      "Epoch 15/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 1.2295 - val_loss: 0.0192\n",
      "Epoch 16/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 1.2291 - val_loss: 0.0192\n",
      "Epoch 17/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 1.2288 - val_loss: 0.0192\n",
      "Epoch 18/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 1.2285 - val_loss: 0.0192\n",
      "Epoch 19/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2282 - val_loss: 0.0192\n",
      "Epoch 20/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2279 - val_loss: 0.0193\n",
      "Epoch 21/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2276 - val_loss: 0.0193\n",
      "Epoch 22/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2273 - val_loss: 0.0193\n",
      "Epoch 23/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2269 - val_loss: 0.0193\n",
      "Epoch 24/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2266 - val_loss: 0.0194\n",
      "Epoch 25/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2263 - val_loss: 0.0194\n",
      "Epoch 26/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2260 - val_loss: 0.0194\n",
      "Epoch 27/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2256 - val_loss: 0.0194\n",
      "Epoch 28/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2253 - val_loss: 0.0195\n",
      "Epoch 29/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2250 - val_loss: 0.0195\n",
      "Epoch 30/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2246 - val_loss: 0.0195\n",
      "Epoch 31/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2243 - val_loss: 0.0195\n",
      "Epoch 32/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2239 - val_loss: 0.0196\n",
      "Epoch 33/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2236 - val_loss: 0.0196\n",
      "Epoch 34/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2232 - val_loss: 0.0196\n",
      "Epoch 35/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2228 - val_loss: 0.0197\n",
      "Epoch 36/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2225 - val_loss: 0.0197\n",
      "Epoch 37/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 1.2221 - val_loss: 0.0198\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_56 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_57 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_28 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_56 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_57 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_28 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 1.2524 - val_loss: 0.0217\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2448 - val_loss: 0.0209\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2401 - val_loss: 0.0204\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2374 - val_loss: 0.0202\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2358 - val_loss: 0.0200\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2346 - val_loss: 0.0199\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2336 - val_loss: 0.0198\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2327 - val_loss: 0.0197\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2322 - val_loss: 0.0196\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 1.2315 - val_loss: 0.0196\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 1.2310 - val_loss: 0.0196\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 1.2305 - val_loss: 0.0195\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 1.2300 - val_loss: 0.0195\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2296 - val_loss: 0.0195\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2292 - val_loss: 0.0195\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2287 - val_loss: 0.0196\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2283 - val_loss: 0.0196\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2278 - val_loss: 0.0196\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2273 - val_loss: 0.0196\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2268 - val_loss: 0.0197\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2264 - val_loss: 0.0197\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2259 - val_loss: 0.0197\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2255 - val_loss: 0.0197\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2249 - val_loss: 0.0198\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2245 - val_loss: 0.0198\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2239 - val_loss: 0.0199\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2235 - val_loss: 0.0199\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2229 - val_loss: 0.0199\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2224 - val_loss: 0.0201\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2219 - val_loss: 0.0201\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2213 - val_loss: 0.0201\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2207 - val_loss: 0.0202\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2201 - val_loss: 0.0203\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 1.2194 - val_loss: 0.0203\n",
      "(34969, 72, 3) (34969, 24, 1) (8665, 72, 3) (8665, 24, 1)\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_58 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_59 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_29 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_58 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_59 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_29 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 1.2459 - val_loss: 0.0199\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2400 - val_loss: 0.0195\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2370 - val_loss: 0.0192\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2361 - val_loss: 0.0195\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2353 - val_loss: 0.0195\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 1.2345 - val_loss: 0.0198\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 1.2335 - val_loss: 0.0199\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 1.2327 - val_loss: 0.0204\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 1.2327 - val_loss: 0.0222\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2313 - val_loss: 0.0202\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2372 - val_loss: 0.0204\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2307 - val_loss: 0.0235\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2322 - val_loss: 0.0223\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2281 - val_loss: 0.0199\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2316 - val_loss: 0.0236\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2296 - val_loss: 0.0242\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2271 - val_loss: 0.0199\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2323 - val_loss: 0.0262\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2277 - val_loss: 0.0277\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2245 - val_loss: 0.0284\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2263 - val_loss: 0.0303\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2478 - val_loss: 0.0297\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 1.2322 - val_loss: 0.0293\n",
      "273/273 [==============================] - 0s 1ms/step\n",
      "272/272 [==============================] - 0s 1ms/step\n",
      "271/271 [==============================] - 1s 2ms/step\n",
      "NORTH\n",
      "24h MAE: 0.1219\n",
      "48h MAE: 0.1242\n",
      "72h MAE: 0.1641\n",
      "\n",
      "NORTH\n",
      "24h MAE: 13.6471\n",
      "48h MAE: 13.9073\n",
      "72h MAE: 18.3772\n",
      "\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_60 (Conv1D)          (None, 12, 32)            320       \n",
      "                                                                 \n",
      " conv1d_61 (Conv1D)          (None, 6, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 192)               0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 64)                12352     \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,336\n",
      "Trainable params: 17,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 1.0424 - val_loss: 0.4132\n",
      "Epoch 2/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8976 - val_loss: 0.3787\n",
      "Epoch 3/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8565 - val_loss: 0.3686\n",
      "Epoch 4/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8407 - val_loss: 0.3637\n",
      "Epoch 5/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8323 - val_loss: 0.3606\n",
      "Epoch 6/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8265 - val_loss: 0.3583\n",
      "Epoch 7/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8220 - val_loss: 0.3565\n",
      "Epoch 8/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8182 - val_loss: 0.3550\n",
      "Epoch 9/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8152 - val_loss: 0.3536\n",
      "Epoch 10/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8126 - val_loss: 0.3524\n",
      "Epoch 11/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8104 - val_loss: 0.3515\n",
      "Epoch 12/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.8085 - val_loss: 0.3507\n",
      "Epoch 13/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.8068 - val_loss: 0.3502\n",
      "Epoch 14/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.8053 - val_loss: 0.3496\n",
      "Epoch 15/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.8039 - val_loss: 0.3492\n",
      "Epoch 16/50\n",
      "876/876 [==============================] - 4s 4ms/step - loss: 0.8026 - val_loss: 0.3489\n",
      "Epoch 17/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8015 - val_loss: 0.3486\n",
      "Epoch 18/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.8004 - val_loss: 0.3484\n",
      "Epoch 19/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7994 - val_loss: 0.3481\n",
      "Epoch 20/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7982 - val_loss: 0.3480\n",
      "Epoch 21/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7973 - val_loss: 0.3479\n",
      "Epoch 22/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7963 - val_loss: 0.3478\n",
      "Epoch 23/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7954 - val_loss: 0.3477\n",
      "Epoch 24/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7945 - val_loss: 0.3477\n",
      "Epoch 25/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7937 - val_loss: 0.3475\n",
      "Epoch 26/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7929 - val_loss: 0.3474\n",
      "Epoch 27/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7922 - val_loss: 0.3473\n",
      "Epoch 28/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7914 - val_loss: 0.3473\n",
      "Epoch 29/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7907 - val_loss: 0.3472\n",
      "Epoch 30/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7899 - val_loss: 0.3471\n",
      "Epoch 31/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7892 - val_loss: 0.3471\n",
      "Epoch 32/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7886 - val_loss: 0.3471\n",
      "Epoch 33/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7879 - val_loss: 0.3471\n",
      "Epoch 34/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7872 - val_loss: 0.3471\n",
      "Epoch 35/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7866 - val_loss: 0.3471\n",
      "Epoch 36/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7859 - val_loss: 0.3471\n",
      "Epoch 37/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7854 - val_loss: 0.3470\n",
      "Epoch 38/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7847 - val_loss: 0.3469\n",
      "Epoch 39/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7841 - val_loss: 0.3469\n",
      "Epoch 40/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7835 - val_loss: 0.3468\n",
      "Epoch 41/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7830 - val_loss: 0.3468\n",
      "Epoch 42/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7823 - val_loss: 0.3468\n",
      "Epoch 43/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7818 - val_loss: 0.3468\n",
      "Epoch 44/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7813 - val_loss: 0.3467\n",
      "Epoch 45/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7807 - val_loss: 0.3467\n",
      "Epoch 46/50\n",
      "876/876 [==============================] - 3s 4ms/step - loss: 0.7802 - val_loss: 0.3466\n",
      "Epoch 47/50\n",
      "876/876 [==============================] - 5s 5ms/step - loss: 0.7797 - val_loss: 0.3466\n",
      "Epoch 48/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.7792 - val_loss: 0.3466\n",
      "Epoch 49/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.7786 - val_loss: 0.3465\n",
      "Epoch 50/50\n",
      "876/876 [==============================] - 4s 5ms/step - loss: 0.7781 - val_loss: 0.3465\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_62 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_63 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_62 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_63 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 1.0349 - val_loss: 0.4012\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.9245 - val_loss: 0.3769\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.8720 - val_loss: 0.3671\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.8465 - val_loss: 0.3621\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.8337 - val_loss: 0.3592\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.8258 - val_loss: 0.3572\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.8198 - val_loss: 0.3557\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.8153 - val_loss: 0.3543\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8115 - val_loss: 0.3534\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.8083 - val_loss: 0.3526\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.8054 - val_loss: 0.3519\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.8029 - val_loss: 0.3514\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.8006 - val_loss: 0.3508\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7987 - val_loss: 0.3504\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7969 - val_loss: 0.3499\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7952 - val_loss: 0.3496\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7935 - val_loss: 0.3493\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7920 - val_loss: 0.3490\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7905 - val_loss: 0.3488\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7891 - val_loss: 0.3486\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7878 - val_loss: 0.3485\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7866 - val_loss: 0.3483\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7854 - val_loss: 0.3482\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7842 - val_loss: 0.3481\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7830 - val_loss: 0.3481\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7819 - val_loss: 0.3480\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7808 - val_loss: 0.3479\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7798 - val_loss: 0.3479\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7787 - val_loss: 0.3478\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7777 - val_loss: 0.3477\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7767 - val_loss: 0.3477\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7758 - val_loss: 0.3477\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7747 - val_loss: 0.3476\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7738 - val_loss: 0.3476\n",
      "Epoch 35/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7728 - val_loss: 0.3476\n",
      "Epoch 36/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7719 - val_loss: 0.3475\n",
      "Epoch 37/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7710 - val_loss: 0.3476\n",
      "Epoch 38/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7700 - val_loss: 0.3476\n",
      "Epoch 39/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7692 - val_loss: 0.3476\n",
      "Epoch 40/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7682 - val_loss: 0.3476\n",
      "Epoch 41/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7673 - val_loss: 0.3477\n",
      "Epoch 42/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7664 - val_loss: 0.3478\n",
      "Epoch 43/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7655 - val_loss: 0.3479\n",
      "Epoch 44/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7646 - val_loss: 0.3480\n",
      "Epoch 45/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7638 - val_loss: 0.3480\n",
      "Epoch 46/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7628 - val_loss: 0.3481\n",
      "Epoch 47/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7619 - val_loss: 0.3481\n",
      "Epoch 48/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7611 - val_loss: 0.3482\n",
      "Epoch 49/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7603 - val_loss: 0.3483\n",
      "Epoch 50/50\n",
      "875/875 [==============================] - 4s 4ms/step - loss: 0.7594 - val_loss: 0.3484\n",
      "(34969, 72, 3) (34969, 24, 1) (8665, 72, 3) (8665, 24, 1)\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_64 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_65 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_64 (Conv1D)          (None, 36, 32)            416       \n",
      "                                                                 \n",
      " conv1d_65 (Conv1D)          (None, 18, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 9, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,584\n",
      "Trainable params: 14,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.9478 - val_loss: 0.3620\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8987 - val_loss: 0.3579\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8933 - val_loss: 0.3605\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8808 - val_loss: 0.3563\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8680 - val_loss: 0.3558\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8595 - val_loss: 0.3553\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8568 - val_loss: 0.3539\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.8614 - val_loss: 0.3544\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.8641 - val_loss: 0.3642\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.8457 - val_loss: 0.3580\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.8410 - val_loss: 0.3564\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8352 - val_loss: 0.3570\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8340 - val_loss: 0.3643\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8303 - val_loss: 0.3530\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8170 - val_loss: 0.3637\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8184 - val_loss: 0.3545\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8156 - val_loss: 0.3674\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8129 - val_loss: 0.3565\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8232 - val_loss: 0.3583\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8300 - val_loss: 0.3619\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8044 - val_loss: 0.3638\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8115 - val_loss: 0.3565\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8165 - val_loss: 0.3649\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8032 - val_loss: 0.3588\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8055 - val_loss: 0.3576\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7997 - val_loss: 0.3535\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8016 - val_loss: 0.3538\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7993 - val_loss: 0.3520\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8060 - val_loss: 0.3578\n",
      "Epoch 30/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7918 - val_loss: 0.3579\n",
      "Epoch 31/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7943 - val_loss: 0.3594\n",
      "Epoch 32/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7923 - val_loss: 0.3584\n",
      "Epoch 33/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7858 - val_loss: 0.3592\n",
      "Epoch 34/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7830 - val_loss: 0.3574\n",
      "Epoch 35/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7752 - val_loss: 0.3576\n",
      "Epoch 36/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7888 - val_loss: 0.3592\n",
      "Epoch 37/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7773 - val_loss: 0.3619\n",
      "Epoch 38/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.7773 - val_loss: 0.3627\n",
      "Epoch 39/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7669 - val_loss: 0.3608\n",
      "Epoch 40/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.7793 - val_loss: 0.3623\n",
      "Epoch 41/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7811 - val_loss: 0.3591\n",
      "Epoch 42/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7875 - val_loss: 0.3535\n",
      "Epoch 43/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7767 - val_loss: 0.3588\n",
      "Epoch 44/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.8090 - val_loss: 0.3646\n",
      "Epoch 45/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7803 - val_loss: 0.3617\n",
      "Epoch 46/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7967 - val_loss: 0.3602\n",
      "Epoch 47/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7816 - val_loss: 0.3631\n",
      "Epoch 48/50\n",
      "875/875 [==============================] - 4s 5ms/step - loss: 0.7916 - val_loss: 0.3625\n",
      "273/273 [==============================] - 0s 1ms/step\n",
      "272/272 [==============================] - 0s 1ms/step\n",
      "271/271 [==============================] - 1s 2ms/step\n",
      "WEST\n",
      "24h MAE: 0.4550\n",
      "48h MAE: 0.4670\n",
      "72h MAE: 0.5361\n",
      "\n",
      "WEST\n",
      "24h MAE: 11.2819\n",
      "48h MAE: 11.5802\n",
      "72h MAE: 13.3480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for zone in zones:\n",
    "    # Read each timeseries (RTP = Real-Time Price, DAP = Day-Ahead Price, LF = Load Forecast)\n",
    "    raw_DAP = pd.read_csv(\"nyiso/da_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "    raw_RTP = pd.read_csv(\"nyiso/rt_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "    raw_LF = pd.read_csv(\"nyiso/load_frcstd_df_2015_2021.csv\", index_col=0)\n",
    "    \n",
    "    # Prepare the dataset as a dataframe\n",
    "    raw_data = pd.concat([raw_DAP.loc[:,zone], raw_LF.loc[:,zone], raw_RTP.loc[:,zone]],\n",
    "                           axis=1).loc['2017-01-01 05:00:00+00:00':]\n",
    "    raw_data.columns = ['DAP', 'LF', 'RTP']\n",
    "    raw_data.index.names = ['date']\n",
    "    raw_data.to_csv('nyiso/NYISO_'+zone+'_raw.csv')\n",
    "\n",
    "    log_data = raw_data.copy(deep=True)\n",
    "    log_data.loc[:,\"DAP\"] = np.log(raw_data.loc[:,\"DAP\"] + 1 - min(raw_data.loc[:,\"DAP\"]))\n",
    "    log_data.loc[:,\"RTP\"] = np.log(raw_data.loc[:,\"RTP\"] + 1 - min(raw_data.loc[:,\"RTP\"]))\n",
    "    log_data.to_csv('nyiso/NYISO_'+zone+'_log.csv')\n",
    "\n",
    "    # Split dataset: 2015 year for training and 2016-2017 years for testing\n",
    "    x_train_df = log_data.iloc[:8760*4+24,:]\n",
    "    x_test_df = log_data.iloc[8760*4+24:,:]\n",
    "\n",
    "    y_train_df = log_data.iloc[:8760*4+24,2:]\n",
    "    y_test_df = log_data.iloc[8760*4+24:,2:]\n",
    "\n",
    "    # Standardization\n",
    "    x_mean, x_std = x_train_df.mean(), x_train_df.std()\n",
    "    y_mean, y_std = y_train_df.mean(), y_train_df.std()\n",
    "\n",
    "    x_train = ((x_train_df - x_mean)/x_std).to_numpy()\n",
    "    x_test = ((x_test_df - x_mean)/x_std).to_numpy()\n",
    "\n",
    "    y_train = ((y_train_df - y_mean)/y_std).to_numpy()\n",
    "    y_test = ((y_test_df - y_mean)/y_std).to_numpy()\n",
    "\n",
    "    ############## Lag = 24 ###############\n",
    "\n",
    "    n_steps_in = 24\n",
    "    n_steps_out = 24\n",
    "\n",
    "    x_train_cnn = np.array([x_train[i:i+n_steps_in] for i in range(0, x_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_train_cnn = np.array([y_train[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    x_test_cnn = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_test_cnn = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    # set hyperparameters\n",
    "    n_filters  = 32  # number of filters\n",
    "    n_neurons  = 64  # number of neurons in the Dense layer\n",
    "    activation     = 'relu' # activation function\n",
    "    kernel_size    = 3\n",
    "    pool_size = 1\n",
    "    learning_rate  = 0.0001\n",
    "    minibatch_size = 32\n",
    "    num_epochs     = 50\n",
    "\n",
    "    # define model\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(filters=n_filters,kernel_size=kernel_size, strides=2, padding='same',\n",
    "                         input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=activation))\n",
    "    cnn_model.add(Conv1D(filters=n_filters,kernel_size=kernel_size, strides=2, padding='same',\n",
    "                         input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=activation))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(n_neurons, activation=activation))\n",
    "    cnn_model.add(Dense(n_steps_out, activation='linear'))\n",
    "    cnn_model.summary()\n",
    "    cnn_model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "    history = cnn_model.fit(x_train_cnn, y_train_cnn, \n",
    "                            batch_size = minibatch_size,\n",
    "                            epochs = num_epochs,\n",
    "                            validation_split=0.2, verbose=1,\n",
    "                            callbacks=[early_stop],\n",
    "                            shuffle=False)\n",
    "\n",
    "    model_path = os.path.join(cwd,'saved_model')\n",
    "    make_dir(model_path)\n",
    "    cnn_model.save(os.path.join(model_path,'cnn_model_'+zone+'_24h.h5'))\n",
    "\n",
    "    ############## Lag = 48 ###############\n",
    "\n",
    "    n_steps_in = 48\n",
    "    n_steps_out = 24\n",
    "\n",
    "    x_train_cnn = np.array([x_train[i:i+n_steps_in] for i in range(0, x_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_train_cnn = np.array([y_train[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    x_test_cnn = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_test_cnn = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    print(x_train_cnn.shape,y_train_cnn.shape,x_test_cnn.shape,y_test_cnn.shape)\n",
    "\n",
    "    # set hyperparameters\n",
    "    n_filters  = 32  # number of filters\n",
    "    n_neurons  = 64  # number of neurons in the Dense layer\n",
    "    activation     = 'relu' # activation function\n",
    "    kernel_size    = 3\n",
    "    pool_size = 1\n",
    "    learning_rate  = 0.0001\n",
    "    minibatch_size = 32\n",
    "    num_epochs     = 50\n",
    "\n",
    "    # Building the model\n",
    "    # define model\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(filters=n_filters,kernel_size=kernel_size, strides=2, padding='same',\n",
    "                         input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=activation))\n",
    "    cnn_model.add(Conv1D(filters=n_filters,kernel_size=kernel_size, strides=2, padding='same',\n",
    "                         input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=activation))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(n_neurons, activation=activation))\n",
    "    cnn_model.add(Dense(n_steps_out, activation='linear'))\n",
    "    cnn_model.summary()\n",
    "    cnn_model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "\n",
    "    cnn_model.summary()\n",
    "\n",
    "    # Running training\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "    history = cnn_model.fit(x_train_cnn, y_train_cnn, \n",
    "                            batch_size = minibatch_size,\n",
    "                            epochs = num_epochs,\n",
    "                            validation_split=0.2, verbose=1,\n",
    "                            callbacks=[early_stop],\n",
    "                            shuffle=False)\n",
    "\n",
    "    # Saving the model\n",
    "    model_path = os.path.join(cwd,'saved_model')\n",
    "    make_dir(model_path)\n",
    "    cnn_model.save(os.path.join(model_path,'cnn_model_'+zone+'_48h.h5'))\n",
    "\n",
    "    ############## Lag = 72 ###############\n",
    "\n",
    "    n_steps_in = 72\n",
    "    n_steps_out = 24\n",
    "\n",
    "    x_train_cnn = np.array([x_train[i:i+n_steps_in] for i in range(0, x_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_train_cnn = np.array([y_train[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    x_test_cnn = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_test_cnn = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    print(x_train_cnn.shape,y_train_cnn.shape,x_test_cnn.shape,y_test_cnn.shape)\n",
    "\n",
    "    # set hyperparameters\n",
    "    n_filters  = 32  # number of filters\n",
    "    n_neurons  = 32  # number of neurons in the Dense layer\n",
    "    activation     = 'tanh' # activation function\n",
    "    kernel_size    = 4\n",
    "    pool_size = 2\n",
    "    learning_rate  = 0.001\n",
    "    minibatch_size = 32\n",
    "    num_epochs     = 50\n",
    "\n",
    "    # Building the model\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(filters=n_filters,kernel_size=kernel_size, strides=2, padding='same',\n",
    "                         input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=activation))\n",
    "    cnn_model.add(Conv1D(filters=n_filters,kernel_size=kernel_size, strides=2, padding='same',\n",
    "                         input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=activation))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(n_neurons, activation=activation))\n",
    "    cnn_model.add(Dense(n_steps_out, activation='linear'))\n",
    "    cnn_model.summary()\n",
    "    cnn_model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "\n",
    "    cnn_model.summary()\n",
    "\n",
    "    # Running training\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "    history = cnn_model.fit(x_train_cnn, y_train_cnn, \n",
    "                            batch_size = minibatch_size,\n",
    "                            epochs = num_epochs,\n",
    "                            validation_split=0.2, verbose=1,\n",
    "                            callbacks=[early_stop],\n",
    "                            shuffle=False)\n",
    "\n",
    "    # Saving the model\n",
    "    model_path = os.path.join(cwd,'saved_model')\n",
    "    make_dir(model_path)\n",
    "\n",
    "    cnn_model.save(os.path.join(model_path,'cnn_model_'+zone+'_72h.h5'))\n",
    "\n",
    "    ################# Evaluation ##################\n",
    "\n",
    "    n_steps_in = 24\n",
    "    x_test_cnn = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_test_cnn_24 = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    cnn_model = load_model(os.path.join(model_path,'cnn_model_'+zone+'_24h.h5'))\n",
    "    y_test_pred_24 = cnn_model.predict(x_test_cnn)\n",
    "\n",
    "    n_steps_in = 48\n",
    "    x_test_cnn = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_test_cnn_48 = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    cnn_model = load_model(os.path.join(model_path,'cnn_model_'+zone+'_48h.h5'))\n",
    "    y_test_pred_48 = cnn_model.predict(x_test_cnn)\n",
    "\n",
    "    n_steps_in = 72\n",
    "    x_test_cnn = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_test_cnn_72 = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    cnn_model = load_model(os.path.join(model_path,'cnn_model_'+zone+'_72h.h5'))\n",
    "    y_test_pred_72 = cnn_model.predict(x_test_cnn)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    print(zone)\n",
    "    print('24h MAE: {:.4f}'.format(np.abs(y_test_pred_24 - y_test_cnn_24[:,:,0]).mean()))\n",
    "    print('48h MAE: {:.4f}'.format(np.abs(y_test_pred_48 - y_test_cnn_48[:,:,0]).mean()))\n",
    "    print('72h MAE: {:.4f}'.format(np.abs(y_test_pred_72 - y_test_cnn_72[:,:,0]).mean()))\n",
    "    print('')\n",
    "\n",
    "    y_test_pred_rescale_24 = y_test_pred_24*y_std.values + y_mean.values\n",
    "    y_test_cnn_rescale_24 = y_test_cnn_24*y_std.values + y_mean.values\n",
    "    y_test_pred_invlog_24 = np.exp(y_test_pred_rescale_24) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "    y_test_cnn_invlog_24 = np.exp(y_test_cnn_rescale_24) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "\n",
    "    y_test_pred_rescale_48 = y_test_pred_48*y_std.values + y_mean.values\n",
    "    y_test_cnn_rescale_48 = y_test_cnn_48*y_std.values + y_mean.values\n",
    "    y_test_pred_invlog_48 = np.exp(y_test_pred_rescale_48) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "    y_test_cnn_invlog_48 = np.exp(y_test_cnn_rescale_48) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "\n",
    "    y_test_pred_rescale_72 = y_test_pred_72*y_std.values + y_mean.values\n",
    "    y_test_cnn_rescale_72 = y_test_cnn_72*y_std.values + y_mean.values\n",
    "    y_test_pred_invlog_72 = np.exp(y_test_pred_rescale_72) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "    y_test_cnn_invlog_72 = np.exp(y_test_cnn_rescale_72) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "\n",
    "    # Evaluation metrics\n",
    "\n",
    "    print(zone)\n",
    "    print('24h MAE: {:.4f}'.format(np.abs(y_test_pred_invlog_24 - y_test_cnn_invlog_24[:,:,0]).mean()))\n",
    "    print('48h MAE: {:.4f}'.format(np.abs(y_test_pred_invlog_48 - y_test_cnn_invlog_48[:,:,0]).mean()))\n",
    "    print('72h MAE: {:.4f}'.format(np.abs(y_test_pred_invlog_72 - y_test_cnn_invlog_72[:,:,0]).mean()))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b3a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
