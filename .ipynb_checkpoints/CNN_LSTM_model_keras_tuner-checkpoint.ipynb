{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b2aa88a",
   "metadata": {},
   "source": [
    "# RTP Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731d33db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b599e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "import keras_tuner\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7317c723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e68172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "791e50da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dir(path):\n",
    "    if os.path.exists(path) is False:\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3107984b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#timing callback\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eeacbf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#zones = ['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'LONGIL',\n",
    "#         'MHK VL', 'MILLWD', 'N.Y.C.', 'NORTH', 'WEST']\n",
    "zone = 'N.Y.C.'\n",
    "year = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6a2ff2",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45f734c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read each timeseries (RTP = Real-Time Price, DAP = Day-Ahead Price, LF = Load Forecast)\n",
    "raw_DAP = pd.read_csv(\"nyiso/da_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "raw_RTP = pd.read_csv(\"nyiso/rt_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "raw_LF = pd.read_csv(\"nyiso/load_frcstd_df_2015_2021.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5febf202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the dataset as a dataframe\n",
    "raw_data = pd.concat([raw_DAP.loc[:,zone], raw_LF.loc[:,zone], raw_RTP.loc[:,zone]],\n",
    "                       axis=1).loc['2017-01-01 05:00:00+00:00':]\n",
    "raw_data.columns = ['DAP', 'LF', 'RTP']\n",
    "raw_data.index.names = ['date']\n",
    "raw_data.to_csv('nyiso/NYISO_'+zone+'_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2704d43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We perform log tranformation before feeding the dataset into the model to make enhance the performance\n",
    "# We only log tranform the price data (RTP and DAP)\n",
    "log = 1\n",
    "# log transformation for the forecasting task log10(Y + 1 - min(Y))\n",
    "if log:\n",
    "    log_data = raw_data.copy(deep=True)\n",
    "    log_data.loc[:,\"DAP\"] = np.log(raw_data.loc[:,\"DAP\"] + 1 - min(raw_data.loc[:,\"DAP\"]))\n",
    "    log_data.loc[:,\"RTP\"] = np.log(raw_data.loc[:,\"RTP\"] + 1 - min(raw_data.loc[:,\"RTP\"]))\n",
    "    log_data.to_csv('nyiso/NYISO_'+zone+'_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36355172",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e13d18ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split dataset: 2015 year for training and 2016-2017 years for testing\n",
    "x_train_df = log_data.iloc[:8760*4+24,:]\n",
    "x_test_df = log_data.iloc[8760*4+24:,:]\n",
    "\n",
    "y_train_df = log_data.iloc[:8760*4+24,2:]\n",
    "y_test_df = log_data.iloc[8760*4+24:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "494c0470",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35064, 3) (35064, 1) (8760, 3) (8760, 1)\n"
     ]
    }
   ],
   "source": [
    "# # Standardization\n",
    "x_mean, x_std = x_train_df.mean(), x_train_df.std()\n",
    "y_mean, y_std = y_train_df.mean(), y_train_df.std()\n",
    "\n",
    "x_train = ((x_train_df - x_mean)/x_std).to_numpy()\n",
    "x_test = ((x_test_df - x_mean)/x_std).to_numpy()\n",
    "\n",
    "y_train = ((y_train_df - y_mean)/y_std).to_numpy()\n",
    "y_test = ((y_test_df - y_mean)/y_std).to_numpy()\n",
    "\n",
    "print(x_train.shape,y_train.shape,x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776a123",
   "metadata": {},
   "source": [
    "### Reshape to (samples, steps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7ca14-a13f-4d88-8d9a-306c48a42dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    hp_neurons = hp.Choice('neurons', values=[16,32,64])\n",
    "    hp_filters = hp.Choice('filters', values=[20,40])\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh', 'sigmoid'])\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    hp_kernel_size = hp.Choice('kernel_size', values=[2, 3, 4])\n",
    "    hp_pool_size = hp.Choice('pool_size', values=[1, 2])\n",
    "    hp_loss = hp.Choice('loss', values=['mse','mae'])\n",
    "    \n",
    "    cnn_lstm_model = keras.models.Sequential()\n",
    "    cnn_lstm_model.add(Conv1D(filters=hp_filters,kernel_size=hp_kernel_size, strides=2, padding='same',\n",
    "                        input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=hp_activation))\n",
    "    cnn_lstm_model.add(Conv1D(filters=hp_filters,kernel_size=hp_kernel_size, strides=2, padding='same',\n",
    "                        input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=hp_activation))\n",
    "    cnn_lstm_model.add(MaxPooling1D(pool_size=hp_pool_size))\n",
    "    cnn_lstm_model.add(LSTM(hp_neurons, activation=hp_activation))\n",
    "    cnn_lstm_model.add(Flatten())\n",
    "    cnn_lstm_model.add(Dense(hp_neurons, activation=hp_activation))\n",
    "    cnn_lstm_model.add(Dense(n_steps_out, activation='linear'))\n",
    "    cnn_lstm_model.summary()\n",
    "    cnn_lstm_model.compile(loss=hp_loss,optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate))\n",
    "\n",
    "    return cnn_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b31366b0-34cd-4134-b5d8-296bea0ef5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34969, 72, 3) (34969, 24, 1) (8665, 72, 3) (8665, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "for n_steps in [24, 48, 72]\n",
    "    n_steps_in = n_steps\n",
    "    n_steps_out = 24\n",
    "\n",
    "    x_train_cnn = np.array([x_train[i:i+n_steps_in] for i in range(0, x_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_train_cnn = np.array([y_train[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    x_test_cnn = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_test_cnn = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    print(x_train_cnn.shape,y_train_cnn.shape,x_test_cnn.shape,y_test_cnn.shape)\n",
    "\n",
    "    minibatch_size = 64\n",
    "    num_epochs     = 50\n",
    "    n_trials       = 10\n",
    "\n",
    "    # Instantiate the Tuner and save the trials in a directory with customized project name\n",
    "    random_tuner = keras_tuner.RandomSearch(build_model, \n",
    "                                            max_trials=n_trials,\n",
    "                                            seed=5,\n",
    "                                            objective='val_loss', \n",
    "                                            max_retries_per_trial=0,\n",
    "                                            max_consecutive_failed_trials=3,\n",
    "                                            directory='random_search', \n",
    "                                            project_name='cnn_lstm_search'+str(n_steps)\n",
    "\n",
    "    random_tuner.search_space_summary()\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "    random_tuner.search(x_train_cnn, y_train_cnn, \n",
    "                        batch_size = minibatch_size,\n",
    "                        epochs = num_epochs,\n",
    "                        validation_split=0.2, verbose=1,\n",
    "                        callbacks=[early_stop],\n",
    "                        shuffle=False)\n",
    "\n",
    "    # Initiate an empty dataframe to store your results\n",
    "    tune_res = pd.DataFrame()\n",
    "\n",
    "    # Run a for loop to extract all the information we want\n",
    "    for trial in random_tuner.oracle.trials:\n",
    "        # Get the state for this trial\n",
    "        trial_state = random_tuner.oracle.trials[trial].get_state()\n",
    "\n",
    "        # Create a Series contaning the hyperparameter values for this trial\n",
    "        trial_hyperparameters = pd.Series(\n",
    "            trial_state[\"hyperparameters\"][\"values\"],\n",
    "            index = trial_state[\"hyperparameters\"][\"values\"].keys())\n",
    "\n",
    "        # Create a Series contaning the validation loss for this trial\n",
    "        trial_loss = pd.Series(trial_state[\"score\"], index = [\"val_loss\"])\n",
    "\n",
    "        # Combine both Series into one Series\n",
    "        trial_tune_res = pd.concat([trial_hyperparameters, trial_loss])\n",
    "\n",
    "        # Name the Series (such that we can trace the trial numbers in the final DataFrame)\n",
    "        trial_tune_res.name = trial\n",
    "\n",
    "        # Add this trial information to the DataFrame\n",
    "        tune_res = pd.concat([tune_res, trial_tune_res], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "    # Transpose the DataFrame such that each row represents a trial (optional)\n",
    "    tune_res = tune_res.T\n",
    "\n",
    "    for s in range(n_trials):\n",
    "        min_idx = s\n",
    "        for i in range(s + 1, n_trials):\n",
    "\n",
    "                # For sorting in descending order\n",
    "                # for minimum element in each loop\n",
    "            if (tune_res[\"val_loss\"][i] < tune_res[\"val_loss\"][min_idx]):\n",
    "                    min_idx = i\n",
    "\n",
    "            # Arranging min at the correct position\n",
    "        b, c = tune_res.iloc[s].copy(), tune_res.iloc[min_idx].copy()\n",
    "        temp = tune_res.iloc[s].copy()\n",
    "        tune_res.iloc[s] = c\n",
    "        tune_res.iloc[min_idx] = temp\n",
    "\n",
    "\n",
    "    tune_res.to_csv('tuning_results/cnn_lstm_tune_res_mini'+str(minibatch_size)+'_'+str(n_steps_in)+'h.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b004c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minibatch_size = 32\n",
    "num_epochs     = 50\n",
    "n_trials       = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c677010e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    hp_neurons = hp.Choice('neurons', values=[16,32,64])\n",
    "    hp_filters = hp.Choice('filters', values=[20,40])\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh', 'sigmoid'])\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    hp_kernel_size = hp.Choice('kernel_size', values=[2, 3, 4])\n",
    "    hp_pool_size = hp.Choice('pool_size', values=[1, 2])\n",
    "    hp_loss = hp.Choice('loss', values=['mse','mae'])\n",
    "    \n",
    "    cnn_lstm_model = keras.models.Sequential()\n",
    "    cnn_lstm_model.add(Conv1D(filters=hp_filters,kernel_size=hp_kernel_size, strides=2, padding='same',\n",
    "                        input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=hp_activation))\n",
    "    cnn_lstm_model.add(Conv1D(filters=hp_filters,kernel_size=hp_kernel_size, strides=2, padding='same',\n",
    "                        input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=hp_activation))\n",
    "    cnn_lstm_model.add(MaxPooling1D(pool_size=hp_pool_size))\n",
    "    cnn_lstm_model.add(LSTM(hp_neurons, activation=hp_activation))\n",
    "    cnn_lstm_model.add(Flatten())\n",
    "    cnn_lstm_model.add(Dense(hp_neurons, activation=hp_activation))\n",
    "    cnn_lstm_model.add(Dense(n_steps_out, activation='linear'))\n",
    "    cnn_lstm_model.summary()\n",
    "    cnn_lstm_model.compile(loss=hp_loss,optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate))\n",
    "\n",
    "    return cnn_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44cb9900",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 36, 20)            140       \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 18, 20)            820       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 18, 20)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 16)                2368      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 24)                408       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,008\n",
      "Trainable params: 4,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Tuner and save the trials in a directory with customized project name\n",
    "random_tuner = keras_tuner.RandomSearch(build_model, \n",
    "                                        max_trials=n_trials,\n",
    "                                        seed=5,\n",
    "                                        objective='val_loss', \n",
    "                                        max_retries_per_trial=0,\n",
    "                                        max_consecutive_failed_trials=3,\n",
    "                                        directory='random_search', \n",
    "                                        project_name='cnn_lstm_search3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "787914e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 7\n",
      "neurons (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n",
      "filters (Choice)\n",
      "{'default': 20, 'conditions': [], 'values': [20, 40], 'ordered': True}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "kernel_size (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 4], 'ordered': True}\n",
      "pool_size (Choice)\n",
      "{'default': 1, 'conditions': [], 'values': [1, 2], 'ordered': True}\n",
      "loss (Choice)\n",
      "{'default': 'mse', 'conditions': [], 'values': ['mse', 'mae'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "random_tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a29d64d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 Complete [00h 14m 43s]\n",
      "val_loss: 0.19472865760326385\n",
      "\n",
      "Best val_loss So Far: 0.19472865760326385\n",
      "Total elapsed time: 01h 32m 25s\n",
      "\n",
      "Search: Running Trial #10\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "64                |32                |neurons\n",
      "40                |40                |filters\n",
      "sigmoid           |tanh              |activation\n",
      "0.01              |0.001             |learning_rate\n",
      "2                 |3                 |kernel_size\n",
      "1                 |1                 |pool_size\n",
      "mae               |mse               |loss\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 36, 40)            280       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 18, 40)            3240      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 18, 40)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                26880     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,120\n",
      "Trainable params: 36,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 22s 24ms/step - loss: 0.5639 - val_loss: 0.3739\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 20s 23ms/step - loss: 0.5679 - val_loss: 0.3740\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 19s 21ms/step - loss: 0.5679 - val_loss: 0.3741\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 20s 23ms/step - loss: 0.5679 - val_loss: 0.3741\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 19s 22ms/step - loss: 0.5679 - val_loss: 0.3741\n",
      "Epoch 6/50\n",
      "341/875 [==========>...................] - ETA: 11s - loss: 0.7049"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "random_tuner.search(x_train_cnn, y_train_cnn, \n",
    "                    batch_size = minibatch_size,\n",
    "                    epochs = num_epochs,\n",
    "                    validation_split=0.2, verbose=1,\n",
    "                    callbacks=[early_stop],\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eaac14fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initiate an empty dataframe to store your results\n",
    "tune_res = pd.DataFrame()\n",
    "\n",
    "# Run a for loop to extract all the information we want\n",
    "for trial in random_tuner.oracle.trials:\n",
    "    # Get the state for this trial\n",
    "    trial_state = random_tuner.oracle.trials[trial].get_state()\n",
    "    \n",
    "    # Create a Series contaning the hyperparameter values for this trial\n",
    "    trial_hyperparameters = pd.Series(\n",
    "        trial_state[\"hyperparameters\"][\"values\"],\n",
    "        index = trial_state[\"hyperparameters\"][\"values\"].keys())\n",
    "    \n",
    "    # Create a Series contaning the validation loss for this trial\n",
    "    trial_loss = pd.Series(trial_state[\"score\"], index = [\"val_loss\"])\n",
    "    \n",
    "    # Combine both Series into one Series\n",
    "    trial_tune_res = pd.concat([trial_hyperparameters, trial_loss])\n",
    "    \n",
    "    # Name the Series (such that we can trace the trial numbers in the final DataFrame)\n",
    "    trial_tune_res.name = trial\n",
    "    \n",
    "    # Add this trial information to the DataFrame\n",
    "    tune_res = pd.concat([tune_res, trial_tune_res], axis = 1)\n",
    "    \n",
    "\n",
    "\n",
    "# Transpose the DataFrame such that each row represents a trial (optional)\n",
    "tune_res = tune_res.T\n",
    "\n",
    "# tune_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20d4c42b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neurons</th>\n",
       "      <th>filters</th>\n",
       "      <th>activation</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>pool_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>08</th>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.199529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09</th>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.200933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06</th>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.20323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.209492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.238421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.243082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.253777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07</th>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.255056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.290934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.36727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neurons filters activation learning_rate kernel_size pool_size loss  \\\n",
       "08      64      40       relu        0.0001           4         2  mse   \n",
       "09      32      40       tanh         0.001           3         1  mse   \n",
       "06      64      40       relu         0.001           3         1  mse   \n",
       "05      32      20       relu        0.0001           3         2  mse   \n",
       "00      32      40       tanh          0.01           4         2  mse   \n",
       "03      64      20    sigmoid          0.01           3         1  mse   \n",
       "04      32      40       relu         0.001           2         2  mae   \n",
       "07      32      40       relu          0.01           3         2  mse   \n",
       "02      32      20       tanh          0.01           3         1  mae   \n",
       "01      64      40    sigmoid          0.01           2         1  mae   \n",
       "\n",
       "    val_loss  \n",
       "08  0.199529  \n",
       "09  0.200933  \n",
       "06   0.20323  \n",
       "05  0.209492  \n",
       "00  0.238421  \n",
       "03  0.243082  \n",
       "04  0.253777  \n",
       "07  0.255056  \n",
       "02  0.290934  \n",
       "01   0.36727  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for s in range(n_trials):\n",
    "    min_idx = s\n",
    "    for i in range(s + 1, n_trials):\n",
    "             \n",
    "            # For sorting in descending order\n",
    "            # for minimum element in each loop\n",
    "        if (tune_res[\"val_loss\"][i] < tune_res[\"val_loss\"][min_idx]):\n",
    "                min_idx = i\n",
    " \n",
    "        # Arranging min at the correct position\n",
    "    b, c = tune_res.iloc[s].copy(), tune_res.iloc[min_idx].copy()\n",
    "    temp = tune_res.iloc[s].copy()\n",
    "    tune_res.iloc[s] = c\n",
    "    tune_res.iloc[min_idx] = temp\n",
    "\n",
    "\n",
    "tune_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d750d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tune_res.to_csv('tuning_results/cnn_lstm_tune_res_mini'+str(minibatch_size)+'_'+str(n_steps_in)+'h.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833c3f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0efdc68",
   "metadata": {},
   "source": [
    "After running all the different random searches, we will only test the best one for the three different look-back windows, and see which is the best in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b8be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
