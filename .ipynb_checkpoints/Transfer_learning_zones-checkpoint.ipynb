{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b2aa88a",
   "metadata": {},
   "source": [
    "# RTP Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b599e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7317c723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e68172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791e50da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dir(path):\n",
    "    if os.path.exists(path) is False:\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0718e927-205c-4b38-ae1b-3a2b089806a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(cwd,'saved_model')\n",
    "make_dir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3107984b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#timing callback\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6599df1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot history and future\n",
    "def plot_predictions(pred , actual, title):\n",
    "    plt.figure(figsize=(20, 4), dpi=150)\n",
    "    plt.plot(np.arange(len(pred)), np.array(pred),label='cnn',alpha=0.7)\n",
    "    plt.plot(np.arange(len(pred)), np.array(actual),label='PF', alpha=0.7)\n",
    "    plt.axhline(y=0, color='black', linestyle='--', lw=1, alpha=0.5)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Time step' ,  fontsize=18)\n",
    "    plt.ylabel('Price' , fontsize=18)\n",
    "    plt.title(title, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f090a8e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot history and future\n",
    "def plot_predictions_slide(pred_1,pred_2,pred_3, actual, title):\n",
    "    plt.figure(figsize=(20, 4), dpi=150)\n",
    "    plt.plot(np.arange(len(pred_1)), np.array(actual),label='PF', alpha=0.7)\n",
    "    plt.plot(np.arange(len(pred_1)), np.array(pred_1),label='cnn-24',alpha=0.7)\n",
    "    plt.plot(np.arange(len(pred_1)), np.array(pred_2),label='cnn-48',alpha=0.7)\n",
    "    plt.plot(np.arange(len(pred_1)), np.array(pred_3),label='cnn-27',alpha=0.7)\n",
    "    plt.axhline(y=0, color='black', linestyle='--', lw=1, alpha=0.5)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Time step' ,  fontsize=18)\n",
    "    plt.ylabel('Price' , fontsize=18)\n",
    "    plt.title(title, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eeacbf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zones = ['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'LONGIL',\n",
    "        'MHK VL', 'MILLWD', 'N.Y.C.', 'NORTH', 'WEST']\n",
    "# zone = 'CAPITL'\n",
    "year = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5dbc0-f848-468b-8b65-cacddd9c401c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47fac527-d809-4136-a801-50f7e4364ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 1s 2ms/step\n",
      "CAPITL\n",
      "24h MAE: 0.4724\n",
      "\n",
      "CAPITL\n",
      "24h MAE: 11.9008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read each timeseries (RTP = Real-Time Price, DAP = Day-Ahead Price, LF = Load Forecast)\n",
    "raw_DAP = pd.read_csv(\"nyiso/da_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "raw_RTP = pd.read_csv(\"nyiso/rt_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "raw_LF = pd.read_csv(\"nyiso/load_frcstd_df_2015_2021.csv\", index_col=0)\n",
    "\n",
    "# Prepare the dataset as a dataframe\n",
    "raw_data = pd.concat([raw_DAP.loc[:,zone], raw_LF.loc[:,zone], raw_RTP.loc[:,zone]],\n",
    "                       axis=1).loc['2017-01-01 05:00:00+00:00':]\n",
    "raw_data.columns = ['DAP', 'LF', 'RTP']\n",
    "raw_data.index.names = ['date']\n",
    "raw_data.to_csv('nyiso/NYISO_'+zone+'_raw.csv')\n",
    "\n",
    "log_data = raw_data.copy(deep=True)\n",
    "log_data.loc[:,\"DAP\"] = np.log(raw_data.loc[:,\"DAP\"] + 1 - min(raw_data.loc[:,\"DAP\"]))\n",
    "log_data.loc[:,\"RTP\"] = np.log(raw_data.loc[:,\"RTP\"] + 1 - min(raw_data.loc[:,\"RTP\"]))\n",
    "log_data.to_csv('nyiso/NYISO_'+zone+'_log.csv')\n",
    "\n",
    "# Split dataset: 2015 year for training and 2016-2017 years for testing\n",
    "x_train_df = log_data.iloc[:8760*4+24,:]\n",
    "x_test_df = log_data.iloc[8760*4+24:,:]\n",
    "\n",
    "y_train_df = log_data.iloc[:8760*4+24,2:]\n",
    "y_test_df = log_data.iloc[8760*4+24:,2:]\n",
    "\n",
    "# Standardization\n",
    "x_mean, x_std = x_train_df.mean(), x_train_df.std()\n",
    "y_mean, y_std = y_train_df.mean(), y_train_df.std()\n",
    "\n",
    "x_train = ((x_train_df - x_mean)/x_std).to_numpy()\n",
    "x_test = ((x_test_df - x_mean)/x_std).to_numpy()\n",
    "\n",
    "y_train = ((y_train_df - y_mean)/y_std).to_numpy()\n",
    "y_test = ((y_test_df - y_mean)/y_std).to_numpy()\n",
    "\n",
    "############## Lag = 24 ###############\n",
    "\n",
    "n_steps_in = 48\n",
    "n_steps_out = 24\n",
    "\n",
    "x_train_cnn = np.array([x_train[i:i+n_steps_in] for i in range(0, x_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "y_train_cnn = np.array([y_train[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "x_test_cnn = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "y_test_cnn = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "y_test_cnn = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "cnn_model = load_model(os.path.join(model_path,'cnn_model_CAPITL_48h.h5'))\n",
    "y_test_pred = cnn_model.predict(x_test_cnn)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(zone)\n",
    "print('24h MAE: {:.4f}'.format(np.abs(y_test_pred - y_test_cnn[:,:,0]).mean()))\n",
    "print('')\n",
    "\n",
    "y_test_pred_rescale = y_test_pred*y_std.values + y_mean.values\n",
    "y_test_cnn_rescale = y_test_cnn*y_std.values + y_mean.values\n",
    "y_test_pred_invlog = np.exp(y_test_pred_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "y_test_cnn_invlog = np.exp(y_test_cnn_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "\n",
    "# Evaluation metrics\n",
    "\n",
    "print(zone)\n",
    "print('24h MAE: {:.4f}'.format(np.abs(y_test_pred_invlog - y_test_cnn_invlog[:,:,0]).mean()))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb726db8-eab7-419b-a49d-488ece895ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_50 (Conv1D)          (None, 24, 32)            320       \n",
      "                                                                 \n",
      " conv1d_51 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPoolin  (None, 12, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 64)                24640     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,624\n",
      "Trainable params: 29,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1caa560f-8c4b-4611-a323-44de7e406a89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.5288 - val_loss: 0.2046\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5253 - val_loss: 0.2075\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5238 - val_loss: 0.2052\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.5223 - val_loss: 0.2045\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5208 - val_loss: 0.2050\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5189 - val_loss: 0.2065\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5175 - val_loss: 0.2075\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5157 - val_loss: 0.2072\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5140 - val_loss: 0.2053\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5128 - val_loss: 0.2071\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5110 - val_loss: 0.2078\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5098 - val_loss: 0.2123\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5082 - val_loss: 0.2106\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5072 - val_loss: 0.2097\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5055 - val_loss: 0.2082\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5044 - val_loss: 0.2088\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.5033 - val_loss: 0.2101\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5019 - val_loss: 0.2099\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5003 - val_loss: 0.2101\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4994 - val_loss: 0.2117\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4983 - val_loss: 0.2120\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4972 - val_loss: 0.2120\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.4959 - val_loss: 0.2110\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.4948 - val_loss: 0.2119\n"
     ]
    }
   ],
   "source": [
    "# set hyperparameters\n",
    "n_filters  = 32  # number of filters\n",
    "n_neurons  = 64  # number of neurons in the Dense layer\n",
    "activation     = 'relu' # activation function\n",
    "kernel_size    = 3\n",
    "pool_size = 1\n",
    "learning_rate  = 0.0001\n",
    "minibatch_size = 32\n",
    "num_epochs     = 50\n",
    "    \n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "cnn_model = load_model(os.path.join(model_path,'cnn_model_N.Y.C._48h.h5'))\n",
    "\n",
    "cnn_model.get_layer(index=0).trainable = False\n",
    "cnn_model.get_layer(index=1).trainable = False\n",
    "cnn_model.get_layer(index=2).trainable = False\n",
    "cnn_model.get_layer(index=3).trainable = False\n",
    "cnn_model.get_layer(index=4).trainable = False\n",
    "cnn_model.get_layer(index=5).trainable = True\n",
    "    \n",
    "history = cnn_model.fit(x_train_cnn, y_train_cnn, \n",
    "                    batch_size      = minibatch_size,\n",
    "                    epochs          = num_epochs,\n",
    "                    validation_split= 0.2, \n",
    "                    verbose         = 1,\n",
    "                    callbacks       = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e155e6e5-3dc9-45df-a0aa-d0b1fa0f4411",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 1s 2ms/step\n",
      "CAPITL\n",
      "24h MAE: 0.5016\n",
      "\n",
      "CAPITL\n",
      "24h MAE: 12.6220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = cnn_model.predict(x_test_cnn)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(zone)\n",
    "print('24h MAE: {:.4f}'.format(np.abs(y_test_pred - y_test_cnn[:,:,0]).mean()))\n",
    "print('')\n",
    "\n",
    "y_test_pred_rescale = y_test_pred*y_std.values + y_mean.values\n",
    "y_test_cnn_rescale = y_test_cnn*y_std.values + y_mean.values\n",
    "y_test_pred_invlog = np.exp(y_test_pred_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "y_test_cnn_invlog = np.exp(y_test_cnn_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "\n",
    "# Evaluation metrics\n",
    "\n",
    "print(zone)\n",
    "print('24h MAE: {:.4f}'.format(np.abs(y_test_pred_invlog - y_test_cnn_invlog[:,:,0]).mean()))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a03d30f3-5eb8-43e1-952b-07d20337c475",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 1s 2ms/step\n",
      "CAPITL\n",
      "24h MAE: 0.4999\n",
      "\n",
      "CAPITL\n",
      "24h MAE: 12.6152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = cnn_model.predict(x_test_cnn)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(zone)\n",
    "print('24h MAE: {:.4f}'.format(np.abs(y_test_pred - y_test_cnn[:,:,0]).mean()))\n",
    "print('')\n",
    "\n",
    "y_test_pred_rescale = y_test_pred*y_std.values + y_mean.values\n",
    "y_test_cnn_rescale = y_test_cnn*y_std.values + y_mean.values\n",
    "y_test_pred_invlog = np.exp(y_test_pred_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "y_test_cnn_invlog = np.exp(y_test_cnn_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "\n",
    "# Evaluation metrics\n",
    "\n",
    "print(zone)\n",
    "print('24h MAE: {:.4f}'.format(np.abs(y_test_pred_invlog - y_test_cnn_invlog[:,:,0]).mean()))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc8f72-df84-44f5-b469-a79b48210886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b560a050-ec64-470a-bdc3-f5ea1e3c0422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397ae82d-99d7-4a25-aa3d-e6ecc34d5b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d8088-e1e9-4d78-ba60-87f29814831e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c6ad7-bc7c-4f17-b47a-027e4515482d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a064d-9fdb-45a7-8961-c926f243a5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75512021-7cbc-43ff-b524-69674a8d3311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e752b-c5c9-4dfb-8f6f-35985fc0128b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca6a2ff2",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45f734c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 3ms/step\n",
      "CAPITL\n",
      "Pre-trained:\n",
      "24h MAE: 0.8094\n",
      "24h MAE: 12.5288\n",
      "\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 2s 8ms/step - loss: 0.3555 - val_loss: 1.2090\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.3514 - val_loss: 1.2168\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.3492 - val_loss: 1.2217\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.3474 - val_loss: 1.2264\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.3458 - val_loss: 1.2307\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.3444 - val_loss: 1.2350\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.3431 - val_loss: 1.2393\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.3419 - val_loss: 1.2437\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3408 - val_loss: 1.2481\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.3397 - val_loss: 1.2518\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "CAPITL\n",
      "Re-trained:\n",
      "24h MAE: 0.7895\n",
      "24h MAE: 12.2749\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "CENTRL\n",
      "Pre-trained:\n",
      "24h MAE: 0.9018\n",
      "24h MAE: 10.0304\n",
      "\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5161 - val_loss: 1.5359\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5072 - val_loss: 1.5424\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5021 - val_loss: 1.5467\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4985 - val_loss: 1.5505\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4955 - val_loss: 1.5546\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4931 - val_loss: 1.5582\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4908 - val_loss: 1.5613\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4888 - val_loss: 1.5649\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4870 - val_loss: 1.5684\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4854 - val_loss: 1.5721\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "CENTRL\n",
      "Re-trained:\n",
      "24h MAE: 0.9890\n",
      "24h MAE: 11.0221\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "DUNWOD\n",
      "Pre-trained:\n",
      "24h MAE: 0.7630\n",
      "24h MAE: 10.5505\n",
      "\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.3775 - val_loss: 1.1648\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3738 - val_loss: 1.1732\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3715 - val_loss: 1.1774\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3696 - val_loss: 1.1803\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3681 - val_loss: 1.1828\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3668 - val_loss: 1.1843\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3655 - val_loss: 1.1857\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3644 - val_loss: 1.1876\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3633 - val_loss: 1.1886\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3622 - val_loss: 1.1896\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "DUNWOD\n",
      "Re-trained:\n",
      "24h MAE: 0.7459\n",
      "24h MAE: 10.3532\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "GENESE\n",
      "Pre-trained:\n",
      "24h MAE: 0.8054\n",
      "24h MAE: 9.8501\n",
      "\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6062 - val_loss: 1.2074\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5900 - val_loss: 1.2084\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5807 - val_loss: 1.2093\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5739 - val_loss: 1.2111\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5687 - val_loss: 1.2133\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5644 - val_loss: 1.2160\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5608 - val_loss: 1.2189\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5576 - val_loss: 1.2217\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5549 - val_loss: 1.2246\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5524 - val_loss: 1.2272\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "GENESE\n",
      "Re-trained:\n",
      "24h MAE: 0.9389\n",
      "24h MAE: 11.5282\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "HUD VL\n",
      "Pre-trained:\n",
      "24h MAE: 0.7598\n",
      "24h MAE: 9.9737\n",
      "\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.3811 - val_loss: 1.2061\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3776 - val_loss: 1.2140\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.3756 - val_loss: 1.2183\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.3740 - val_loss: 1.2214\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 2s 8ms/step - loss: 0.3726 - val_loss: 1.2233\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3713 - val_loss: 1.2243\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3702 - val_loss: 1.2254\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3691 - val_loss: 1.2263\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3681 - val_loss: 1.2267\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3672 - val_loss: 1.2274\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "HUD VL\n",
      "Re-trained:\n",
      "24h MAE: 0.7373\n",
      "24h MAE: 9.7023\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "LONGIL\n",
      "Pre-trained:\n",
      "24h MAE: 0.9010\n",
      "24h MAE: 22.6098\n",
      "\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6374 - val_loss: 0.9869\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6295 - val_loss: 1.0025\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6250 - val_loss: 1.0152\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6218 - val_loss: 1.0260\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6191 - val_loss: 1.0351\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6168 - val_loss: 1.0435\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6147 - val_loss: 1.0508\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6127 - val_loss: 1.0576\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6109 - val_loss: 1.0640\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6092 - val_loss: 1.0700\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "LONGIL\n",
      "Re-trained:\n",
      "24h MAE: 0.9209\n",
      "24h MAE: 23.1499\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "MHK VL\n",
      "Pre-trained:\n",
      "24h MAE: 0.9254\n",
      "24h MAE: 10.4456\n",
      "\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.4976 - val_loss: 1.6100\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4895 - val_loss: 1.6132\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4850 - val_loss: 1.6154\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4816 - val_loss: 1.6175\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4789 - val_loss: 1.6203\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4766 - val_loss: 1.6230\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.4745 - val_loss: 1.6255\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4727 - val_loss: 1.6284\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4709 - val_loss: 1.6316\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4693 - val_loss: 1.6350\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "MHK VL\n",
      "Re-trained:\n",
      "24h MAE: 0.9440\n",
      "24h MAE: 10.6600\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "MILLWD\n",
      "Pre-trained:\n",
      "24h MAE: 0.7552\n",
      "24h MAE: 10.9814\n",
      "\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.4214 - val_loss: 1.0561\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4162 - val_loss: 1.0630\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4131 - val_loss: 1.0675\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4107 - val_loss: 1.0716\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4087 - val_loss: 1.0754\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4070 - val_loss: 1.0786\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4054 - val_loss: 1.0813\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4039 - val_loss: 1.0840\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4026 - val_loss: 1.0868\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4013 - val_loss: 1.0883\n",
      "272/272 [==============================] - 0s 2ms/step\n",
      "MILLWD\n",
      "Re-trained:\n",
      "24h MAE: 0.7314\n",
      "24h MAE: 10.6992\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "N.Y.C.\n",
      "Pre-trained:\n",
      "24h MAE: 0.6826\n",
      "24h MAE: 10.7320\n",
      "\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.4829 - val_loss: 0.9013\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.4782 - val_loss: 0.8901\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.4748 - val_loss: 0.8815\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4722 - val_loss: 0.8764\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4700 - val_loss: 0.8742\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4680 - val_loss: 0.8744\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4664 - val_loss: 0.8755\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4648 - val_loss: 0.8773\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4634 - val_loss: 0.8786\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4621 - val_loss: 0.8804\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "N.Y.C.\n",
      "Re-trained:\n",
      "24h MAE: 0.7003\n",
      "24h MAE: 11.0307\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "NORTH\n",
      "Pre-trained:\n",
      "24h MAE: 0.9255\n",
      "24h MAE: 13.8355\n",
      "\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6969 - val_loss: 1.7769\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6789 - val_loss: 1.7758\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6733 - val_loss: 1.7755\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6696 - val_loss: 1.7760\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6668 - val_loss: 1.7767\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6644 - val_loss: 1.7778\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6623 - val_loss: 1.7791\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6604 - val_loss: 1.7800\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6587 - val_loss: 1.7810\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6571 - val_loss: 1.7821\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "NORTH\n",
      "Re-trained:\n",
      "24h MAE: 0.9024\n",
      "24h MAE: 13.4903\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "WEST\n",
      "Pre-trained:\n",
      "24h MAE: 0.7081\n",
      "24h MAE: 11.3917\n",
      "\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.7256 - val_loss: 0.8583\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.7125 - val_loss: 0.8624\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.7054 - val_loss: 0.8645\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.7001 - val_loss: 0.8660\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6959 - val_loss: 0.8674\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6922 - val_loss: 0.8685\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6891 - val_loss: 0.8695\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6862 - val_loss: 0.8706\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6837 - val_loss: 0.8718\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6813 - val_loss: 0.8733\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "WEST\n",
      "Re-trained:\n",
      "24h MAE: 0.7535\n",
      "24h MAE: 12.1324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for zone in zones:\n",
    "    # Read each timeseries (RTP = Real-Time Price, DAP = Day-Ahead Price, LF = Load Forecast)\n",
    "    raw_DAP = pd.read_csv(\"nyiso/da_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "    raw_RTP = pd.read_csv(\"nyiso/rt_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "    raw_LF = pd.read_csv(\"nyiso/load_frcstd_df_2015_2021.csv\", index_col=0)\n",
    "    \n",
    "    # Prepare the dataset as a dataframe\n",
    "    raw_data = pd.concat([raw_DAP.loc[:,zone], raw_LF.loc[:,zone], raw_RTP.loc[:,zone]],\n",
    "                           axis=1).loc['2017-01-01 05:00:00+00:00':]\n",
    "    raw_data.columns = ['DAP', 'LF', 'RTP']\n",
    "    raw_data.index.names = ['date']\n",
    "    raw_data.to_csv('nyiso/NYISO_'+zone+'_raw.csv')\n",
    "\n",
    "    log_data = raw_data.copy(deep=True)\n",
    "    log_data.loc[:,\"DAP\"] = np.log(raw_data.loc[:,\"DAP\"] + 1 - min(raw_data.loc[:,\"DAP\"]))\n",
    "    log_data.loc[:,\"RTP\"] = np.log(raw_data.loc[:,\"RTP\"] + 1 - min(raw_data.loc[:,\"RTP\"]))\n",
    "    log_data.to_csv('nyiso/NYISO_'+zone+'_log.csv')\n",
    "\n",
    "    # Split dataset: 2015 year for training and 2016-2017 years for testing\n",
    "    x_train_df = log_data.iloc[8760*3:8760*4+24,:]\n",
    "    x_test_df = log_data.iloc[8760*4+24:,:]\n",
    "\n",
    "    y_train_df = log_data.iloc[8760*3:8760*4+24,2:]\n",
    "    y_test_df = log_data.iloc[8760*4+24:,2:]\n",
    "\n",
    "    # Standardization\n",
    "    x_mean, x_std = x_train_df.mean(), x_train_df.std()\n",
    "    y_mean, y_std = y_train_df.mean(), y_train_df.std()\n",
    "\n",
    "    x_train = ((x_train_df - x_mean)/x_std).to_numpy()\n",
    "    x_test = ((x_test_df - x_mean)/x_std).to_numpy()\n",
    "\n",
    "    y_train = ((y_train_df - y_mean)/y_std).to_numpy()\n",
    "    y_test = ((y_test_df - y_mean)/y_std).to_numpy()\n",
    "\n",
    "    ############## Lag = 48 ###############\n",
    "\n",
    "    n_steps_in = 48\n",
    "    n_steps_out = 24\n",
    "\n",
    "    x_train_cnn = np.array([x_train[i:i+n_steps_in] for i in range(0, x_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_train_cnn = np.array([y_train[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    x_test_cnn = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_test_cnn = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    print(x_train_cnn.shape,y_train_cnn.shape,x_test_cnn.shape,y_test_cnn.shape)\n",
    "    \n",
    "    # set hyperparameters\n",
    "    n_filters  = 32  # number of filters\n",
    "    n_neurons  = 64  # number of neurons in the Dense layer\n",
    "    activation     = 'relu' # activation function\n",
    "    kernel_size    = 3\n",
    "    pool_size = 1\n",
    "    learning_rate  = 0.0001\n",
    "    minibatch_size = 32\n",
    "    num_epochs     = 10\n",
    "\n",
    "    cnn_model = load_model(os.path.join(model_path,'cnn_model_N.Y.C._48h.h5'))\n",
    "\n",
    "    y_test_pred = cnn_model.predict(x_test_cnn)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    print(zone)\n",
    "    print('Pre-trained:')\n",
    "    print('24h MAE: {:.4f}'.format(np.abs(y_test_pred - y_test_cnn[:,:,0]).mean()))\n",
    "\n",
    "    y_test_pred_rescale = y_test_pred*y_std.values + y_mean.values\n",
    "    y_test_cnn_rescale = y_test_cnn*y_std.values + y_mean.values\n",
    "    y_test_pred_invlog = np.exp(y_test_pred_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "    y_test_cnn_invlog = np.exp(y_test_cnn_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "\n",
    "    # Evaluation metrics\n",
    "    print('24h MAE: {:.4f}'.format(np.abs(y_test_pred_invlog - y_test_cnn_invlog[:,:,0]).mean()))\n",
    "    print('')\n",
    "    \n",
    "    cnn_model.get_layer(index=0).trainable = False\n",
    "    cnn_model.get_layer(index=1).trainable = False\n",
    "    cnn_model.get_layer(index=2).trainable = False\n",
    "    cnn_model.get_layer(index=3).trainable = False\n",
    "    cnn_model.get_layer(index=4).trainable = False\n",
    "    cnn_model.get_layer(index=5).trainable = True\n",
    "\n",
    "    # Running training\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "    history = cnn_model.fit(x_train_cnn, y_train_cnn, \n",
    "                            batch_size = minibatch_size,\n",
    "                            epochs = num_epochs,\n",
    "                            validation_split=0.2, verbose=1,\n",
    "                            callbacks=[early_stop],\n",
    "                            shuffle=False)\n",
    "\n",
    "    # Saving the model\n",
    "    cnn_model.save(os.path.join(model_path,'TL_1y_cnn_model_'+zone+'_48h.h5'))\n",
    "\n",
    "    y_test_pred = cnn_model.predict(x_test_cnn)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    print(zone)\n",
    "    print('Re-trained:')\n",
    "    print('24h MAE: {:.4f}'.format(np.abs(y_test_pred - y_test_cnn[:,:,0]).mean()))\n",
    "\n",
    "    y_test_pred_rescale = y_test_pred*y_std.values + y_mean.values\n",
    "    y_test_cnn_rescale = y_test_cnn*y_std.values + y_mean.values\n",
    "    y_test_pred_invlog = np.exp(y_test_pred_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "    y_test_cnn_invlog = np.exp(y_test_cnn_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "\n",
    "    # Evaluation metrics\n",
    "    print('24h MAE: {:.4f}'.format(np.abs(y_test_pred_invlog - y_test_cnn_invlog[:,:,0]).mean()))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9032e2ff-f288-4dd1-b9f1-a18c53b489d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21c82d-8d49-4067-a886-7a9fae0e2483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449c190-9674-49f8-8a3a-4662c60756c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "CAPITL\n",
      "Pre-trained:\n",
      "24h MAE: 0.4836\n",
      "24h MAE: 12.1424\n",
      "\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.5501 - val_loss: 0.1993\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5421 - val_loss: 0.2003\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5384 - val_loss: 0.2002\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.5354 - val_loss: 0.2001\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5330 - val_loss: 0.2013\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5305 - val_loss: 0.2018\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5281 - val_loss: 0.2016\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5264 - val_loss: 0.2023\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5241 - val_loss: 0.2022\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5224 - val_loss: 0.2035\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5210 - val_loss: 0.2041\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5191 - val_loss: 0.2038\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5176 - val_loss: 0.2049\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5164 - val_loss: 0.2043\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5142 - val_loss: 0.2058\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5132 - val_loss: 0.2069\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5120 - val_loss: 0.2059\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5104 - val_loss: 0.2069\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5092 - val_loss: 0.2081\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5079 - val_loss: 0.2083\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5067 - val_loss: 0.2085\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5151 - val_loss: 0.2133\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5142 - val_loss: 0.2168\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5201 - val_loss: 0.2176\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5246 - val_loss: 0.2142\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5214 - val_loss: 0.2122\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5175 - val_loss: 0.2120\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5158 - val_loss: 0.2122\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5151 - val_loss: 0.2126\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5149 - val_loss: 0.2124\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5146 - val_loss: 0.2125\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5141 - val_loss: 0.2122\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5134 - val_loss: 0.2123\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5129 - val_loss: 0.2121\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5122 - val_loss: 0.2123\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5116 - val_loss: 0.2122\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5110 - val_loss: 0.2125\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5106 - val_loss: 0.2123\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5098 - val_loss: 0.2128\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5093 - val_loss: 0.2124\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5085 - val_loss: 0.2128\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5081 - val_loss: 0.2126\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5074 - val_loss: 0.2132\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5072 - val_loss: 0.2129\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5062 - val_loss: 0.2134\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5058 - val_loss: 0.2131\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5051 - val_loss: 0.2136\n",
      "272/272 [==============================] - 0s 2ms/step\n",
      "CAPITL\n",
      "Re-trained:\n",
      "24h MAE: 0.4935\n",
      "24h MAE: 12.4051\n",
      "\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "CENTRL\n",
      "Pre-trained:\n",
      "24h MAE: 0.4842\n",
      "24h MAE: 9.5521\n",
      "\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.6869 - val_loss: 0.2394\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6726 - val_loss: 0.2391\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.6666 - val_loss: 0.2408\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6621 - val_loss: 0.2350\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6573 - val_loss: 0.2365\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6539 - val_loss: 0.2345\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6500 - val_loss: 0.2351\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6468 - val_loss: 0.2373\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6441 - val_loss: 0.2365\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6410 - val_loss: 0.2376\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6387 - val_loss: 0.2374\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6358 - val_loss: 0.2378\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6329 - val_loss: 0.2373\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6304 - val_loss: 0.2362\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6281 - val_loss: 0.2366\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6256 - val_loss: 0.2370\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6232 - val_loss: 0.2366\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6211 - val_loss: 0.2348\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6191 - val_loss: 0.2367\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6169 - val_loss: 0.2382\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6147 - val_loss: 0.2352\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6129 - val_loss: 0.2365\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6104 - val_loss: 0.2367\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6085 - val_loss: 0.2364\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6068 - val_loss: 0.2386\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6040 - val_loss: 0.2373\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6093 - val_loss: 0.2363\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6152 - val_loss: 0.2361\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6209 - val_loss: 0.2358\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6144 - val_loss: 0.2358\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6122 - val_loss: 0.2358\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6101 - val_loss: 0.2359\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6099 - val_loss: 0.2359\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6087 - val_loss: 0.2360\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6080 - val_loss: 0.2360\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6070 - val_loss: 0.2360\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6058 - val_loss: 0.2361\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6050 - val_loss: 0.2362\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 6s 7ms/step - loss: 0.6038 - val_loss: 0.2362\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6032 - val_loss: 0.2362\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6020 - val_loss: 0.2364\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6012 - val_loss: 0.2364\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6003 - val_loss: 0.2364\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5995 - val_loss: 0.2365\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5983 - val_loss: 0.2366\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5975 - val_loss: 0.2366\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5968 - val_loss: 0.2366\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5955 - val_loss: 0.2367\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5950 - val_loss: 0.2367\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5941 - val_loss: 0.2368\n",
      "272/272 [==============================] - 0s 2ms/step\n",
      "CENTRL\n",
      "Re-trained:\n",
      "24h MAE: 0.5631\n",
      "24h MAE: 11.2318\n",
      "\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "DUNWOD\n",
      "Pre-trained:\n",
      "24h MAE: 0.4064\n",
      "24h MAE: 9.8421\n",
      "\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.5619 - val_loss: 0.1839\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5575 - val_loss: 0.1839\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5553 - val_loss: 0.1838\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5532 - val_loss: 0.1842\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5510 - val_loss: 0.1838\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5492 - val_loss: 0.1853\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5471 - val_loss: 0.1855\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5454 - val_loss: 0.1877\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5436 - val_loss: 0.1834\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5416 - val_loss: 0.1862\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5401 - val_loss: 0.1911\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5384 - val_loss: 0.1874\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5369 - val_loss: 0.1851\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 5s 5ms/step - loss: 0.5356 - val_loss: 0.1851\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5338 - val_loss: 0.1864\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5327 - val_loss: 0.1883\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5311 - val_loss: 0.1870\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5298 - val_loss: 0.1897\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5282 - val_loss: 0.1864\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5273 - val_loss: 0.1890\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5257 - val_loss: 0.1925\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5246 - val_loss: 0.1884\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5232 - val_loss: 0.1879\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5220 - val_loss: 0.1888\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5209 - val_loss: 0.1879\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5197 - val_loss: 0.1914\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5186 - val_loss: 0.1907\n",
      "Epoch 28/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5173 - val_loss: 0.1875\n",
      "Epoch 29/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5163 - val_loss: 0.1931\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5255 - val_loss: 0.1888\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5205 - val_loss: 0.1896\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5195 - val_loss: 0.1902\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5191 - val_loss: 0.1907\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5188 - val_loss: 0.1912\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5187 - val_loss: 0.1917\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5189 - val_loss: 0.1924\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5194 - val_loss: 0.1930\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5205 - val_loss: 0.1936\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5219 - val_loss: 0.1939\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5232 - val_loss: 0.1938\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5233 - val_loss: 0.1931\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5212 - val_loss: 0.1926\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5189 - val_loss: 0.1923\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5171 - val_loss: 0.1923\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5159 - val_loss: 0.1924\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5150 - val_loss: 0.1925\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.5143 - val_loss: 0.1926\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5136 - val_loss: 0.1926\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5131 - val_loss: 0.1928\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5125 - val_loss: 0.1928\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "DUNWOD\n",
      "Re-trained:\n",
      "24h MAE: 0.4503\n",
      "24h MAE: 10.8930\n",
      "\n",
      "(34993, 48, 3) (34993, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "GENESE\n",
      "Pre-trained:\n",
      "24h MAE: 0.4908\n",
      "24h MAE: 9.4843\n",
      "\n",
      "Epoch 1/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.6815 - val_loss: 0.3087\n",
      "Epoch 2/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6697 - val_loss: 0.3050\n",
      "Epoch 3/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6631 - val_loss: 0.3050\n",
      "Epoch 4/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6583 - val_loss: 0.3073\n",
      "Epoch 5/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6538 - val_loss: 0.3080\n",
      "Epoch 6/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6499 - val_loss: 0.3019\n",
      "Epoch 7/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6459 - val_loss: 0.3013\n",
      "Epoch 8/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6424 - val_loss: 0.3031\n",
      "Epoch 9/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6392 - val_loss: 0.3049\n",
      "Epoch 10/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6362 - val_loss: 0.3023\n",
      "Epoch 11/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6329 - val_loss: 0.3028\n",
      "Epoch 12/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6301 - val_loss: 0.3024\n",
      "Epoch 13/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6266 - val_loss: 0.3040\n",
      "Epoch 14/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6242 - val_loss: 0.3027\n",
      "Epoch 15/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6215 - val_loss: 0.3025\n",
      "Epoch 16/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6191 - val_loss: 0.3031\n",
      "Epoch 17/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6168 - val_loss: 0.3040\n",
      "Epoch 18/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6146 - val_loss: 0.3022\n",
      "Epoch 19/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6118 - val_loss: 0.3038\n",
      "Epoch 20/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6101 - val_loss: 0.3023\n",
      "Epoch 21/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6073 - val_loss: 0.3023\n",
      "Epoch 22/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6052 - val_loss: 0.3019\n",
      "Epoch 23/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6031 - val_loss: 0.3028\n",
      "Epoch 24/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.6011 - val_loss: 0.3021\n",
      "Epoch 25/50\n",
      "875/875 [==============================] - 6s 6ms/step - loss: 0.5985 - val_loss: 0.3027\n",
      "Epoch 26/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5966 - val_loss: 0.3033\n",
      "Epoch 27/50\n",
      "875/875 [==============================] - 5s 6ms/step - loss: 0.5943 - val_loss: 0.3031\n",
      "Epoch 1/50\n",
      "400/875 [============>.................] - ETA: 2s - loss: 0.7492"
     ]
    }
   ],
   "source": [
    "for zone in zones:\n",
    "    # Read each timeseries (RTP = Real-Time Price, DAP = Day-Ahead Price, LF = Load Forecast)\n",
    "    raw_DAP = pd.read_csv(\"nyiso/da_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "    raw_RTP = pd.read_csv(\"nyiso/rt_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "    raw_LF = pd.read_csv(\"nyiso/load_frcstd_df_2015_2021.csv\", index_col=0)\n",
    "    \n",
    "    # Prepare the dataset as a dataframe\n",
    "    raw_data = pd.concat([raw_DAP.loc[:,zone], raw_LF.loc[:,zone], raw_RTP.loc[:,zone]],\n",
    "                           axis=1).loc['2017-01-01 05:00:00+00:00':]\n",
    "    raw_data.columns = ['DAP', 'LF', 'RTP']\n",
    "    raw_data.index.names = ['date']\n",
    "    raw_data.to_csv('nyiso/NYISO_'+zone+'_raw.csv')\n",
    "\n",
    "    log_data = raw_data.copy(deep=True)\n",
    "    log_data.loc[:,\"DAP\"] = np.log(raw_data.loc[:,\"DAP\"] + 1 - min(raw_data.loc[:,\"DAP\"]))\n",
    "    log_data.loc[:,\"RTP\"] = np.log(raw_data.loc[:,\"RTP\"] + 1 - min(raw_data.loc[:,\"RTP\"]))\n",
    "    log_data.to_csv('nyiso/NYISO_'+zone+'_log.csv')\n",
    "\n",
    "    # Split dataset: 2015 year for training and 2016-2017 years for testing\n",
    "    x_train_df = log_data.iloc[:8760*4+24,:]\n",
    "    x_test_df = log_data.iloc[8760*4+24:,:]\n",
    "\n",
    "    y_train_df = log_data.iloc[:8760*4+24,2:]\n",
    "    y_test_df = log_data.iloc[8760*4+24:,2:]\n",
    "\n",
    "    # Standardization\n",
    "    x_mean, x_std = x_train_df.mean(), x_train_df.std()\n",
    "    y_mean, y_std = y_train_df.mean(), y_train_df.std()\n",
    "\n",
    "    x_train = ((x_train_df - x_mean)/x_std).to_numpy()\n",
    "    x_test = ((x_test_df - x_mean)/x_std).to_numpy()\n",
    "\n",
    "    y_train = ((y_train_df - y_mean)/y_std).to_numpy()\n",
    "    y_test = ((y_test_df - y_mean)/y_std).to_numpy()\n",
    "\n",
    "    ############## Lag = 48 ###############\n",
    "\n",
    "    n_steps_in = 48\n",
    "    n_steps_out = 24\n",
    "\n",
    "    x_train_cnn = np.array([x_train[i:i+n_steps_in] for i in range(0, x_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_train_cnn = np.array([y_train[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    x_test_cnn = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_test_cnn = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    print(x_train_cnn.shape,y_train_cnn.shape,x_test_cnn.shape,y_test_cnn.shape)\n",
    "    \n",
    "    # set hyperparameters\n",
    "    n_filters  = 32  # number of filters\n",
    "    n_neurons  = 64  # number of neurons in the Dense layer\n",
    "    activation     = 'relu' # activation function\n",
    "    kernel_size    = 3\n",
    "    pool_size = 1\n",
    "    learning_rate  = 0.0001\n",
    "    minibatch_size = 32\n",
    "    num_epochs     = 50\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "    cnn_model = load_model(os.path.join(model_path,'cnn_model_N.Y.C._48h.h5'))\n",
    "\n",
    "    y_test_pred = cnn_model.predict(x_test_cnn)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    print(zone)\n",
    "    print('Pre-trained:')\n",
    "    print('24h MAE: {:.4f}'.format(np.abs(y_test_pred - y_test_cnn[:,:,0]).mean()))\n",
    "\n",
    "    y_test_pred_rescale = y_test_pred*y_std.values + y_mean.values\n",
    "    y_test_cnn_rescale = y_test_cnn*y_std.values + y_mean.values\n",
    "    y_test_pred_invlog = np.exp(y_test_pred_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "    y_test_cnn_invlog = np.exp(y_test_cnn_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "\n",
    "    # Evaluation metrics\n",
    "    print('24h MAE: {:.4f}'.format(np.abs(y_test_pred_invlog - y_test_cnn_invlog[:,:,0]).mean()))\n",
    "    print('')\n",
    "    \n",
    "    cnn_model.get_layer(index=0).trainable = False\n",
    "    cnn_model.get_layer(index=1).trainable = False\n",
    "    cnn_model.get_layer(index=2).trainable = False\n",
    "    cnn_model.get_layer(index=3).trainable = False\n",
    "    cnn_model.get_layer(index=4).trainable = False\n",
    "    cnn_model.get_layer(index=5).trainable = True\n",
    "\n",
    "    history = cnn_model.fit(x_train_cnn, y_train_cnn, \n",
    "                        batch_size      = minibatch_size,\n",
    "                        epochs          = num_epochs,\n",
    "                        validation_split= 0.2, \n",
    "                        verbose         = 1,\n",
    "                        callbacks       = [early_stop])\n",
    "\n",
    "    # Running training\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "    history = cnn_model.fit(x_train_cnn, y_train_cnn, \n",
    "                            batch_size = minibatch_size,\n",
    "                            epochs = num_epochs,\n",
    "                            validation_split=0.2, verbose=1,\n",
    "                            callbacks=[early_stop],\n",
    "                            shuffle=False)\n",
    "\n",
    "    # Saving the model\n",
    "    cnn_model.save(os.path.join(model_path,'TL_50ep_cnn_model_'+zone+'_48h.h5'))\n",
    "\n",
    "    y_test_pred = cnn_model.predict(x_test_cnn)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    print(zone)\n",
    "    print('Re-trained:')\n",
    "    print('24h MAE: {:.4f}'.format(np.abs(y_test_pred - y_test_cnn[:,:,0]).mean()))\n",
    "\n",
    "    y_test_pred_rescale = y_test_pred*y_std.values + y_mean.values\n",
    "    y_test_cnn_rescale = y_test_cnn*y_std.values + y_mean.values\n",
    "    y_test_pred_invlog = np.exp(y_test_pred_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "    y_test_cnn_invlog = np.exp(y_test_cnn_rescale) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "\n",
    "    # Evaluation metrics\n",
    "    print('24h MAE: {:.4f}'.format(np.abs(y_test_pred_invlog - y_test_cnn_invlog[:,:,0]).mean()))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084eccbc-0c93-4b1d-aef2-42e97c1d837b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc25a9-0326-4be8-a2da-c9bf41f67837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d95b3a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5305 - val_loss: 2.6437\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4648 - val_loss: 2.4213\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4339 - val_loss: 2.2216\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4164 - val_loss: 2.0476\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4024 - val_loss: 1.8831\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.3909 - val_loss: 1.7480\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3823 - val_loss: 1.6526\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3758 - val_loss: 1.5876\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3710 - val_loss: 1.5407\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3673 - val_loss: 1.5073\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3642 - val_loss: 1.4821\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3617 - val_loss: 1.4631\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3595 - val_loss: 1.4493\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3575 - val_loss: 1.4378\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3557 - val_loss: 1.4286\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3541 - val_loss: 1.4217\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3527 - val_loss: 1.4162\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3513 - val_loss: 1.4123\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3501 - val_loss: 1.4080\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3489 - val_loss: 1.4044\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3479 - val_loss: 1.4022\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3468 - val_loss: 1.3996\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3459 - val_loss: 1.3987\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3450 - val_loss: 1.3977\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3441 - val_loss: 1.3962\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3433 - val_loss: 1.3958\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3425 - val_loss: 1.3954\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3417 - val_loss: 1.3947\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3409 - val_loss: 1.3940\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3402 - val_loss: 1.3946\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3395 - val_loss: 1.3937\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3388 - val_loss: 1.3946\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3381 - val_loss: 1.3939\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 0.3374 - val_loss: 1.3945\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3368 - val_loss: 1.3946\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3361 - val_loss: 1.3951\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3355 - val_loss: 1.3964\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3349 - val_loss: 1.3953\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3343 - val_loss: 1.3970\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3337 - val_loss: 1.3968\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3331 - val_loss: 1.3991\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3325 - val_loss: 1.3989\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3320 - val_loss: 1.3998\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3314 - val_loss: 1.4007\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3309 - val_loss: 1.4018\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.3303 - val_loss: 1.4019\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3298 - val_loss: 1.4031\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3292 - val_loss: 1.4035\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3287 - val_loss: 1.4048\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3282 - val_loss: 1.4065\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "CAPITL\n",
      "48h MAE: 0.8541\n",
      "48h MAE: 13.2170\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.7182 - val_loss: 2.0433\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6531 - val_loss: 1.8972\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5975 - val_loss: 1.7869\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5666 - val_loss: 1.7322\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5493 - val_loss: 1.6988\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5379 - val_loss: 1.6766\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5299 - val_loss: 1.6606\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5238 - val_loss: 1.6491\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5189 - val_loss: 1.6407\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5150 - val_loss: 1.6348\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5117 - val_loss: 1.6309\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5088 - val_loss: 1.6280\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5063 - val_loss: 1.6260\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5039 - val_loss: 1.6251\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5017 - val_loss: 1.6253\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4997 - val_loss: 1.6255\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4978 - val_loss: 1.6262\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4960 - val_loss: 1.6271\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4943 - val_loss: 1.6286\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4926 - val_loss: 1.6302\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4911 - val_loss: 1.6321\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4896 - val_loss: 1.6340\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4881 - val_loss: 1.6362\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4867 - val_loss: 1.6382\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4854 - val_loss: 1.6404\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4840 - val_loss: 1.6425\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4827 - val_loss: 1.6446\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4815 - val_loss: 1.6467\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4803 - val_loss: 1.6487\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4792 - val_loss: 1.6509\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4780 - val_loss: 1.6529\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4769 - val_loss: 1.6551\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4758 - val_loss: 1.6575\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4748 - val_loss: 1.6598\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "CENTRL\n",
      "48h MAE: 1.1318\n",
      "48h MAE: 12.6315\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6059 - val_loss: 2.3835\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5172 - val_loss: 2.1352\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4639 - val_loss: 1.9269\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4369 - val_loss: 1.7890\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4220 - val_loss: 1.6955\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4126 - val_loss: 1.6289\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4059 - val_loss: 1.5787\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4007 - val_loss: 1.5401\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3967 - val_loss: 1.5105\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3933 - val_loss: 1.4864\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3905 - val_loss: 1.4668\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3880 - val_loss: 1.4504\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3857 - val_loss: 1.4370\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3837 - val_loss: 1.4249\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3818 - val_loss: 1.4137\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3802 - val_loss: 1.4040\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3787 - val_loss: 1.3955\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3774 - val_loss: 1.3885\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3761 - val_loss: 1.3819\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3748 - val_loss: 1.3766\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3737 - val_loss: 1.3719\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3726 - val_loss: 1.3678\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3716 - val_loss: 1.3643\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3706 - val_loss: 1.3612\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3696 - val_loss: 1.3591\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3687 - val_loss: 1.3558\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3678 - val_loss: 1.3537\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3670 - val_loss: 1.3520\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3661 - val_loss: 1.3501\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3653 - val_loss: 1.3479\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3645 - val_loss: 1.3469\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3638 - val_loss: 1.3455\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3630 - val_loss: 1.3442\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3623 - val_loss: 1.3430\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3615 - val_loss: 1.3425\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3608 - val_loss: 1.3420\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3601 - val_loss: 1.3416\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3595 - val_loss: 1.3415\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3588 - val_loss: 1.3411\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3581 - val_loss: 1.3408\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3575 - val_loss: 1.3409\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3568 - val_loss: 1.3402\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3562 - val_loss: 1.3398\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3555 - val_loss: 1.3391\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3549 - val_loss: 1.3394\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3543 - val_loss: 1.3389\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3537 - val_loss: 1.3387\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3531 - val_loss: 1.3387\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3525 - val_loss: 1.3384\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3519 - val_loss: 1.3385\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "DUNWOD\n",
      "48h MAE: 0.8236\n",
      "48h MAE: 11.3802\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.8351 - val_loss: 1.5983\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.7694 - val_loss: 1.5124\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.7150 - val_loss: 1.4330\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6743 - val_loss: 1.3807\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6475 - val_loss: 1.3484\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6296 - val_loss: 1.3278\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6173 - val_loss: 1.3143\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6083 - val_loss: 1.3051\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6013 - val_loss: 1.2987\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5958 - val_loss: 1.2945\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5911 - val_loss: 1.2923\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.5872 - val_loss: 1.2902\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5839 - val_loss: 1.2890\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5808 - val_loss: 1.2880\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5781 - val_loss: 1.2877\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5757 - val_loss: 1.2875\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5735 - val_loss: 1.2876\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5714 - val_loss: 1.2881\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.5694 - val_loss: 1.2885\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5676 - val_loss: 1.2889\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5659 - val_loss: 1.2892\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5642 - val_loss: 1.2905\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5626 - val_loss: 1.2915\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5610 - val_loss: 1.2923\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5594 - val_loss: 1.2934\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5580 - val_loss: 1.2951\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5565 - val_loss: 1.2958\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5552 - val_loss: 1.2971\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5537 - val_loss: 1.2977\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5526 - val_loss: 1.2996\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5512 - val_loss: 1.3004\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5499 - val_loss: 1.3020\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5486 - val_loss: 1.3033\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5474 - val_loss: 1.3050\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5461 - val_loss: 1.3063\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5450 - val_loss: 1.3079\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "GENESE\n",
      "48h MAE: 1.2210\n",
      "48h MAE: 15.0240\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5800 - val_loss: 2.4923\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5085 - val_loss: 2.2825\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4605 - val_loss: 2.0766\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4386 - val_loss: 1.9194\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4253 - val_loss: 1.8084\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4162 - val_loss: 1.7279\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4094 - val_loss: 1.6676\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4040 - val_loss: 1.6179\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3996 - val_loss: 1.5738\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3958 - val_loss: 1.5381\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3926 - val_loss: 1.5109\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3899 - val_loss: 1.4901\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.3875 - val_loss: 1.4712\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3854 - val_loss: 1.4555\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3835 - val_loss: 1.4435\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3818 - val_loss: 1.4335\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3802 - val_loss: 1.4253\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3788 - val_loss: 1.4178\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3774 - val_loss: 1.4127\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3762 - val_loss: 1.4086\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3750 - val_loss: 1.4051\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3739 - val_loss: 1.4018\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3728 - val_loss: 1.3998\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3718 - val_loss: 1.3988\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3708 - val_loss: 1.3976\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3699 - val_loss: 1.3969\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3691 - val_loss: 1.3964\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3682 - val_loss: 1.3947\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3674 - val_loss: 1.3942\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3666 - val_loss: 1.3939\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3658 - val_loss: 1.3935\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3651 - val_loss: 1.3931\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3643 - val_loss: 1.3932\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3636 - val_loss: 1.3934\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3630 - val_loss: 1.3937\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3623 - val_loss: 1.3942\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3616 - val_loss: 1.3955\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3610 - val_loss: 1.3951\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3603 - val_loss: 1.3959\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.3597 - val_loss: 1.3964\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3591 - val_loss: 1.3961\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3585 - val_loss: 1.3972\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3579 - val_loss: 1.3975\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3573 - val_loss: 1.3975\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3568 - val_loss: 1.3982\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3562 - val_loss: 1.3988\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3556 - val_loss: 1.4000\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3551 - val_loss: 1.4000\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3545 - val_loss: 1.4003\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3540 - val_loss: 1.4007\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "HUD VL\n",
      "48h MAE: 0.8393\n",
      "48h MAE: 10.9890\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.7672 - val_loss: 1.7655\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.7170 - val_loss: 1.6641\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6886 - val_loss: 1.5925\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6740 - val_loss: 1.5445\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6649 - val_loss: 1.5081\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6581 - val_loss: 1.4768\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.6525 - val_loss: 1.4502\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6478 - val_loss: 1.4297\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6437 - val_loss: 1.4151\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6402 - val_loss: 1.4031\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6372 - val_loss: 1.3934\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6345 - val_loss: 1.3866\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6320 - val_loss: 1.3800\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6297 - val_loss: 1.3773\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6276 - val_loss: 1.3725\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.6256 - val_loss: 1.3714\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6236 - val_loss: 1.3673\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6217 - val_loss: 1.3658\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6199 - val_loss: 1.3623\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6182 - val_loss: 1.3600\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6165 - val_loss: 1.3590\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6149 - val_loss: 1.3575\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6134 - val_loss: 1.3567\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6119 - val_loss: 1.3563\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6104 - val_loss: 1.3565\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6090 - val_loss: 1.3564\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6076 - val_loss: 1.3555\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6062 - val_loss: 1.3570\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6048 - val_loss: 1.3570\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6035 - val_loss: 1.3577\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6022 - val_loss: 1.3583\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6009 - val_loss: 1.3621\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5996 - val_loss: 1.3619\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5983 - val_loss: 1.3660\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5972 - val_loss: 1.3691\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5959 - val_loss: 1.3736\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5947 - val_loss: 1.3742\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5936 - val_loss: 1.3797\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5923 - val_loss: 1.3822\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5912 - val_loss: 1.3860\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5900 - val_loss: 1.3889\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5889 - val_loss: 1.3926\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5877 - val_loss: 1.3967\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5867 - val_loss: 1.4006\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5855 - val_loss: 1.4014\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5845 - val_loss: 1.4079\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5834 - val_loss: 1.4087\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "LONGIL\n",
      "48h MAE: 1.1469\n",
      "48h MAE: 28.8699\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6926 - val_loss: 2.1196\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6414 - val_loss: 1.9859\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5939 - val_loss: 1.8555\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5551 - val_loss: 1.7753\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5342 - val_loss: 1.7374\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5224 - val_loss: 1.7157\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5147 - val_loss: 1.7014\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5090 - val_loss: 1.6917\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5047 - val_loss: 1.6851\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5012 - val_loss: 1.6805\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4982 - val_loss: 1.6770\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4957 - val_loss: 1.6749\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4933 - val_loss: 1.6734\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4912 - val_loss: 1.6727\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4892 - val_loss: 1.6721\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.4874 - val_loss: 1.6722\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4856 - val_loss: 1.6723\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.4840 - val_loss: 1.6729\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4825 - val_loss: 1.6738\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4810 - val_loss: 1.6749\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4796 - val_loss: 1.6762\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4782 - val_loss: 1.6777\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4769 - val_loss: 1.6792\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4757 - val_loss: 1.6809\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4744 - val_loss: 1.6829\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4732 - val_loss: 1.6849\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4720 - val_loss: 1.6867\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4709 - val_loss: 1.6888\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4698 - val_loss: 1.6904\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4687 - val_loss: 1.6922\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4677 - val_loss: 1.6941\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4666 - val_loss: 1.6959\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4656 - val_loss: 1.6981\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4646 - val_loss: 1.7000\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4636 - val_loss: 1.7023\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "MHK VL\n",
      "48h MAE: 1.0417\n",
      "48h MAE: 11.7713\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6492 - val_loss: 2.1757\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5613 - val_loss: 1.8243\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4918 - val_loss: 1.5714\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4656 - val_loss: 1.4649\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4539 - val_loss: 1.4061\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4462 - val_loss: 1.3650\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4402 - val_loss: 1.3337\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4354 - val_loss: 1.3109\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4314 - val_loss: 1.2940\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4280 - val_loss: 1.2825\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4250 - val_loss: 1.2754\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4224 - val_loss: 1.2688\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4201 - val_loss: 1.2649\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4180 - val_loss: 1.2619\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4161 - val_loss: 1.2600\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4143 - val_loss: 1.2585\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4127 - val_loss: 1.2575\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4111 - val_loss: 1.2577\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.4096 - val_loss: 1.2585\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4082 - val_loss: 1.2585\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4069 - val_loss: 1.2591\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4056 - val_loss: 1.2586\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4044 - val_loss: 1.2603\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4032 - val_loss: 1.2592\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4020 - val_loss: 1.2599\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4009 - val_loss: 1.2597\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3999 - val_loss: 1.2587\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3989 - val_loss: 1.2573\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3980 - val_loss: 1.2579\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3970 - val_loss: 1.2578\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3962 - val_loss: 1.2574\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3953 - val_loss: 1.2580\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3944 - val_loss: 1.2576\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3936 - val_loss: 1.2585\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.3928 - val_loss: 1.2602\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3920 - val_loss: 1.2603\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3912 - val_loss: 1.2640\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3905 - val_loss: 1.2628\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3897 - val_loss: 1.2640\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3890 - val_loss: 1.2631\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3883 - val_loss: 1.2637\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3876 - val_loss: 1.2631\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.3869 - val_loss: 1.2648\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3862 - val_loss: 1.2635\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.3855 - val_loss: 1.2656\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.3848 - val_loss: 1.2645\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.3842 - val_loss: 1.2657\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.3835 - val_loss: 1.2655\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "MILLWD\n",
      "48h MAE: 0.8261\n",
      "48h MAE: 11.9769\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 3s 8ms/step - loss: 0.7420 - val_loss: 1.7738\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6426 - val_loss: 1.5708\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5825 - val_loss: 1.4117\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.5529 - val_loss: 1.3030\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5373 - val_loss: 1.2288\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.5274 - val_loss: 1.1785\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.5203 - val_loss: 1.1415\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.5147 - val_loss: 1.1138\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.5103 - val_loss: 1.0919\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5065 - val_loss: 1.0742\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5034 - val_loss: 1.0595\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.5005 - val_loss: 1.0477\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4981 - val_loss: 1.0379\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4959 - val_loss: 1.0301\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4938 - val_loss: 1.0235\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4919 - val_loss: 1.0186\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4901 - val_loss: 1.0137\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4884 - val_loss: 1.0102\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4869 - val_loss: 1.0065\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4854 - val_loss: 1.0040\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4840 - val_loss: 1.0015\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.4826 - val_loss: 0.9997\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4813 - val_loss: 0.9983\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4800 - val_loss: 0.9972\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4789 - val_loss: 0.9956\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4777 - val_loss: 0.9949\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4765 - val_loss: 0.9939\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4754 - val_loss: 0.9934\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4744 - val_loss: 0.9930\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4733 - val_loss: 0.9931\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4723 - val_loss: 0.9928\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.4713 - val_loss: 0.9927\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4703 - val_loss: 0.9927\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.4693 - val_loss: 0.9927\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4683 - val_loss: 0.9929\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4674 - val_loss: 0.9935\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4664 - val_loss: 0.9935\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.4655 - val_loss: 0.9940\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4646 - val_loss: 0.9944\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4637 - val_loss: 0.9946\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4628 - val_loss: 0.9948\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4619 - val_loss: 0.9953\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4611 - val_loss: 0.9961\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4602 - val_loss: 0.9974\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4593 - val_loss: 0.9984\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4585 - val_loss: 0.9994\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4576 - val_loss: 1.0003\n",
      "Epoch 48/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.4568 - val_loss: 1.0014\n",
      "Epoch 49/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4560 - val_loss: 1.0027\n",
      "Epoch 50/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.4552 - val_loss: 1.0039\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "N.Y.C.\n",
      "48h MAE: 0.7435\n",
      "48h MAE: 11.6405\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 3s 9ms/step - loss: 0.7647 - val_loss: 1.9986\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.7453 - val_loss: 1.9666\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.7333 - val_loss: 1.9377\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.7225 - val_loss: 1.9154\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.7126 - val_loss: 1.8964\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.7034 - val_loss: 1.8810\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6959 - val_loss: 1.8695\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 2s 8ms/step - loss: 0.6897 - val_loss: 1.8612\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6845 - val_loss: 1.8546\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6800 - val_loss: 1.8494\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6761 - val_loss: 1.8454\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6727 - val_loss: 1.8420\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6697 - val_loss: 1.8392\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6670 - val_loss: 1.8372\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 2s 8ms/step - loss: 0.6645 - val_loss: 1.8355\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6623 - val_loss: 1.8339\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6602 - val_loss: 1.8328\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6583 - val_loss: 1.8313\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6565 - val_loss: 1.8305\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6548 - val_loss: 1.8297\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6531 - val_loss: 1.8288\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6515 - val_loss: 1.8283\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6500 - val_loss: 1.8279\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6485 - val_loss: 1.8280\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6471 - val_loss: 1.8276\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6457 - val_loss: 1.8275\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6443 - val_loss: 1.8274\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6429 - val_loss: 1.8274\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6416 - val_loss: 1.8277\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6403 - val_loss: 1.8279\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6390 - val_loss: 1.8282\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6377 - val_loss: 1.8287\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6365 - val_loss: 1.8290\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6353 - val_loss: 1.8296\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6341 - val_loss: 1.8299\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6328 - val_loss: 1.8308\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6316 - val_loss: 1.8316\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6305 - val_loss: 1.8320\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6292 - val_loss: 1.8330\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6281 - val_loss: 1.8336\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6269 - val_loss: 1.8347\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6258 - val_loss: 1.8356\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6246 - val_loss: 1.8367\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6235 - val_loss: 1.8377\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6223 - val_loss: 1.8386\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6213 - val_loss: 1.8399\n",
      "Epoch 47/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6201 - val_loss: 1.8410\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "NORTH\n",
      "48h MAE: 0.9726\n",
      "48h MAE: 14.5480\n",
      "\n",
      "(8713, 48, 3) (8713, 24, 1) (8689, 48, 3) (8689, 24, 1)\n",
      "Epoch 1/50\n",
      "218/218 [==============================] - 2s 8ms/step - loss: 0.9494 - val_loss: 1.1177\n",
      "Epoch 2/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.8753 - val_loss: 1.0628\n",
      "Epoch 3/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.8255 - val_loss: 1.0212\n",
      "Epoch 4/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.7915 - val_loss: 0.9921\n",
      "Epoch 5/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.7678 - val_loss: 0.9723\n",
      "Epoch 6/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.7512 - val_loss: 0.9596\n",
      "Epoch 7/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.7401 - val_loss: 0.9508\n",
      "Epoch 8/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.7323 - val_loss: 0.9444\n",
      "Epoch 9/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.7259 - val_loss: 0.9393\n",
      "Epoch 10/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.7206 - val_loss: 0.9360\n",
      "Epoch 11/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.7165 - val_loss: 0.9331\n",
      "Epoch 12/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.7127 - val_loss: 0.9308\n",
      "Epoch 13/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.7094 - val_loss: 0.9290\n",
      "Epoch 14/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.7064 - val_loss: 0.9276\n",
      "Epoch 15/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.7037 - val_loss: 0.9266\n",
      "Epoch 16/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.7011 - val_loss: 0.9261\n",
      "Epoch 17/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6988 - val_loss: 0.9256\n",
      "Epoch 18/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6967 - val_loss: 0.9251\n",
      "Epoch 19/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6947 - val_loss: 0.9248\n",
      "Epoch 20/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6929 - val_loss: 0.9243\n",
      "Epoch 21/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6912 - val_loss: 0.9243\n",
      "Epoch 22/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6896 - val_loss: 0.9241\n",
      "Epoch 23/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6880 - val_loss: 0.9239\n",
      "Epoch 24/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6866 - val_loss: 0.9237\n",
      "Epoch 25/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6851 - val_loss: 0.9237\n",
      "Epoch 26/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6838 - val_loss: 0.9236\n",
      "Epoch 27/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6824 - val_loss: 0.9239\n",
      "Epoch 28/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6812 - val_loss: 0.9242\n",
      "Epoch 29/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6800 - val_loss: 0.9243\n",
      "Epoch 30/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6789 - val_loss: 0.9244\n",
      "Epoch 31/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6776 - val_loss: 0.9245\n",
      "Epoch 32/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6766 - val_loss: 0.9246\n",
      "Epoch 33/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6754 - val_loss: 0.9246\n",
      "Epoch 34/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6744 - val_loss: 0.9245\n",
      "Epoch 35/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6732 - val_loss: 0.9246\n",
      "Epoch 36/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6722 - val_loss: 0.9249\n",
      "Epoch 37/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6711 - val_loss: 0.9249\n",
      "Epoch 38/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6702 - val_loss: 0.9250\n",
      "Epoch 39/50\n",
      "218/218 [==============================] - 1s 6ms/step - loss: 0.6691 - val_loss: 0.9254\n",
      "Epoch 40/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6681 - val_loss: 0.9253\n",
      "Epoch 41/50\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.6671 - val_loss: 0.9258\n",
      "Epoch 42/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6661 - val_loss: 0.9258\n",
      "Epoch 43/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6652 - val_loss: 0.9261\n",
      "Epoch 44/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6642 - val_loss: 0.9264\n",
      "Epoch 45/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6633 - val_loss: 0.9267\n",
      "Epoch 46/50\n",
      "218/218 [==============================] - 1s 7ms/step - loss: 0.6623 - val_loss: 0.9271\n",
      "272/272 [==============================] - 1s 2ms/step\n",
      "WEST\n",
      "48h MAE: 0.8095\n",
      "48h MAE: 13.0270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for zone in zones:\n",
    "    # Read each timeseries (RTP = Real-Time Price, DAP = Day-Ahead Price, LF = Load Forecast)\n",
    "    raw_DAP = pd.read_csv(\"nyiso/da_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "    raw_RTP = pd.read_csv(\"nyiso/rt_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "    raw_LF = pd.read_csv(\"nyiso/load_frcstd_df_2015_2021.csv\", index_col=0)\n",
    "    \n",
    "    # Prepare the dataset as a dataframe\n",
    "    raw_data = pd.concat([raw_DAP.loc[:,zone], raw_LF.loc[:,zone], raw_RTP.loc[:,zone]],\n",
    "                           axis=1).loc['2017-01-01 05:00:00+00:00':]\n",
    "    raw_data.columns = ['DAP', 'LF', 'RTP']\n",
    "    raw_data.index.names = ['date']\n",
    "    raw_data.to_csv('nyiso/NYISO_'+zone+'_raw.csv')\n",
    "\n",
    "    log_data = raw_data.copy(deep=True)\n",
    "    log_data.loc[:,\"DAP\"] = np.log(raw_data.loc[:,\"DAP\"] + 1 - min(raw_data.loc[:,\"DAP\"]))\n",
    "    log_data.loc[:,\"RTP\"] = np.log(raw_data.loc[:,\"RTP\"] + 1 - min(raw_data.loc[:,\"RTP\"]))\n",
    "    log_data.to_csv('nyiso/NYISO_'+zone+'_log.csv')\n",
    "\n",
    "    # Split dataset: 2015 year for training and 2016-2017 years for testing\n",
    "    x_train_df = log_data.iloc[8760*3:8760*4+24,:]\n",
    "    x_test_df = log_data.iloc[8760*4+24:,:]\n",
    "\n",
    "    y_train_df = log_data.iloc[8760*3:8760*4+24,2:]\n",
    "    y_test_df = log_data.iloc[8760*4+24:,2:]\n",
    "\n",
    "    # Standardization\n",
    "    x_mean, x_std = x_train_df.mean(), x_train_df.std()\n",
    "    y_mean, y_std = y_train_df.mean(), y_train_df.std()\n",
    "\n",
    "    x_train = ((x_train_df - x_mean)/x_std).to_numpy()\n",
    "    x_test = ((x_test_df - x_mean)/x_std).to_numpy()\n",
    "\n",
    "    y_train = ((y_train_df - y_mean)/y_std).to_numpy()\n",
    "    y_test = ((y_test_df - y_mean)/y_std).to_numpy()\n",
    "\n",
    "    \n",
    "    ############## Lag = 48 ###############\n",
    "\n",
    "    n_steps_in = 48\n",
    "    n_steps_out = 24\n",
    "\n",
    "    x_train_cnn = np.array([x_train[i:i+n_steps_in] for i in range(0, x_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_train_cnn = np.array([y_train[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_train.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    x_test_cnn = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_test_cnn = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "\n",
    "    print(x_train_cnn.shape,y_train_cnn.shape,x_test_cnn.shape,y_test_cnn.shape)\n",
    "\n",
    "    # set hyperparameters\n",
    "    n_filters  = 32  # number of filters\n",
    "    n_neurons  = 64  # number of neurons in the Dense layer\n",
    "    activation     = 'relu' # activation function\n",
    "    kernel_size    = 3\n",
    "    pool_size = 1\n",
    "    learning_rate  = 0.0001\n",
    "    minibatch_size = 32\n",
    "    num_epochs     = 50\n",
    "\n",
    "    # Building the model\n",
    "    # define model\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(filters=n_filters,kernel_size=kernel_size, strides=2, padding='same',\n",
    "                         input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=activation))\n",
    "    cnn_model.add(Conv1D(filters=n_filters,kernel_size=kernel_size, strides=2, padding='same',\n",
    "                         input_shape=(x_train_cnn.shape[1],x_train_cnn.shape[2]), activation=activation))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(n_neurons, activation=activation))\n",
    "    cnn_model.add(Dense(n_steps_out, activation='linear'))\n",
    "    cnn_model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "\n",
    "    # Running training\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "    history = cnn_model.fit(x_train_cnn, y_train_cnn, \n",
    "                            batch_size = minibatch_size,\n",
    "                            epochs = num_epochs,\n",
    "                            validation_split=0.2, verbose=1,\n",
    "                            callbacks=[early_stop],\n",
    "                            shuffle=False)\n",
    "\n",
    "    # Saving the model\n",
    "    model_path = os.path.join(cwd,'saved_model')\n",
    "    make_dir(model_path)\n",
    "    cnn_model.save(os.path.join(model_path,'1y_cnn_model_'+zone+'_48h.h5'))\n",
    "\n",
    "    ################# Evaluation ##################\n",
    "\n",
    "    n_steps_in = 48\n",
    "    x_test_cnn = np.array([x_test[i:i+n_steps_in] for i in range(0, x_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    y_test_cnn_48 = np.array([y_test[i+n_steps_in:i+n_steps_in+n_steps_out] for i in range(0, y_test.shape[0]-n_steps_in-n_steps_out+1)])\n",
    "    cnn_model = load_model(os.path.join(model_path,'1y_cnn_model_'+zone+'_48h.h5'))\n",
    "    y_test_pred_48 = cnn_model.predict(x_test_cnn)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    print(zone)\n",
    "    print('48h MAE: {:.4f}'.format(np.abs(y_test_pred_48 - y_test_cnn_48[:,:,0]).mean()))\n",
    "\n",
    "    y_test_pred_rescale_48 = y_test_pred_48*y_std.values + y_mean.values\n",
    "    y_test_cnn_rescale_48 = y_test_cnn_48*y_std.values + y_mean.values\n",
    "    y_test_pred_invlog_48 = np.exp(y_test_pred_rescale_48) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "    y_test_cnn_invlog_48 = np.exp(y_test_cnn_rescale_48) -1 + min(raw_data.loc[:,\"RTP\"])\n",
    "\n",
    "    # Evaluation metrics\n",
    "\n",
    "    print('48h MAE: {:.4f}'.format(np.abs(y_test_pred_invlog_48 - y_test_cnn_invlog_48[:,:,0]).mean()))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4120f5c-82fc-4e5d-bdaa-e1032cb5a99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61eacb82-1ec7-42f0-ab33-20741d4d44a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPITL\n",
      "44.6038\n",
      "18.9331\n",
      "44.1633\n",
      "29.5993\n",
      "CENTRL\n",
      "29.8999\n",
      "16.3021\n",
      "29.5728\n",
      "22.6937\n",
      "DUNWOD\n",
      "41.6494\n",
      "18.1111\n",
      "41.4403\n",
      "25.9568\n",
      "GENESE\n",
      "28.7855\n",
      "15.9150\n",
      "28.5536\n",
      "22.5367\n",
      "HUD VL\n",
      "40.7378\n",
      "17.2660\n",
      "40.0888\n",
      "23.3379\n",
      "LONGIL\n",
      "54.0603\n",
      "31.3705\n",
      "54.7833\n",
      "63.6448\n",
      "MHK VL\n",
      "30.1917\n",
      "16.6750\n",
      "30.0775\n",
      "23.3890\n",
      "MILLWD\n",
      "41.6300\n",
      "18.2120\n",
      "41.7525\n",
      "29.6173\n",
      "N.Y.C.\n",
      "42.5206\n",
      "18.9206\n",
      "42.4620\n",
      "26.8635\n",
      "NORTH\n",
      "22.6753\n",
      "16.0531\n",
      "23.5312\n",
      "30.2330\n",
      "WEST\n",
      "31.0270\n",
      "19.4403\n",
      "30.8867\n",
      "27.0452\n"
     ]
    }
   ],
   "source": [
    "for zone in zones:\n",
    "    # Read each timeseries (RTP = Real-Time Price, DAP = Day-Ahead Price, LF = Load Forecast)\n",
    "    raw_DAP = pd.read_csv(\"nyiso/da_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "    raw_RTP = pd.read_csv(\"nyiso/rt_lmp_zones_df_2015_2021.csv\", index_col=0)\n",
    "    raw_LF = pd.read_csv(\"nyiso/load_frcstd_df_2015_2021.csv\", index_col=0)\n",
    "    \n",
    "    # Prepare the dataset as a dataframe\n",
    "    raw_data = pd.concat([raw_DAP.loc[:,zone], raw_LF.loc[:,zone], raw_RTP.loc[:,zone]],\n",
    "                           axis=1).loc['2017-01-01 05:00:00+00:00':]\n",
    "    raw_data.columns = ['DAP', 'LF', 'RTP']\n",
    "    raw_data.index.names = ['date']\n",
    "    raw_data.to_csv('nyiso/NYISO_'+zone+'_raw.csv')\n",
    "\n",
    "    log_data = raw_data.copy(deep=True)\n",
    "    log_data.loc[:,\"DAP\"] = np.log(raw_data.loc[:,\"DAP\"] + 1 - min(raw_data.loc[:,\"DAP\"]))\n",
    "    log_data.loc[:,\"RTP\"] = np.log(raw_data.loc[:,\"RTP\"] + 1 - min(raw_data.loc[:,\"RTP\"]))\n",
    "    log_data.to_csv('nyiso/NYISO_'+zone+'_log.csv')\n",
    "\n",
    "    # Split dataset: 2015 year for training and 2016-2017 years for testing\n",
    "    x_train_df = log_data.iloc[8760*3:8760*4+24,:]\n",
    "    x_test_df = log_data.iloc[8760*4+24:,:]\n",
    "\n",
    "    y_train_df = log_data.iloc[8760*3:8760*4+24,2:]\n",
    "    y_test_df = log_data.iloc[8760*4+24:,2:]\n",
    "\n",
    "    # Standardization\n",
    "    x_mean, x_std = x_train_df.mean(), x_train_df.std()\n",
    "    y_mean, y_std = y_train_df.mean(), y_train_df.std()\n",
    "\n",
    "    # Evaluation metrics\n",
    "    print(zone)\n",
    "    print('DAP mean: {:.4f}'.format(raw_data.iloc[8760*4+24:,:1].mean()[0]))\n",
    "    print('DAP std: {:.4f}'.format(raw_data.iloc[8760*4+24:,:1].std()[0]))\n",
    "    print('RTP mean: {:.4f}'.format(raw_data.iloc[8760*4+24:,2:].mean()[0]))\n",
    "    print('RTP std: {:.4f}'.format(raw_data.iloc[8760*4+24:,2:].std()[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34eac9c-ccbd-4f0a-838e-206c2c81494e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daeab95-cf3a-4a5a-bb8a-3477711589ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
